{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab5baaa3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-25T15:47:27.227507Z",
     "iopub.status.busy": "2023-01-25T15:47:27.226367Z",
     "iopub.status.idle": "2023-01-25T15:47:29.212048Z",
     "shell.execute_reply": "2023-01-25T15:47:29.210650Z"
    },
    "papermill": {
     "duration": 2.085099,
     "end_time": "2023-01-25T15:47:29.212410",
     "exception": false,
     "start_time": "2023-01-25T15:47:27.127311",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: papermill in /home/user/miniconda/envs/py36/lib/python3.6/site-packages (2.3.4)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: entrypoints in /home/user/miniconda/envs/py36/lib/python3.6/site-packages (from papermill) (0.3)\r\n",
      "Requirement already satisfied: ansiwrap in /home/user/miniconda/envs/py36/lib/python3.6/site-packages (from papermill) (0.8.4)\r\n",
      "Requirement already satisfied: tqdm>=4.32.2 in /home/user/miniconda/envs/py36/lib/python3.6/site-packages (from papermill) (4.51.0)\r\n",
      "Requirement already satisfied: tenacity in /home/user/miniconda/envs/py36/lib/python3.6/site-packages (from papermill) (8.1.0)\r\n",
      "Requirement already satisfied: nbformat>=5.1.2 in /home/user/miniconda/envs/py36/lib/python3.6/site-packages (from papermill) (5.1.3)\r\n",
      "Requirement already satisfied: requests in /home/user/miniconda/envs/py36/lib/python3.6/site-packages (from papermill) (2.27.1)\r\n",
      "Requirement already satisfied: click in /home/user/miniconda/envs/py36/lib/python3.6/site-packages (from papermill) (8.0.4)\r\n",
      "Requirement already satisfied: nbclient>=0.2.0 in /home/user/miniconda/envs/py36/lib/python3.6/site-packages (from papermill) (0.5.1)\r\n",
      "Requirement already satisfied: pyyaml in /home/user/miniconda/envs/py36/lib/python3.6/site-packages (from papermill) (5.3.1)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nest-asyncio in /home/user/miniconda/envs/py36/lib/python3.6/site-packages (from nbclient>=0.2.0->papermill) (1.4.2)\r\n",
      "Requirement already satisfied: traitlets>=4.2 in /home/user/miniconda/envs/py36/lib/python3.6/site-packages (from nbclient>=0.2.0->papermill) (4.3.3)\r\n",
      "Requirement already satisfied: async-generator in /home/user/miniconda/envs/py36/lib/python3.6/site-packages (from nbclient>=0.2.0->papermill) (1.10)\r\n",
      "Requirement already satisfied: jupyter-client>=6.1.5 in /home/user/miniconda/envs/py36/lib/python3.6/site-packages (from nbclient>=0.2.0->papermill) (6.1.7)\r\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /home/user/miniconda/envs/py36/lib/python3.6/site-packages (from nbformat>=5.1.2->papermill) (3.2.0)\r\n",
      "Requirement already satisfied: ipython-genutils in /home/user/miniconda/envs/py36/lib/python3.6/site-packages (from nbformat>=5.1.2->papermill) (0.2.0)\r\n",
      "Requirement already satisfied: jupyter-core in /home/user/miniconda/envs/py36/lib/python3.6/site-packages (from nbformat>=5.1.2->papermill) (4.6.3)\r\n",
      "Requirement already satisfied: textwrap3>=0.9.2 in /home/user/miniconda/envs/py36/lib/python3.6/site-packages (from ansiwrap->papermill) (0.9.2)\r\n",
      "Requirement already satisfied: importlib-metadata in /home/user/miniconda/envs/py36/lib/python3.6/site-packages (from click->papermill) (2.0.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/user/miniconda/envs/py36/lib/python3.6/site-packages (from requests->papermill) (1.26.14)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/user/miniconda/envs/py36/lib/python3.6/site-packages (from requests->papermill) (2021.5.30)\r\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/user/miniconda/envs/py36/lib/python3.6/site-packages (from requests->papermill) (2.0.12)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/user/miniconda/envs/py36/lib/python3.6/site-packages (from requests->papermill) (3.4)\r\n",
      "Requirement already satisfied: setuptools in /home/user/miniconda/envs/py36/lib/python3.6/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=5.1.2->papermill) (58.0.4)\r\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /home/user/miniconda/envs/py36/lib/python3.6/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=5.1.2->papermill) (0.17.3)\r\n",
      "Requirement already satisfied: attrs>=17.4.0 in /home/user/miniconda/envs/py36/lib/python3.6/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=5.1.2->papermill) (20.2.0)\r\n",
      "Requirement already satisfied: six>=1.11.0 in /home/user/miniconda/envs/py36/lib/python3.6/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=5.1.2->papermill) (1.15.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyzmq>=13 in /home/user/miniconda/envs/py36/lib/python3.6/site-packages (from jupyter-client>=6.1.5->nbclient>=0.2.0->papermill) (19.0.2)\r\n",
      "Requirement already satisfied: tornado>=4.1 in /home/user/miniconda/envs/py36/lib/python3.6/site-packages (from jupyter-client>=6.1.5->nbclient>=0.2.0->papermill) (6.0.4)\r\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/user/miniconda/envs/py36/lib/python3.6/site-packages (from jupyter-client>=6.1.5->nbclient>=0.2.0->papermill) (2.8.1)\r\n",
      "Requirement already satisfied: decorator in /home/user/miniconda/envs/py36/lib/python3.6/site-packages (from traitlets>=4.2->nbclient>=0.2.0->papermill) (4.4.2)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: zipp>=0.5 in /home/user/miniconda/envs/py36/lib/python3.6/site-packages (from importlib-metadata->click->papermill) (3.4.0)\r\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install papermill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dba1bcae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-25T15:47:29.396567Z",
     "iopub.status.busy": "2023-01-25T15:47:29.395544Z",
     "iopub.status.idle": "2023-01-25T15:47:31.336390Z",
     "shell.execute_reply": "2023-01-25T15:47:31.334973Z"
    },
    "papermill": {
     "duration": 2.033152,
     "end_time": "2023-01-25T15:47:31.336855",
     "exception": false,
     "start_time": "2023-01-25T15:47:29.303703",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: chainer in /home/user/miniconda/envs/py36/lib/python3.6/site-packages (7.8.1)\r\n",
      "Requirement already satisfied: typing-extensions in /home/user/miniconda/envs/py36/lib/python3.6/site-packages (from chainer) (4.1.1)\r\n",
      "Requirement already satisfied: filelock in /home/user/miniconda/envs/py36/lib/python3.6/site-packages (from chainer) (3.4.1)\r\n",
      "Requirement already satisfied: numpy>=1.9.0 in /home/user/miniconda/envs/py36/lib/python3.6/site-packages (from chainer) (1.18.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: protobuf>=3.0.0 in /home/user/miniconda/envs/py36/lib/python3.6/site-packages (from chainer) (3.13.0)\r\n",
      "Requirement already satisfied: setuptools in /home/user/miniconda/envs/py36/lib/python3.6/site-packages (from chainer) (58.0.4)\r\n",
      "Requirement already satisfied: six>=1.9.0 in /home/user/miniconda/envs/py36/lib/python3.6/site-packages (from chainer) (1.15.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install chainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7af423d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-25T15:47:31.523543Z",
     "iopub.status.busy": "2023-01-25T15:47:31.522482Z",
     "iopub.status.idle": "2023-01-25T15:47:33.472576Z",
     "shell.execute_reply": "2023-01-25T15:47:33.471141Z"
    },
    "papermill": {
     "duration": 2.044584,
     "end_time": "2023-01-25T15:47:33.472832",
     "exception": false,
     "start_time": "2023-01-25T15:47:31.428248",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch_geometric in /home/user/miniconda/envs/py36/lib/python3.6/site-packages (2.0.3)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: networkx in /home/user/miniconda/envs/py36/lib/python3.6/site-packages (from torch_geometric) (2.5)\r\n",
      "Requirement already satisfied: rdflib in /home/user/miniconda/envs/py36/lib/python3.6/site-packages (from torch_geometric) (5.0.0)\r\n",
      "Requirement already satisfied: jinja2 in /home/user/miniconda/envs/py36/lib/python3.6/site-packages (from torch_geometric) (2.11.2)\r\n",
      "Requirement already satisfied: scipy in /home/user/miniconda/envs/py36/lib/python3.6/site-packages (from torch_geometric) (1.5.3)\r\n",
      "Requirement already satisfied: yacs in /home/user/miniconda/envs/py36/lib/python3.6/site-packages (from torch_geometric) (0.1.8)\r\n",
      "Requirement already satisfied: pyparsing in /home/user/miniconda/envs/py36/lib/python3.6/site-packages (from torch_geometric) (2.4.7)\r\n",
      "Requirement already satisfied: PyYAML in /home/user/miniconda/envs/py36/lib/python3.6/site-packages (from torch_geometric) (5.3.1)\r\n",
      "Requirement already satisfied: requests in /home/user/miniconda/envs/py36/lib/python3.6/site-packages (from torch_geometric) (2.27.1)\r\n",
      "Requirement already satisfied: scikit-learn in /home/user/miniconda/envs/py36/lib/python3.6/site-packages (from torch_geometric) (0.23.0)\r\n",
      "Requirement already satisfied: pandas in /home/user/miniconda/envs/py36/lib/python3.6/site-packages (from torch_geometric) (1.1.5)\r\n",
      "Requirement already satisfied: numpy in /home/user/miniconda/envs/py36/lib/python3.6/site-packages (from torch_geometric) (1.18.0)\r\n",
      "Requirement already satisfied: tqdm in /home/user/miniconda/envs/py36/lib/python3.6/site-packages (from torch_geometric) (4.51.0)\r\n",
      "Requirement already satisfied: googledrivedownloader in /home/user/miniconda/envs/py36/lib/python3.6/site-packages (from torch_geometric) (0.4)\r\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /home/user/miniconda/envs/py36/lib/python3.6/site-packages (from jinja2->torch_geometric) (1.1.1)\r\n",
      "Requirement already satisfied: decorator>=4.3.0 in /home/user/miniconda/envs/py36/lib/python3.6/site-packages (from networkx->torch_geometric) (4.4.2)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/user/miniconda/envs/py36/lib/python3.6/site-packages (from pandas->torch_geometric) (2.8.1)\r\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/user/miniconda/envs/py36/lib/python3.6/site-packages (from pandas->torch_geometric) (2022.7.1)\r\n",
      "Requirement already satisfied: six in /home/user/miniconda/envs/py36/lib/python3.6/site-packages (from rdflib->torch_geometric) (1.15.0)\r\n",
      "Requirement already satisfied: isodate in /home/user/miniconda/envs/py36/lib/python3.6/site-packages (from rdflib->torch_geometric) (0.6.1)\r\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/user/miniconda/envs/py36/lib/python3.6/site-packages (from requests->torch_geometric) (2.0.12)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/user/miniconda/envs/py36/lib/python3.6/site-packages (from requests->torch_geometric) (1.26.14)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/user/miniconda/envs/py36/lib/python3.6/site-packages (from requests->torch_geometric) (3.4)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/user/miniconda/envs/py36/lib/python3.6/site-packages (from requests->torch_geometric) (2021.5.30)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/user/miniconda/envs/py36/lib/python3.6/site-packages (from scikit-learn->torch_geometric) (2.1.0)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /home/user/miniconda/envs/py36/lib/python3.6/site-packages (from scikit-learn->torch_geometric) (0.17.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc9f4ff6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-25T15:47:33.664372Z",
     "iopub.status.busy": "2023-01-25T15:47:33.663735Z"
    },
    "papermill": {
     "duration": 3.300027,
     "end_time": "2023-01-25T15:47:36.867037",
     "exception": false,
     "start_time": "2023-01-25T15:47:33.567010",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://pytorch-geometric.com/whl/torch-1.5.0+cu113.html\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch-sparse==0.6.11\r\n",
      "  Using cached torch_sparse-0.6.11.tar.gz (40 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Preparing metadata (setup.py) ... \u001b[?25l-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: scipy in /home/user/miniconda/envs/py36/lib/python3.6/site-packages (from torch-sparse==0.6.11) (1.5.3)\r\n",
      "Requirement already satisfied: numpy>=1.14.5 in /home/user/miniconda/envs/py36/lib/python3.6/site-packages (from scipy->torch-sparse==0.6.11) (1.18.0)\r\n",
      "Building wheels for collected packages: torch-sparse\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Building wheel for torch-sparse (setup.py) ... \u001b[?25l-"
     ]
    }
   ],
   "source": [
    "!pip install torch-sparse==0.6.11 -f https://pytorch-geometric.com/whl/torch-1.5.0+cu113.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d130ace",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -U torch==1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c3ea19",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!export LD_LIBRARY_PATH=/usr/local/lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a89a758",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# %load_ext line_profiler\n",
    "import h5py\n",
    "import randomcolor\n",
    "import numpy as np\n",
    "\n",
    "from utils import *\n",
    "from optimization import *\n",
    "from topological_graph import *\n",
    "\n",
    "from scipy.spatial import cKDTree\n",
    "from scipy.interpolate import UnivariateSpline, splev, splprep\n",
    "from scipy.optimize import minimize\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import point_cloud_utils as pcu\n",
    "import torch\n",
    "from torch_geometric.nn import fps as tfps\n",
    "import time\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.model_selection import ParameterGrid \n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from pytorch3d.loss.chamfer import chamfer_distance\n",
    "from geomloss import SamplesLoss\n",
    "import copy\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ec651e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "\n",
    "RES = 0.02\n",
    "sharpness_threshold = RES * 3 #RES*3\n",
    "\n",
    "knn_radius = 2\n",
    "\n",
    "filtering_radius = RES * 1 # max distance to connect a pair in knn filtering\n",
    "corner_connected_components_radius = RES * knn_radius # max distance to connect a pair in knn corner separation\n",
    "curve_connected_components_radius = RES * 2.5 # max distance to connect a pair in knn curve separation\n",
    "\n",
    "sampling = 'blue' # 'blue','random','voxel'\n",
    "num_voxels_per_axis = 100\n",
    "subsample_factor = 10\n",
    "filtering_factor = 30\n",
    "filtering_mode = False\n",
    "fps_factor = 5\n",
    "\n",
    "# corner_detector_radius = RES * 8\n",
    "# upper_variance_threshold = 0.05\n",
    "# lower_variance_threshold = 0.04\n",
    "cornerness_threshold = 0.7\n",
    "# box_margin = RES * 4\n",
    "quantile = 1\n",
    "\n",
    "curve_extraction_mode = 'knn' # 'subdivision', 'knn'\n",
    "endpoint_detector_radius = RES * 10\n",
    "endpoint_threshold = 0.6\n",
    "\n",
    "corner_connector_radius = RES * 20\n",
    "\n",
    "initial_split_threshold = RES * 4\n",
    "# optimization_split_threshold = RES * 3\n",
    "alpha_ang = 1000\n",
    "\n",
    "DISPLAY_RES = 0.03\n",
    "cut_metric = 'fscore' #fscore #'chamfer_dist','sinkhorn' \n",
    "\n",
    "\n",
    "small_lines_clip_primitive_number = 3\n",
    "small_lines_clip_primitives_length = 0.4\n",
    "\n",
    "id_it = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5038348b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "id_it = 1\n",
    "sharpness_threshold = 0.06\n",
    "cornerness_threshold = 0.7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6d20be",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = 'input/'\n",
    "_ids = np.sort(glob('input/*.hdf5'))\n",
    "# _id = 'abc_0051_00514480_6c33de245ad4c4ff41a3360f_000'\n",
    "_id = _ids[id_it].split('__')[0][6:]\n",
    "_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadc1c48",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# path = 'input_new_models/'\n",
    "# _ids = np.sort(glob('input_new_models/*.hdf5'))\n",
    "# # _id = 'abc_0051_00514480_6c33de245ad4c4ff41a3360f_000'\n",
    "# # _id = _ids[id_it].split('__')[0][6:]\n",
    "# _id = _ids[id_it].split('__')[0][17:]\n",
    "# _id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffa1366",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "meta_exp_name = 'cor_' + str(cornerness_threshold) + '_sharp_' + str(sharpness_threshold)+'_subs_'+ str(subsample_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fd42ca",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(meta_exp_name):\n",
    "    os.makedirs(meta_exp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f863290d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "#changed\n",
    "folder_name = 'id_it' + str(id_it) + '_'+ str(_id)+'_cor_' + str(cornerness_threshold) + '_sharp_' + str(sharpness_threshold)+'_subs_'+ str(subsample_factor)\n",
    "if not os.path.exists(meta_exp_name+'/'+folder_name):\n",
    "    os.makedirs(meta_exp_name+ '/'+folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90934067",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### print('Processing ', _id)\n",
    "# with h5py.File('{path}/{_id}__min.hdf5'.format(path=path, _id=_id), 'r') as f:\n",
    "with h5py.File('{path}/{_id}__adv60.hdf5'.format(path=path, _id=_id), 'r') as f:\n",
    "    whole_model_points = f['points'][:]\n",
    "    whole_model_distances = f['distances'][:]\n",
    "points = whole_model_points[whole_model_distances < sharpness_threshold]\n",
    "distances = whole_model_distances[whole_model_distances < sharpness_threshold]\n",
    "print(points.shape)\n",
    "subsample_rate = int(points.shape[0] / subsample_factor)\n",
    "print(\"subsample_rate\", subsample_rate)\n",
    "\n",
    "print('processing {size} points'.format(size=len(points)))\n",
    "start_all = time.time()\n",
    "if sampling:\n",
    "    if  subsample_rate > 0 and sampling=='random':\n",
    "        print('random sampling')\n",
    "        sub_idx = np.random.choice(np.arange(len(points)), subsample_rate)\n",
    "        points = points[sub_idx]\n",
    "        distances = distances[sub_idx]\n",
    "    elif sampling=='blue'and subsample_rate > 0:\n",
    "        start =time.time()\n",
    "        print('blue sampling')\n",
    "        # Downsample a point cloud by approximately to subsample_rate so that the sampled points approximately\n",
    "        # follow a blue noise distribution\n",
    "        # idx is an array of integer indices into v indicating which samples to keep\n",
    "        sub_idx = pcu.downsample_point_cloud_poisson_disk(points, num_samples=subsample_rate)\n",
    "        # Use the indices to get the sample positions and normals\n",
    "        points = points[sub_idx]\n",
    "        distances = distances[sub_idx]\n",
    "        print(time.time()-start)\n",
    "    elif sampling=='voxel':\n",
    "        start =time.time()\n",
    "        print(\"voxel sampling\")\n",
    "        # We'll use a voxel grid with 128 voxels per axis\n",
    "        distances = np.array(np.tile(distances, (3,1)).transpose(1,0), order='C')\n",
    "\n",
    "        # Size of the axis aligned bounding box of the point cloud\n",
    "        bbox_size = points.max(0) - points.min(0)\n",
    "\n",
    "        # The size per-axis of a single voxel\n",
    "        sizeof_voxel = bbox_size / num_voxels_per_axis\n",
    "\n",
    "        # Downsample a point cloud on a voxel grid so there is at most one point per voxel.\n",
    "        # Multiple points, normals, and colors within a voxel cell are averaged together.\n",
    "        v_sampled, n_sampled, c_sampled = pcu.downsample_point_cloud_voxel_grid(sizeof_voxel, points,distances , None)\n",
    "        points = v_sampled\n",
    "        distances = n_sampled[:,0]\n",
    "        print(time.time()-start)\n",
    "    else:\n",
    "        raise Exception(\"No other option for samoling\") \n",
    "\n",
    "\n",
    "if filtering_mode:\n",
    "    print('filtering')\n",
    "    filtered_clusters = separate_graph_connected_components(points, radius=filtering_radius, filtering_mode=True, \n",
    "                                                            filtering_factor=filtering_factor)\n",
    "    points = points[np.unique(np.concatenate(filtered_clusters))]\n",
    "    distances = distances[np.unique(np.concatenate(filtered_clusters))]\n",
    "\n",
    "print('processing {size} points'.format(size=len(points)))\n",
    "# fps = farthest_point_sampling(points, points.shape[0] // fps_factor)\n",
    "# print('fps_finished')\n",
    "print(time.time()-start_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef8aa65",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "a = torch.tensor(points)\n",
    "print(time.time()-start)\n",
    "start = time.time()\n",
    "fps = tfps(a,ratio=1/fps_factor)\n",
    "print(time.time()-start)\n",
    "fps = fps.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d60a513",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# New methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63731d9",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "parameters = {'corner_detector_radius':[RES * 5, RES * 6, RES * 7, RES * 8],\n",
    "              'neighbours_count':[10,20,40], \n",
    "              'variance_dynamics_threshold':[5,10,15,20,25]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c002a465",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def neighb_prob(par, variance):\n",
    "    var_dynamics = np.zeros_like(variances)\n",
    "    tree_fps = cKDTree(points[fps])\n",
    "    fps_nbhds = tree_fps.query(points[fps], par['neighbours_count'])\n",
    "    \n",
    "    for i in range(1,par['neighbours_count']):\n",
    "        var_dynamics += ((variances[fps_nbhds[1][:,i]] - variances) / fps_nbhds[0][:,i][:,None]) ** 2\n",
    "#     var_dynamics = np.abs(var_dynamics)\n",
    "    # it can be done softer, can be just averaging var_dinamics\n",
    "    return np.where(var_dynamics.sum(-1) > par['variance_dynamics_threshold'])\n",
    "    #return var_dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1e455d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "boxes = []\n",
    "for it in range(len(parameters['corner_detector_radius'])):\n",
    "    tree = cKDTree(points)\n",
    "    neighbours = tree.query_ball_point(points[fps], r=parameters[\"corner_detector_radius\"][it])\n",
    "    variances = []\n",
    "    for n in tqdm(neighbours):\n",
    "        pca = PCA(3)\n",
    "        # if size of neighbourhood is sufficient\n",
    "        if len(n) > 5:\n",
    "            pca.fit(points[n])\n",
    "            variances.append(pca.explained_variance_ratio_)\n",
    "        else: variances.append([1,0,0])\n",
    "    variances = np.array(variances)\n",
    "    keys = ['neighbours_count','variance_dynamics_threshold' ]\n",
    "    cicle_par = {x:parameters[x] for x in keys}\n",
    "    #TODO can be optimized \n",
    "    boxsss=Parallel(n_jobs=4)(delayed(neighb_prob)(par,variances) for par in tqdm(ParameterGrid(cicle_par)))\n",
    "    boxes.append(boxsss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebafd4fd",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "(corners,counts) = np.unique(np.concatenate(np.concatenate(np.concatenate(boxes))),return_counts=True)\n",
    "prob = counts/(len(list(ParameterGrid(cicle_par)))*len(parameters['corner_detector_radius']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67084cb6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot = k3d.plot()\n",
    "\n",
    "cmap=k3d.colormaps.matplotlib_color_maps.plasma\n",
    "colors = k3d.helpers.map_colors(\n",
    "                prob, cmap, [prob.min(), prob.max()]\n",
    "            ).astype(np.uint32)\n",
    "\n",
    "k3d_points = k3d.points(points[fps][corners.astype(int)], point_size=DISPLAY_RES, shader='3d', name='sharp_points',colors=colors)\n",
    "plot += k3d_points\n",
    "\n",
    "k3d_points_i = k3d.points(points[fps][~np.in1d(range(len(points[fps])),corners)], point_size=DISPLAY_RES, shader='3d', name='sharp_points')\n",
    "plot += k3d_points_i\n",
    "\n",
    "plot.display()\n",
    "\n",
    "with open(meta_exp_name+'/'+folder_name+'/'+'prob_corr'+'.html', 'w') as f:\n",
    "    f.write(plot.get_snapshot())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82260f01",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_fps_prob = np.zeros(points[fps].shape[0])\n",
    "all_fps_prob[corners] = prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877e8138",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "neigh = KNeighborsRegressor(n_neighbors=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dabdc8",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "neigh.fit(points[fps], all_fps_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37a719d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# не знаю стоит ли предсказывать для всех или только для тех которые не известны\n",
    "all_prob = neigh.predict(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792489bd",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cornerness_threshold=0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a680925",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cornerness_threshold=0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ea23c0",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "corners = np.arange(points.shape[0])[all_prob>cornerness_threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d402feff",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cornerness_threshold=0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7749dc81",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot = k3d.plot()\n",
    "\n",
    "\n",
    "k3d_points = k3d.points(points[np.setdiff1d(np.arange(len(points)), corners)], point_size=DISPLAY_RES, shader='3d', name='sharp_points')\n",
    "plot += k3d_points\n",
    "\n",
    "k3d_points = k3d.points(points[corners], point_size=DISPLAY_RES, shader='3d', name='sharp_points',color=0xff0000)\n",
    "plot += k3d_points\n",
    "\n",
    "\n",
    "plot.display()\n",
    "with open(meta_exp_name + '/'+ folder_name +'/'+'corners'+'.html', 'w') as f:\n",
    "    f.write(plot.get_snapshot())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90eaad47",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# decrease if neccessary (if there are glued corners)\n",
    "# quantile = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5d6551",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "corner_centers = []\n",
    "corner_clusters = []\n",
    "corners = np.arange(points.shape[0])[all_prob>cornerness_threshold]\n",
    "\n",
    "tmp_corner_clusters = separate_graph_connected_components(points[corners], corner_connected_components_radius,\n",
    "                                                                          compute_barycenters=False)\n",
    "tmp_corner_centers = [np.median(points[corners][clust], axis=0).tolist() for clust in tmp_corner_clusters] \n",
    "\n",
    "# for every corner box, sample two points as corners, and store connections between them\n",
    "\n",
    "init_connections = []\n",
    "norms = []\n",
    "for i, cluster in enumerate(tmp_corner_clusters):\n",
    "    tmp_p = points[corners][cluster]\n",
    "    tmp_p -= tmp_p.mean(0)\n",
    "    norms.append(np.linalg.norm(tmp_p, axis=1).max())\n",
    "for i, cluster in enumerate(tmp_corner_clusters):\n",
    "    if norms[i] < np.quantile(norms, quantile):\n",
    "        corner_clusters.append(cluster)\n",
    "        query = cKDTree(points[corners]).query(tmp_corner_centers[i], 1)\n",
    "        corner_centers.append(query[1])\n",
    "        continue\n",
    "    else:\n",
    "        gmm = GaussianMixture(2)\n",
    "        res = gmm.fit_predict(points[corners][cluster])\n",
    "        corner_clusters.append(np.array(cluster)[res == 0].tolist())\n",
    "        corner_clusters.append(np.array(cluster)[res == 1].tolist())\n",
    "        endpoints_query = cKDTree(points[corners]).query(gmm.means_, 1)\n",
    "        ind = len(corner_centers)\n",
    "        corner_centers.append(endpoints_query[1][0])\n",
    "        corner_centers.append(endpoints_query[1][1])\n",
    "        init_connections.append([ind, ind+1])    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7919cf",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "not_corners = np.setdiff1d(np.arange(len(points)), corners)\n",
    "\n",
    "# print('separating curves')\n",
    "curves = separate_graph_connected_components(points[not_corners], radius=curve_connected_components_radius)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9a4a5c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot = k3d.plot()\n",
    "rand_color = randomcolor.RandomColor()\n",
    "\n",
    "cmap=k3d.colormaps.matplotlib_color_maps.plasma_r\n",
    "colors = k3d.helpers.map_colors(\n",
    "                distances, cmap, [distances.min(), distances.max()]\n",
    "            ).astype(np.uint32)\n",
    "\n",
    "plot += k3d.points(points, point_size=0.03, colors=colors)\n",
    "\n",
    "for i in corner_clusters:\n",
    "    color = rand_color.generate()[0]\n",
    "    color = int('0x' + color[1:], 16)\n",
    "    plot += k3d.points(points[corners][i], color=color, point_size=0.03)\n",
    "    \n",
    "for i in range(len(curves)):\n",
    "    color = rand_color.generate()[0]\n",
    "    color = int('0x' + color[1:], 16)\n",
    "    plot += k3d.points(points[not_corners][curves[i]], color=color, point_size=0.03)\n",
    "    \n",
    "plot.display()\n",
    "with open(meta_exp_name+'/'+folder_name+'/'+'segmentation_'+curve_extraction_mode+'.html', 'w') as f:\n",
    "    f.write(plot.get_snapshot())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad506fe0",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# curve_extraction_mode = 'knn' #subdivision,knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac330c6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('initializing topological graph')\n",
    "from topological_graph import *\n",
    "corner_positions, corner_pairs = initialize_topological_graph(points, distances, \n",
    "                                                              not_corners, curves, \n",
    "                                                              corners, corner_centers,\n",
    "                                                              init_connections,\n",
    "                                                              endpoint_detector_radius, endpoint_threshold, \n",
    "                                                              initial_split_threshold, corner_connector_radius,\n",
    "                                                              curve_extraction_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f5bb6d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# np.arange(len(corner_positions))\n",
    "not_corners_ss = np.setdiff1d(np.arange(len(np.arange(len(corner_positions)))), np.unique(corner_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b10242f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot = k3d.plot()\n",
    "\n",
    "k3d_points = k3d.points(points, point_size=DISPLAY_RES, opacity=0.1, shader='3d', name='sharp_points')\n",
    "plot += k3d_points\n",
    "\n",
    "points_corner_centers = k3d.points(np.array(corner_positions),\n",
    "                                   color=0xFF0000, point_size=DISPLAY_RES, shader='3d', name='polyline_nodes')\n",
    "plot += points_corner_centers\n",
    "\n",
    "for edge in corner_pairs:\n",
    "    try:\n",
    "        e = k3d.line(np.array(corner_positions)[edge], name='polyline_edge')\n",
    "        plot+=e\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "plot.display()\n",
    "\n",
    "\n",
    "with open(meta_exp_name+'/'+folder_name+'/'+'graph_initialization_'+curve_extraction_mode+'.html', 'w') as f:\n",
    "    f.write(plot.get_snapshot())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dad3dd9",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('optimizing topological graph')\n",
    "from optimization import *\n",
    "corner_positions, corner_pairs = optimize_topological_graph(corner_positions, corner_pairs, corner_centers, \n",
    "                                                            points, distances, \n",
    "                                                            initial_split_threshold, alpha_fit=1, \n",
    "                                                            alpha_ang=1, corner_alpha_ang=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c48716",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot = k3d.plot()\n",
    "\n",
    "k3d_points = k3d.points(points, point_size=DISPLAY_RES, opacity=0.1, shader='3d', name='sharp_points')\n",
    "plot += k3d_points\n",
    "\n",
    "points_corner_centers = k3d.points(np.array(corner_positions),\n",
    "                                   color=0xFF0000, point_size=DISPLAY_RES, shader='3d', name='polyline_nodes')\n",
    "plot += points_corner_centers\n",
    "\n",
    "for edge in corner_pairs:\n",
    "    try:\n",
    "        e = k3d.line(np.array(corner_positions)[edge], name='polyline_edge')\n",
    "        plot+=e\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "plot.display()\n",
    "\n",
    "\n",
    "with open(meta_exp_name+'/'+folder_name+'/'+'graph_optimization_'+curve_extraction_mode+'.html', 'w') as f:\n",
    "    f.write(plot.get_snapshot())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d4e580",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from optimization import *\n",
    "print('creating paths')\n",
    "_, paths, _, closed_paths, _ = get_paths_and_corners(corner_pairs, corner_positions, corner_centers)\n",
    "\n",
    "\n",
    "print('aabboxing')\n",
    "# aabboxes = create_aabboxes(np.array(corner_positions)[np.array(corner_pairs)])\n",
    "matching = parallel_nearest_point(np.array(corner_positions), np.array(corner_pairs), points)\n",
    "curve_data, curve_distances = recalculate(points, distances, matching, corner_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dd21c6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# curve_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84717ff",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# utils for straight segments detection\n",
    "\n",
    "straight_threshold = 0.977\n",
    "breakpoint_threshold = 0.2\n",
    "\n",
    "path_angles = []\n",
    "for path in paths:\n",
    "    path_pairs = list(zip(path, path[1:]))\n",
    "    current_angles = []\n",
    "    if len(path_pairs) == 1:\n",
    "        path_angles.append(None)\n",
    "        continue\n",
    "    for path_node in range(1,len(path) - 1):\n",
    "        vec1 = np.array(corner_positions)[path[path_node]] - np.array(corner_positions)[path[0]]\n",
    "        vec2 = np.array(corner_positions)[path[-1]] - np.array(corner_positions)[path[path_node]]\n",
    "        vec1 /= np.linalg.norm(vec1)\n",
    "        vec2 /= np.linalg.norm(vec2)\n",
    "        current_angles.append(np.dot(vec1, vec2))\n",
    "    path_angles.append(current_angles)\n",
    "    \n",
    "straight = np.zeros((len(paths)))\n",
    "for i in range(len(paths)):\n",
    "    if len(paths[i]) == 2:\n",
    "        straight[i] = 1\n",
    "    if path_angles[i] is not None:\n",
    "        if (np.array(path_angles[i]) >= straight_threshold).all():\n",
    "            straight[i] = 1\n",
    "\n",
    "path_angles = []\n",
    "for path in paths:\n",
    "    path_pairs = list(zip(path, path[1:]))\n",
    "    current_angles = []\n",
    "    if len(path_pairs) == 1:\n",
    "        path_angles.append(None)\n",
    "        continue\n",
    "    for path_node in range(1,len(path) - 1):\n",
    "        vec1 = np.array(corner_positions)[path[path_node]] - np.array(corner_positions)[path[path_node-1]]\n",
    "        vec2 = np.array(corner_positions)[path[path_node+1]] - np.array(corner_positions)[path[path_node]]\n",
    "        vec1 /= np.linalg.norm(vec1)\n",
    "        vec2 /= np.linalg.norm(vec2)\n",
    "        current_angles.append(np.dot(vec1, vec2))\n",
    "    path_angles.append(current_angles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2e83d3",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "        \n",
    "new_paths = []\n",
    "for i,path in enumerate(paths):\n",
    "    if path_angles[i] is None:\n",
    "        new_paths.append(path)\n",
    "        continue\n",
    "    if straight[i] == 1:\n",
    "        new_paths.append(path)\n",
    "        continue\n",
    "    if (np.array(path_angles[i]) > straight_threshold).any() and (np.array(path_angles[i]) < breakpoint_threshold).any():\n",
    "        breakpoints = []\n",
    "        for j in range(1,len(path)-2):\n",
    "            if (np.array(path_angles[i]) > straight_threshold)[j-1] == (np.array(path_angles[i]) < breakpoint_threshold)[j]:\n",
    "                breakpoints.append((np.array([j-1,j]) * np.logical_not([(np.array(path_angles[i]) > straight_threshold)[j-1], (np.array(path_angles[i]) > breakpoint_threshold)[j]])).sum())\n",
    "        if not breakpoints:\n",
    "            continue\n",
    "        breakpoints = np.unique(breakpoints)\n",
    "        new_paths.append(path[:breakpoints[0]+2])\n",
    "        new_paths.append(path[breakpoints[-1]+1:])\n",
    "        if len(breakpoints) > 1:\n",
    "            for b,c in zip(breakpoints[:-1], breakpoints[1:]):\n",
    "                new_paths.append(path[b+1:c+2])\n",
    "    else:\n",
    "        new_paths.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3933f0f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "paths = new_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0096a8",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def process_paths(paths, corner_pairs, corner_positions, curve_data, curve_distances):\n",
    "new_paths = []\n",
    "path_points = []\n",
    "path_distances = []\n",
    "path_params = []\n",
    "path_knots = []\n",
    "avg_len = np.linalg.norm(np.array(corner_positions)[\n",
    "    np.array(corner_pairs)[:,0]] - np.array(corner_positions)[\n",
    "    np.array(corner_pairs)[:,1]], axis=1).mean()\n",
    "for path in paths:\n",
    "    path_len = len(path)\n",
    "#     print(len(path))\n",
    "    path_pairs = list(zip(path, path[1:]))\n",
    "    current_points = []\n",
    "    current_distances = []\n",
    "    current_params = []\n",
    "    current_knots = []\n",
    "    knot_param = 0\n",
    "    for i,current_pair in enumerate(path_pairs):\n",
    "        endpoints = np.array(corner_positions)[np.array(current_pair)]\n",
    "        ind = np.where(np.isin(corner_pairs, current_pair).sum(1) == 2)[0][0]\n",
    "        if len(path) < 3 and len(curve_data[ind]) < 5:\n",
    "            break\n",
    "        cosines = np.dot(curve_data[ind] - endpoints[0], endpoints[1] - endpoints[0]) / np.linalg.norm(endpoints[1] - endpoints[0])\n",
    "        truncate = np.logical_and(cosines >= 0, cosines <= np.linalg.norm(endpoints[1] - endpoints[0]))\n",
    "\n",
    "        param = cosines[truncate]\n",
    "\n",
    "        argsort = np.argsort(param)\n",
    "        if len(current_params) == 0:\n",
    "            max_param = 0\n",
    "        else:\n",
    "            max_param = max(np.concatenate(current_params).max(),knot_param) \n",
    "        knot_param += np.linalg.norm(endpoints[1] - endpoints[0])\n",
    "        if len(param[argsort]) > 0:\n",
    "            current_params.append(param[argsort] + max_param)\n",
    "            current_points.append(curve_data[ind][truncate][argsort])\n",
    "            current_distances.append(curve_distances[ind][truncate][argsort])\n",
    "    if len(path) < 3 and len(curve_data[ind]) < 5:\n",
    "            continue\n",
    "\n",
    "#     print(len(current_points))\n",
    "    try:\n",
    "        \n",
    "        path_points.append(np.concatenate(current_points))\n",
    "        path_distances.append(np.concatenate(current_distances))\n",
    "        path_params.append(np.concatenate(current_params))\n",
    "        path_knots.append(np.linspace(0,np.concatenate(current_params).max(), max(5, int(len(current_points)/2.))))\n",
    "        new_paths.append(path)\n",
    "    except:\n",
    "        continue\n",
    "#     return path_points, path_distances, path_params, path_knots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae0c1dd",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "paths = new_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e548a4",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_angles = []\n",
    "for path in paths:\n",
    "    path_pairs = list(zip(path, path[1:]))\n",
    "    current_angles = []\n",
    "    if len(path_pairs) == 1:\n",
    "        path_angles.append(None)\n",
    "        continue\n",
    "    for path_node in range(1,len(path) - 1):\n",
    "        vec1 = np.array(corner_positions)[path[path_node]] - np.array(corner_positions)[path[0]]\n",
    "        vec2 = np.array(corner_positions)[path[-1]] - np.array(corner_positions)[path[path_node]]\n",
    "        vec1 /= np.linalg.norm(vec1)\n",
    "        vec2 /= np.linalg.norm(vec2)\n",
    "        current_angles.append(np.dot(vec1, vec2))\n",
    "    path_angles.append(current_angles)\n",
    "    \n",
    "straight = np.zeros((len(paths)))\n",
    "for i in range(len(paths)):\n",
    "    if len(paths[i]) == 2:\n",
    "        straight[i] = 1\n",
    "    if path_angles[i] is not None:\n",
    "        if (np.array(path_angles[i]) >= straight_threshold).all():\n",
    "            straight[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ce8328",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def spacing_weights(linspace):\n",
    "    dists = linspace[1:]-linspace[:-1]\n",
    "    return np.array( [dists[0]*0.5] + \n",
    "                       [(dists[i]+dists[i+1])*0.5 for i in range(0,len(dists)-1)]\n",
    "                    +[dists[-1]*0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2350ddc7",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def err(c, points, distances, u, t, k, endpoints):\n",
    "    c = c.reshape(3,-1)\n",
    "    eval_spline = np.array(splev(u, (t,c,k))).T\n",
    "    proj_distances = np.linalg.norm(points - eval_spline, axis=1)\n",
    "    residual = np.mean(np.abs(proj_distances - distances)) + 0.1*proj_distances.mean()\n",
    "    return residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62084ad",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "inds = []\n",
    "print('start splining')        \n",
    "tcks = []\n",
    "errs = []\n",
    "straight_lines = []\n",
    "closed_tcks = []\n",
    "for i in tqdm(range(len(paths))):\n",
    "    if len(path_params[i]) < 2:\n",
    "        continue\n",
    "    linspace = (path_params[i] - path_knots[i].min()) / (path_knots[i].max() - path_knots[i].min())\n",
    "    where = np.unique(linspace, return_index=True)[1]\n",
    "    linspace = linspace[where]\n",
    "    argsort = np.argsort(linspace)\n",
    "    linspace = linspace[argsort]\n",
    "    path_points_current = path_points[i][where][argsort]\n",
    "    knots = np.sort(((path_knots[i] - path_knots[i].min()) / (path_knots[i].max() - path_knots[i].min())))\n",
    "    knots_as_needed = np.zeros((6+len(knots)))\n",
    "    knots_as_needed[-3:] = 1\n",
    "    knots_as_needed[3:-3] = knots\n",
    "    weights = 1 - path_distances[i][where][argsort]\n",
    "    space_weights = spacing_weights(linspace)\n",
    "    endpoints = np.array(corner_positions)[np.array(paths[i])[[0,-1]]]\n",
    "    if straight[i] == 1:\n",
    "        straight_lines.append(endpoints)\n",
    "        continue\n",
    "    inds.append(i)\n",
    "    try:\n",
    "        (t,c0,k), u = splprep(u=linspace, x=path_points_current.T, w=space_weights, task=-1, t=knots_as_needed)\n",
    "    except:\n",
    "        continue\n",
    "    con = ({'type': 'eq',\n",
    "           'fun': lambda c: (splev(0, (t, c.reshape(3,-1), k))-endpoints[0])\n",
    "           },\n",
    "           {'type': 'eq',\n",
    "           'fun': lambda c: (splev(1, (t, c.reshape(3,-1), k))-endpoints[1])\n",
    "           })\n",
    "    opt = minimize(err, np.array(c0).flatten(), (path_points_current, (1-weights), u, t, k, endpoints),\n",
    "                  constraints=con, tol=1e-10)\n",
    "    copt = opt.x\n",
    "    tcks.append((t, copt.reshape(3,-1), k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44468987",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# new_paths = []\n",
    "path_points = []\n",
    "path_distances = []\n",
    "path_params = []\n",
    "path_knots = []\n",
    "avg_len = np.linalg.norm(np.array(corner_positions)[\n",
    "    np.array(corner_pairs)[:,0]] - np.array(corner_positions)[\n",
    "    np.array(corner_pairs)[:,1]], axis=1).mean()\n",
    "for path in closed_paths:\n",
    "    path_len = len(path)\n",
    "#     print(len(path))\n",
    "    path_pairs = list(zip(path, path[1:]))\n",
    "    current_points = []\n",
    "    current_distances = []\n",
    "    current_params = []\n",
    "    current_knots = []\n",
    "    knot_param = 0\n",
    "    for i,current_pair in enumerate(path_pairs):\n",
    "        endpoints = np.array(corner_positions)[np.array(current_pair)]\n",
    "        ind = np.where(np.isin(corner_pairs, current_pair).sum(1) == 2)[0][0]\n",
    "        if len(path) < 3 and len(curve_data[ind]) < 5:\n",
    "            break\n",
    "        cosines = np.dot(curve_data[ind] - endpoints[0], endpoints[1] - endpoints[0]) / np.linalg.norm(endpoints[1] - endpoints[0])\n",
    "        truncate = np.logical_and(cosines >= 0, cosines <= np.linalg.norm(endpoints[1] - endpoints[0]))\n",
    "\n",
    "        param = cosines[truncate]\n",
    "\n",
    "        argsort = np.argsort(param)\n",
    "        if len(current_params) == 0:\n",
    "            max_param = 0\n",
    "        else:\n",
    "            max_param = max(np.concatenate(current_params).max(),knot_param) \n",
    "        knot_param += np.linalg.norm(endpoints[1] - endpoints[0])\n",
    "        if len(param[argsort]) > 0:\n",
    "            current_params.append(param[argsort] + max_param)\n",
    "            current_points.append(curve_data[ind][truncate][argsort])\n",
    "            current_distances.append(curve_distances[ind][truncate][argsort])\n",
    "    if len(path) < 3 and len(curve_data[ind]) < 5:\n",
    "            continue\n",
    "#     new_paths.append(path)\n",
    "    path_points.append(np.concatenate(current_points))\n",
    "    path_distances.append(np.concatenate(current_distances))\n",
    "    path_params.append(np.concatenate(current_params))\n",
    "    path_knots.append(np.linspace(0,np.concatenate(current_params).max(),6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fcf878",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if len(closed_paths) > 0:\n",
    "    print('splining closed curves')\n",
    "    \n",
    "    for i in tqdm(range(len(closed_paths))):\n",
    "        linspace = (path_params[i] - path_knots[i].min()) / (path_knots[i].max() - path_knots[i].min())\n",
    "        where = np.unique(linspace, return_index=True)[1]\n",
    "        linspace = linspace[where]\n",
    "        argsort = np.argsort(linspace)\n",
    "        linspace = linspace[argsort]\n",
    "        path_points_current = path_points[i][where][argsort]\n",
    "        knots = np.sort(((path_knots[i] - path_knots[i].min()) / (path_knots[i].max() - path_knots[i].min())))\n",
    "        knots_as_needed = np.zeros((6+len(knots)))\n",
    "        knots_as_needed[-3:] = 1\n",
    "        knots_as_needed[3:-3] = knots\n",
    "        weights = 1 - path_distances[i][where][argsort]\n",
    "        space_weights = spacing_weights(linspace)\n",
    "\n",
    "        (t,c0,k), u = splprep(u=linspace, x=path_points_current.T, w=space_weights, task=-1, t=knots_as_needed)\n",
    "        con = ({'type': 'eq',\n",
    "               'fun': lambda c: (np.array(splev(0, (t, c.reshape(3,-1), k)))-np.array(splev(1, (t, c.reshape(3,-1), k))))\n",
    "               },\n",
    "               {'type': 'eq',\n",
    "               'fun': lambda c: (np.sum(np.abs(np.array(splev(0, (t, c.reshape(3,-1), k), der=1))-np.array(splev(1, (t, c.reshape(3,-1), k), der=1)))))\n",
    "               }\n",
    "              )\n",
    "        opt = minimize(err, np.array(c0).flatten(), (path_points_current, 1-weights, u, t, k, endpoints),\n",
    "                      constraints=con)\n",
    "        copt = opt.x\n",
    "        closed_tcks.append((t, copt.reshape(3,-1), k))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03897ef1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# closed_tcks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae81212",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot = k3d.plot()\n",
    "\n",
    "cmap=k3d.colormaps.matplotlib_color_maps.plasma_r\n",
    "colors = k3d.helpers.map_colors(\n",
    "                distances, cmap, [distances.min(), distances.max()]\n",
    "            ).astype(np.uint32)\n",
    "\n",
    "k3d_points = k3d.points(points, point_size=DISPLAY_RES, opacity=0.1, shader='3d', name='sharp_points')\n",
    "plot += k3d_points\n",
    "\n",
    "for i in range(len(straight_lines)):\n",
    "    spline = k3d.line(straight_lines[i], color=0xff0000, width=DISPLAY_RES-0.015, name='line')\n",
    "    plot += spline\n",
    "\n",
    "for i in range(len(tcks)):\n",
    "    spline = k3d.points(np.array(splev(np.linspace(0,1,2500), tcks[i])).T, color=0xff0000, point_size=DISPLAY_RES-0.015, shader='flat', name='default')\n",
    "    plot += spline\n",
    "    \n",
    "for i in range(len(closed_tcks)):    \n",
    "    spline = k3d.points(np.array(splev(np.linspace(0,1,2500), closed_tcks[i])).T, color=0xff0000, point_size=DISPLAY_RES-0.015, shader='flat', name='spline')\n",
    "    plot += spline\n",
    "\n",
    "plot.display()\n",
    "\n",
    "with open(meta_exp_name+'/'+folder_name+'/'+'vectorization_'+curve_extraction_mode+'.html', 'w') as f:\n",
    "    f.write(plot.get_snapshot())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0455a0b9",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "def write_results(folder_name,straight_lines,tcks,closed_tcks):\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "    with open(folder_name + '/vectorization_line.txt', \"wb\") as fp:   #Pickling\n",
    "        pickle.dump(straight_lines, fp)\n",
    "    with open(folder_name+'/vectorization_open_curves.txt', \"wb\") as fp:   #Pickling\n",
    "        pickle.dump(tcks, fp)\n",
    "    with open(folder_name+'/vectorization_closed_curves.txt', \"wb\") as fp:   #Pickling\n",
    "        pickle.dump(closed_tcks, fp)\n",
    "        \n",
    "def read_results(folder_name):\n",
    "    with open(folder_name + '/vectorization_line.txt', \"rb\") as fp:   # Unpickling\n",
    "        straight_lines = pickle.load(fp)\n",
    "    with open(folder_name+'/vectorization_open_curves.txt', \"rb\") as fp:   #Pickling\n",
    "        tcks = pickle.load(fp)\n",
    "    with open(folder_name+'/vectorization_closed_curves.txt', \"rb\") as fp:   #Pickling\n",
    "        closed_tcks = pickle.load(fp)\n",
    "    return straight_lines,tcks,closed_tcks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54b1ac9",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "write_results(meta_exp_name+'/'+folder_name+'/raw_vectorization/',straight_lines,tcks,closed_tcks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61069822",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Metric calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5763b971",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def loss_calculating(pred_sampling_small,inp_sampling_small,blur=0.05):\n",
    "    loss = SamplesLoss(loss=\"sinkhorn\",backend = \"tensorized\",blur=blur)\n",
    "    sink_ls = loss(pred_sampling_small.cuda(), inp_sampling_small.cuda())\n",
    "\n",
    "    loss = SamplesLoss(loss=\"energy\",backend = \"tensorized\",blur=blur)\n",
    "    en_ls = loss(pred_sampling_small.cuda(), inp_sampling_small.cuda())\n",
    "\n",
    "    loss = SamplesLoss(loss=\"gaussian\",backend = \"tensorized\",blur=blur)\n",
    "    gaus_ls = loss(pred_sampling_small.cuda(), inp_sampling_small.cuda())\n",
    "\n",
    "    loss = SamplesLoss(loss=\"laplacian\",backend = \"tensorized\",blur=blur)\n",
    "    lap_ls = loss(pred_sampling_small.cuda(), inp_sampling_small.cuda())\n",
    "\n",
    "    return sink_ls, en_ls, gaus_ls, lap_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd73e3a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def write_to_file(folder_name, file_name, CD_gt_to_pred, CD_pred_to_gt,chamf_l, sink_ls, en_ls, gaus_ls, lap_ls):\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "    with open(folder_name +'/'+'metrics_'+ file_name + curve_extraction_mode + '.txt', 'w') as f:\n",
    "        f.write('CD_gt_to_pred')\n",
    "        f.write('\\n')\n",
    "        f.write(str(CD_gt_to_pred.item()))\n",
    "        f.write('\\n')\n",
    "        f.write('CD_pred_to_gt')\n",
    "        f.write('\\n')\n",
    "        f.write(str(CD_pred_to_gt.item()))\n",
    "        f.write('\\n')\n",
    "        f.write('Chamfer loss')\n",
    "        f.write('\\n')\n",
    "        f.write(str(chamf_l))\n",
    "        f.write('\\n')\n",
    "        f.write('Energy loss')\n",
    "        f.write('\\n')\n",
    "        f.write(str(en_ls.item()))\n",
    "        f.write('\\n')\n",
    "        f.write('Sinkhorn loss')\n",
    "        f.write('\\n')\n",
    "        f.write(str(sink_ls.item()))\n",
    "        f.write('\\n')\n",
    "        f.write('Gaussian loss')\n",
    "        f.write('\\n')\n",
    "        f.write(str(gaus_ls.item()))\n",
    "        f.write('\\n')\n",
    "        f.write('Laplassian loss')\n",
    "        f.write('\\n')\n",
    "        f.write(str(lap_ls.item()))\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eeb0287",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "NO_GT=False\n",
    "# load GT curves as segments\n",
    "gt_edges = []\n",
    "if os.path.exists('parametric_labeling/{file}__parametric.txt'.format(file=_id[9:])):\n",
    "    with open('parametric_labeling/{file}__parametric.txt'.format(file=_id[9:])) as f:\n",
    "        for line in f:\n",
    "            curve_id, curve_type, edges = line.split(' ', maxsplit=2)\n",
    "            gt_edges.append(np.array([float(v) for v in edges.split()]).reshape((-1, 2, 3)))\n",
    "else:\n",
    "    NO_GT = True\n",
    "    print('No GT!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdf1a1f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sample GT edges\n",
    "if not NO_GT:\n",
    "    gt_sampling = []\n",
    "    for edge in np.concatenate(gt_edges):\n",
    "        num = int(np.linalg.norm(edge[1] - edge[0]) // 0.001)\n",
    "        if num > 0:\n",
    "            linspace = np.linspace(0, 1, num)\n",
    "        #     break\n",
    "            gt_sampling.append(linspace[:,None] * edge[0] + (1 - linspace)[:,None] * edge[1])\n",
    "        else:\n",
    "            gt_sampling.append(edge)\n",
    "    gt_sampling = np.concatenate(gt_sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce668db8",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pred_sampling_points(straight_lines,tcks,closed_tcks):\n",
    "    pred_sampling = []\n",
    "\n",
    "    for i in range(len(straight_lines)):\n",
    "        edge = straight_lines[i]\n",
    "        num = int(np.linalg.norm(edge[1] - edge[0]) // 0.001)\n",
    "        if num > 0:\n",
    "            linspace = np.linspace(0, 1, num)\n",
    "        #     break\n",
    "            pred_sampling.append(linspace[:,None] * edge[0] + (1 - linspace)[:,None] * edge[1])\n",
    "        else:\n",
    "            pred_sampling.append(edge)\n",
    "\n",
    "    for i in range(len(tcks)):\n",
    "        pred_sampling.append(np.array(splev(np.linspace(0,1,5000), tcks[i])).T)\n",
    "\n",
    "    for i in range(len(closed_tcks)):    \n",
    "        pred_sampling.append(np.array(splev(np.linspace(0,1,5000), closed_tcks[i])).T)\n",
    "    return pred_sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37589056",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def metric_calculation(pred_sampling,gt_sampling,blur=0.05):\n",
    "  \n",
    "    CD_gt_to_pred = (cKDTree(pred_sampling).query(gt_sampling, 1)[0]**2).mean()\n",
    "    CD_pred_to_gt = (cKDTree(gt_sampling).query(pred_sampling, 1)[0]**2).mean()\n",
    "    \n",
    "    pred_sampling = torch.tensor(pred_sampling)[None]\n",
    "    gt_sampling = torch.tensor(gt_sampling)[None]\n",
    "    chamf_l = chamfer_distance(pred_sampling.clone().cuda().detach().float(), gt_sampling.clone().cuda().detach().float())\n",
    "    \n",
    "    if pred_sampling[0].shape[0]>10000:\n",
    "        sub_idx = pcu.downsample_point_cloud_poisson_disk(np.array(pred_sampling[0]), num_samples=10000)\n",
    "        # Use the indices to get the sample positions and normals\n",
    "        pred_sampling_small = pred_sampling[:,sub_idx]\n",
    "    else:\n",
    "        pred_sampling_small =  pred_sampling\n",
    "    \n",
    "    if gt_sampling[0].shape[0]>10000:\n",
    "        sub_idx = pcu.downsample_point_cloud_poisson_disk(np.array(gt_sampling[0]), num_samples=10000)\n",
    "        # Use the indices to get the sample positions and normals\n",
    "        gt_sampling_small = gt_sampling[:,sub_idx]\n",
    "    else:\n",
    "        gt_sampling_small = gt_sampling\n",
    "    sink_ls, en_ls, gaus_ls, lap_ls = loss_calculating(pred_sampling_small,gt_sampling_small,blur=blur)\n",
    "    return CD_gt_to_pred, CD_pred_to_gt,chamf_l, sink_ls, en_ls, gaus_ls, lap_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edb3690",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_sampling = pred_sampling_points(straight_lines,tcks,closed_tcks)\n",
    "pred_sampling = np.concatenate(pred_sampling)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706a9aaa",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not NO_GT:\n",
    "    CD_gt_to_pred, CD_pred_to_gt,chamf_l, sink_ls, en_ls, gaus_ls, lap_ls  = metric_calculation(pred_sampling,gt_sampling)\n",
    "    _, _,chamf_l, sink_ls_bl02, en_ls_bl02, gaus_ls_bl02, lap_ls_bl02  = metric_calculation(pred_sampling,gt_sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922f8c0d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not NO_GT:\n",
    "    write_to_file(meta_exp_name+'/'+folder_name+'/metrics/','raw_vectorization',CD_gt_to_pred, CD_pred_to_gt,chamf_l, sink_ls, en_ls, gaus_ls, lap_ls)\n",
    "    df = pd.DataFrame([[folder_name,CD_gt_to_pred.item(),CD_pred_to_gt.item(),chamf_l[0].item(),\n",
    "                        en_ls.item(),sink_ls.item(),\n",
    "                        gaus_ls.item(),lap_ls.item(), en_ls_bl02.item(),sink_ls_bl02.item(),\n",
    "                        gaus_ls_bl02.item(),lap_ls_bl02.item()]],\n",
    "                      index=None,  columns=['Name','CD_gt_to_pred','CD_pred_to_gt','Chamfer_loss',\n",
    "                                            'Energy_loss','Sinkhorn_loss','Gaussian_loss'\n",
    "                                            ,'Laplassian_loss','Energy_loss_blure02','Sinkhorn_loss_blure02','Gaussian_loss_blure02'\n",
    "                                            ,'Laplassian_loss_blure02'])\n",
    "    if not os.path.exists(meta_exp_name+'/metrics/'):\n",
    "        os.makedirs(meta_exp_name+'/metrics/')\n",
    "    \n",
    "    if not os.path.exists(meta_exp_name+'/metrics/'+meta_exp_name + '_raw_vectorization_metrics.csv'):\n",
    "        df.to_csv(meta_exp_name+'/metrics/'+meta_exp_name + '_raw_vectorization_metrics.csv', index = False,sep=';')\n",
    "    else:\n",
    "        df.to_csv(meta_exp_name+'/metrics/'+meta_exp_name + '_raw_vectorization_metrics.csv', mode='a', header=None, index = False,sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798d1c97",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save this also\n",
    "if not NO_GT:\n",
    "    plot = k3d.plot()\n",
    "\n",
    "    cmap=k3d.colormaps.matplotlib_color_maps.plasma_r\n",
    "    colors = k3d.helpers.map_colors(\n",
    "                    distances, cmap, [distances.min(), distances.max()]\n",
    "                ).astype(np.uint32)\n",
    "\n",
    "    k3d_points = k3d.points(pred_sampling, point_size=DISPLAY_RES, opacity=0.1, shader='3d', name='sharp_points', color=0xff0000)\n",
    "    plot += k3d_points\n",
    "\n",
    "    k3d_points = k3d.points(gt_sampling, point_size=DISPLAY_RES, opacity=0.1, shader='3d', name='sharp_points')\n",
    "    plot += k3d_points\n",
    "\n",
    "    plot.display()\n",
    "    with open(meta_exp_name+'/'+folder_name+'/'+'vectorization_with_GT_'+curve_extraction_mode+'.html', 'w') as f:\n",
    "        f.write(plot.get_snapshot())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c773a6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Caclulating distance between prediction and input point cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b24d6a1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CD_gt_to_pred_mm, CD_pred_to_gt_mm, chamf_l_mm, sink_ls_mm, en_ls_mm, gaus_ls_mm, lap_ls_mm  = metric_calculation(pred_sampling,points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c2ccf5",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "write_to_file(meta_exp_name+'/'+folder_name+'/metrics/','chosing_raw_vectorization',CD_gt_to_pred_mm, CD_pred_to_gt_mm, chamf_l_mm, sink_ls_mm, en_ls_mm, gaus_ls_mm, lap_ls_mm)\n",
    "\n",
    "df = pd.DataFrame([[folder_name,chamf_l_mm[0].item(),en_ls_mm.item(),sink_ls_mm.item(),gaus_ls_mm.item(),lap_ls_mm.item()]],\n",
    "                  index=None,  columns=['Name','Chamfer_loss','Energy_loss','Sinkhorn_loss','Gaussian_loss','Laplassian_loss'])\n",
    "\n",
    "if not os.path.exists(meta_exp_name+'/metrics/'):\n",
    "    os.makedirs(meta_exp_name+'/metrics/')\n",
    "    \n",
    "if not os.path.exists(meta_exp_name+'/metrics/' + meta_exp_name + '_chosing_raw_vectorization_metrics.csv'):\n",
    "    df.to_csv(meta_exp_name+'/metrics/'+meta_exp_name + '_chosing_raw_vectorization_metrics.csv', index = False,sep=';')\n",
    "else:\n",
    "    df.to_csv(meta_exp_name+'/metrics/'+meta_exp_name + '_chosing_raw_vectorization_metrics.csv', mode='a', header=None, index = False,sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b39734",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Pretification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b944c23",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# straight_lines,tcks,closed_tcks = read_results(meta_exp_name+'/'+folder_name+'/raw_vectorization/')\n",
    "# cut_metric ='fscore'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873f8743",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#0.00001\n",
    "\n",
    "def fscorebeta(dist1, dist2, threshold=0.005, beta = 0.5):\n",
    "    # From here https://github.com/ThibaultGROUEIX/ChamferDistancePytorch/blob/master/fscore.py\n",
    "    \"\"\"\n",
    "    Calculates the F-score between two point clouds with the corresponding threshold value.\n",
    "    \n",
    "    :param dist1: Batch, N-Points\n",
    "    :param dist2: Batch, N-Points\n",
    "    :param th: float\n",
    "    :return: fscore, precision, recall\n",
    "    \"\"\"\n",
    "    # NB : In this depo, dist1 and dist2 are squared pointcloud euclidean distances, so you should adapt the threshold accordingly.\n",
    "    precision_1 = torch.mean((dist1 < threshold).float(), dim=1)\n",
    "    precision_2 = torch.mean((dist2 < threshold).float(), dim=1)\n",
    "    fscore = (1 + beta*beta) * precision_1 * precision_2 / (beta*beta*precision_1 + precision_2)\n",
    "    fscore[torch.isnan(fscore)] = 0\n",
    "    return fscore, precision_1, precision_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45369f1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_sampling = pred_sampling_points(straight_lines,tcks,closed_tcks)\n",
    "pred_sampling = np.concatenate(pred_sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb188059",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if cut_metric =='fscore' or cut_metric =='precision':\n",
    "    CD_gt_to_pred = (cKDTree(pred_sampling).query(points, 1)[0]**2)\n",
    "    CD_pred_to_gt = (cKDTree(points).query(pred_sampling, 1)[0]**2)\n",
    "else:\n",
    "    pred_sampling = torch.tensor(pred_sampling)[None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1769f3c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if cut_metric =='fscore'  or cut_metric =='precision':\n",
    "    fsc_max,pred_1_max,pred_2_max = fscorebeta(torch.tensor(CD_pred_to_gt)[None],torch.tensor(CD_gt_to_pred)[None]) \n",
    "elif cut_metric == 'chamfer_dist':\n",
    "    ch_dst_min = chamf_l_mm[0].item()\n",
    "elif cut_metric == 'sinkhorn':\n",
    "    sink_dst_min = sink_ls_mm.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62161cff",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "it=0\n",
    "curve_cuted =0\n",
    "while it<len(straight_lines)+len(tcks)+len(closed_tcks):\n",
    "    pred_sampling = []\n",
    "    tks =  copy.deepcopy(tcks)\n",
    "    str_lines = copy.deepcopy(straight_lines)\n",
    "    closed_tks = copy.deepcopy(closed_tcks)\n",
    "    if it < len(straight_lines):\n",
    "        str_lines.pop(it)\n",
    "    elif it < len(straight_lines)+len(tcks):\n",
    "        tks.pop(it-len(straight_lines))   \n",
    "    else:\n",
    "        closed_tks.pop(it-len(straight_lines)-len(tcks))\n",
    "    \n",
    "    if len(str_lines)+len(tks)+len(closed_tks)==0:\n",
    "        straight_lines = copy.deepcopy(str_lines)\n",
    "        tcks = copy.deepcopy(tks)\n",
    "        closed_tcks = copy.deepcopy(closed_tks)\n",
    "        curve_cuted+=1\n",
    "        break\n",
    "        \n",
    "    pred_sampling = pred_sampling_points(str_lines,tks,closed_tks)\n",
    "    pred_sampling = np.concatenate(pred_sampling)\n",
    "    \n",
    "    if cut_metric =='fscore' or cut_metric =='precision':\n",
    "        CD_gt_to_pred = (cKDTree(pred_sampling).query(points, 1)[0]**2)\n",
    "        CD_pred_to_gt = (cKDTree(points).query(pred_sampling, 1)[0]**2)\n",
    "        fsc,pred_1,pred_2  = fscorebeta(torch.tensor(CD_pred_to_gt)[None],torch.tensor(CD_gt_to_pred)[None]) \n",
    "        print(fsc,pred_1,pred_2)\n",
    "        if cut_metric =='precision':\n",
    "            if pred_1 > pred_1_max:\n",
    "                fsc_max = fsc\n",
    "                pred_1_max = pred_1\n",
    "                pred_2_max = pred_2\n",
    "                straight_lines = copy.deepcopy(str_lines)\n",
    "                tcks = copy.deepcopy(tks)\n",
    "                closed_tcks = copy.deepcopy(closed_tks)\n",
    "                curve_cuted+=1\n",
    "            else:\n",
    "                it+=1\n",
    "        else:\n",
    "            if fsc > fsc_max:\n",
    "                fsc_max = fsc\n",
    "                pred_2_max = pred_2\n",
    "                pred_1_max = pred_1\n",
    "                straight_lines = copy.deepcopy(str_lines)\n",
    "                tcks = copy.deepcopy(tks)\n",
    "                closed_tcks = copy.deepcopy(closed_tks)\n",
    "                curve_cuted+=1\n",
    "            else:\n",
    "                it+=1\n",
    "    elif cut_metric == 'chamfer_dist':\n",
    "        pred_sampling = torch.tensor(pred_sampling)[None]\n",
    "        chamf_l_mm = chamfer_distance(pred_sampling.clone().cuda().detach().float(), torch.tensor(points)[None].clone().cuda().detach().float())\n",
    "        if chamf_l_mm[0].item()<=ch_dst_min:\n",
    "            ch_dst_min = chamf_l_mm[0].item()\n",
    "            straight_lines = copy.deepcopy(str_lines)\n",
    "            tcks = copy.deepcopy(tks)\n",
    "            closed_tcks = copy.deepcopy(closed_tks)\n",
    "            curve_cuted+=1\n",
    "        else:\n",
    "            it+=1\n",
    "    elif cut_metric == 'sinkhorn':\n",
    "        pred_sampling = torch.tensor(pred_sampling)[None]\n",
    "        if pred_sampling[0].shape[0]>10000:\n",
    "            sub_idx = pcu.downsample_point_cloud_poisson_disk(np.array(pred_sampling[0]), num_samples=10000)\n",
    "            pred_sampling_small = pred_sampling[:,sub_idx]\n",
    "        else:\n",
    "            pred_sampling_small =  pred_sampling\n",
    "        loss = SamplesLoss(loss=\"sinkhorn\",backend = \"tensorized\")\n",
    "        sink_ls_mm = loss(pred_sampling_small.cuda(), inp_sampling_small.cuda())\n",
    "        if  sink_ls_mm.item()<=sink_dst_min:\n",
    "            sink_dst_min= sink_ls_mm.item()\n",
    "            straight_lines = copy.deepcopy(str_lines)\n",
    "            tcks = copy.deepcopy(tks)\n",
    "            closed_tcks = copy.deepcopy(closed_tks)\n",
    "            curve_cuted+=1\n",
    "        else:\n",
    "            it+=1\n",
    "print('Get rid of:', curve_cuted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc644673",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot = k3d.plot()\n",
    "\n",
    "cmap=k3d.colormaps.matplotlib_color_maps.plasma_r\n",
    "colors = k3d.helpers.map_colors(\n",
    "                distances, cmap, [distances.min(), distances.max()]\n",
    "            ).astype(np.uint32)\n",
    "\n",
    "k3d_points = k3d.points(points, point_size=DISPLAY_RES, opacity=0.1, shader='3d', name='sharp_points')\n",
    "plot += k3d_points\n",
    "\n",
    "for i in range(len(straight_lines)):\n",
    "    spline = k3d.line(straight_lines[i], color=0xff0000, width=DISPLAY_RES-0.015, name='line')\n",
    "    plot += spline\n",
    "\n",
    "for i in range(len(tcks)):\n",
    "    spline = k3d.points(np.array(splev(np.linspace(0,1,2500), tcks[i])).T, color=0xff0000, point_size=DISPLAY_RES-0.015, shader='flat', name='default')\n",
    "    plot += spline\n",
    "    \n",
    "for i in range(len(closed_tcks)):    \n",
    "    spline = k3d.points(np.array(splev(np.linspace(0,1,2500), closed_tcks[i])).T, color=0xff0000, point_size=DISPLAY_RES-0.015, shader='flat', name='spline')\n",
    "    plot += spline\n",
    "\n",
    "plot.display()\n",
    "\n",
    "with open(meta_exp_name+'/'+folder_name+'/'+'pretified_vectorization_'+curve_extraction_mode+'.html', 'w') as f:\n",
    "    f.write(plot.get_snapshot())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d464926",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Writing metrics and curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87dba2ba",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sample GT edges\n",
    "if not NO_GT:\n",
    "    gt_sampling = []\n",
    "    for edge in np.concatenate(gt_edges):\n",
    "        num = int(np.linalg.norm(edge[1] - edge[0]) // 0.001)\n",
    "        if num > 0:\n",
    "            linspace = np.linspace(0, 1, num)\n",
    "        #     break\n",
    "            gt_sampling.append(linspace[:,None] * edge[0] + (1 - linspace)[:,None] * edge[1])\n",
    "        else:\n",
    "            gt_sampling.append(edge)\n",
    "    gt_sampling = np.concatenate(gt_sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40516136",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "write_results(meta_exp_name+'/'+folder_name+'/pretified_vectorization/',straight_lines,tcks,closed_tcks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccfdc7a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_sampling = pred_sampling_points(straight_lines,tcks,closed_tcks)\n",
    "pred_sampling = np.concatenate(pred_sampling)\n",
    "if not NO_GT:\n",
    "    CD_gt_to_pred, CD_pred_to_gt,chamf_l, sink_ls, en_ls, gaus_ls, lap_ls  = metric_calculation(pred_sampling,gt_sampling)\n",
    "    _, _,chamf_l, sink_ls_bl02, en_ls_bl02, gaus_ls_bl02, lap_ls_bl02  = metric_calculation(pred_sampling,gt_sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748c31e5",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not NO_GT:\n",
    "    write_to_file(meta_exp_name+'/'+folder_name+'/metrics/','pretified_vectorization',CD_gt_to_pred, CD_pred_to_gt,chamf_l, sink_ls, en_ls, gaus_ls, lap_ls)\n",
    "    df = pd.DataFrame([[folder_name,CD_gt_to_pred.item(),CD_pred_to_gt.item(),chamf_l[0].item(),\n",
    "                        en_ls.item(),sink_ls.item(),\n",
    "                        gaus_ls.item(),lap_ls.item(), en_ls_bl02.item(),sink_ls_bl02.item(),\n",
    "                        gaus_ls_bl02.item(),lap_ls_bl02.item()]],\n",
    "                      index=None,  columns=['Name','CD_gt_to_pred','CD_pred_to_gt','Chamfer_loss',\n",
    "                                            'Energy_loss','Sinkhorn_loss','Gaussian_loss'\n",
    "                                            ,'Laplassian_loss','Energy_loss_blure02','Sinkhorn_loss_blure02','Gaussian_loss_blure02'\n",
    "                                            ,'Laplassian_loss_blure02'])\n",
    "    if not os.path.exists(meta_exp_name+'/metrics/'):\n",
    "        os.makedirs(meta_exp_name+'/metrics/')\n",
    "    \n",
    "    if not os.path.exists(meta_exp_name+'/metrics/'+meta_exp_name + '_pretified_vectorization_metrics.csv'):\n",
    "        df.to_csv(meta_exp_name+'/metrics/'+meta_exp_name + '_pretified_vectorization_metrics.csv', index = False,sep=';')\n",
    "    else:\n",
    "        df.to_csv(meta_exp_name+'/metrics/'+meta_exp_name + '_pretified_vectorization_metrics.csv', mode='a', header=None, index = False,sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570dae42",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CD_gt_to_pred_mm, CD_pred_to_gt_mm, chamf_l_mm, sink_ls_mm, en_ls_mm, gaus_ls_mm, lap_ls_mm  = metric_calculation(pred_sampling,points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a38d35",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "write_to_file(meta_exp_name+'/'+folder_name+'/metrics/','chosing_pretified_vectorization',CD_gt_to_pred_mm, CD_pred_to_gt_mm, chamf_l_mm, sink_ls_mm, en_ls_mm, gaus_ls_mm, lap_ls_mm)\n",
    "\n",
    "df = pd.DataFrame([[folder_name,chamf_l_mm[0].item(),en_ls_mm.item(),sink_ls_mm.item(),gaus_ls_mm.item(),lap_ls_mm.item()]],\n",
    "                  index=None,  columns=['Name','Chamfer_loss','Energy_loss','Sinkhorn_loss','Gaussian_loss','Laplassian_loss'])\n",
    "\n",
    "if not os.path.exists(meta_exp_name+'/metrics/'):\n",
    "    os.makedirs(meta_exp_name+'/metrics/')\n",
    "    \n",
    "if not os.path.exists(meta_exp_name+'/metrics/' + meta_exp_name + '_chosing_pretified_vectorization_metrics.csv'):\n",
    "    df.to_csv(meta_exp_name+'/metrics/'+meta_exp_name + '_chosing_pretified_vectorization_metrics.csv', index = False,sep=';')\n",
    "else:\n",
    "    df.to_csv(meta_exp_name+'/metrics/'+meta_exp_name + '_chosing_pretified_vectorization_metrics.csv', mode='a', header=None, index = False,sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fa081f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Small lines cutting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2e3fd0",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def curve_length(curve,devision_points_count=200):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        curve - curve in as in scipy splprep\n",
    "        devision_points_count - the amount of points on curve\n",
    "    output:\n",
    "        length of the curve\n",
    "    \"\"\"\n",
    "    ar = np.array(splev(np.linspace(0,1,devision_points_count), curve)).T\n",
    "    return np.sum(np.sqrt(np.sum((ar[:-1]-ar[1:])**2,axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d784ea",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Adding curves endpoints as lines for constructing connection graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8b7207",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "str_lines = copy.deepcopy(straight_lines) \n",
    "for it in tcks:\n",
    "    ar = np.array(splev(np.linspace(0,1,2), it)).T\n",
    "    str_lines.append(ar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329da51d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Constructing graph where vertex are primitives and edges between vertex exist if primitives share endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9f4d6c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from(range(len(str_lines)))\n",
    "\n",
    "for i,line in enumerate(str_lines):\n",
    "        for j,line_2 in  enumerate(str_lines):\n",
    "            if j>i:\n",
    "                if np.allclose(line[0],line_2[0]) or np.allclose(line[0],line_2[1]) or np.allclose(line[1],line_2[0]) or np.allclose(line[1],line_2[1]):\n",
    "                    G.add_edge(i,j)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daff2e9d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Getting connected subgraphs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62f3b74",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "S = [G.subgraph(c).copy() for c in nx.connected_components(G)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6616846",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Calculating for each length of  conected segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bd96fa",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "gr = []\n",
    "for sg in S:\n",
    "    gr_len=0\n",
    "    for node in sg.nodes():\n",
    "        if node<len(straight_lines):\n",
    "            #for lines\n",
    "            gr_len+=np.sqrt(np.sum((straight_lines[node][0]-straight_lines[node][1])**2))\n",
    "        else:\n",
    "            #for curves\n",
    "            gr_len+=curve_length(tcks[node-len(straight_lines)])\n",
    "    gr.append(gr_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c29786",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Getting read of small curves and lines which are in small component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6071ab",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "str_line_copy = []\n",
    "tcks_copy = []\n",
    "for i,sg in enumerate(S):\n",
    "    if gr[i]<small_lines_clip_primitives_length and len(sg.nodes)<=small_lines_clip_primitive_number:\n",
    "        continue\n",
    "    for node in sg.nodes():\n",
    "        if node<len(straight_lines):\n",
    "            #for lines\n",
    "            str_line_copy.append(straight_lines[node])\n",
    "        else:\n",
    "            #for curves\n",
    "            tcks_copy.append(tcks[node-len(straight_lines)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61098e39",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Constructing result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a9cb4a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "straight_lines = str_line_copy\n",
    "tcks = tcks_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d54c209",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot = k3d.plot()\n",
    "\n",
    "cmap=k3d.colormaps.matplotlib_color_maps.plasma_r\n",
    "colors = k3d.helpers.map_colors(\n",
    "                distances, cmap, [distances.min(), distances.max()]\n",
    "            ).astype(np.uint32)\n",
    "\n",
    "k3d_points = k3d.points(points, point_size=DISPLAY_RES, opacity=0.1, shader='3d', name='sharp_points')\n",
    "plot += k3d_points\n",
    "\n",
    "for i in range(len(straight_lines)):\n",
    "    spline = k3d.line(str_line_copy[i], color=0xff0000, width=DISPLAY_RES-0.015, name='line')\n",
    "    plot += spline\n",
    "\n",
    "for i in range(len(tcks)):\n",
    "    spline = k3d.points(np.array(splev(np.linspace(0,1,2500), tcks[i])).T, color=0xff0000, point_size=DISPLAY_RES-0.015, shader='flat', name='default')\n",
    "    plot += spline\n",
    "    \n",
    "for i in range(len(closed_tcks)):    \n",
    "    spline = k3d.points(np.array(splev(np.linspace(0,1,2500), closed_tcks[i])).T, color=0xff0000, point_size=DISPLAY_RES-0.015, shader='flat', name='spline')\n",
    "    plot += spline\n",
    "\n",
    "plot.display()\n",
    "\n",
    "with open(meta_exp_name+'/'+folder_name+'/'+'pretified_vectorization_final_'+curve_extraction_mode+'.html', 'w') as f:\n",
    "    f.write(plot.get_snapshot())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589d3ef5",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Writing metrics and curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c87f2f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sample GT edges\n",
    "if not NO_GT:\n",
    "    gt_sampling = []\n",
    "    for edge in np.concatenate(gt_edges):\n",
    "        num = int(np.linalg.norm(edge[1] - edge[0]) // 0.001)\n",
    "        if num > 0:\n",
    "            linspace = np.linspace(0, 1, num)\n",
    "        #     break\n",
    "            gt_sampling.append(linspace[:,None] * edge[0] + (1 - linspace)[:,None] * edge[1])\n",
    "        else:\n",
    "            gt_sampling.append(edge)\n",
    "    gt_sampling = np.concatenate(gt_sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccc0a8e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "write_results(meta_exp_name+'/'+folder_name+'/pretified_vectorization_final/',str_line_copy,tcks,closed_tcks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9417eed",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_sampling = pred_sampling_points(straight_lines,tcks,closed_tcks)\n",
    "pred_sampling = np.concatenate(pred_sampling)\n",
    "if not NO_GT:\n",
    "    CD_gt_to_pred, CD_pred_to_gt,chamf_l, sink_ls, en_ls, gaus_ls, lap_ls  = metric_calculation(pred_sampling,gt_sampling)\n",
    "    _, _,chamf_l, sink_ls_bl02, en_ls_bl02, gaus_ls_bl02, lap_ls_bl02  = metric_calculation(pred_sampling,gt_sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b3a373",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not NO_GT:\n",
    "    write_to_file(meta_exp_name+'/'+folder_name+'/metrics/','pretified_vectorization_final',CD_gt_to_pred, CD_pred_to_gt,chamf_l, sink_ls, en_ls, gaus_ls, lap_ls)\n",
    "    df = pd.DataFrame([[folder_name,CD_gt_to_pred.item(),CD_pred_to_gt.item(),chamf_l[0].item(),\n",
    "                        en_ls.item(),sink_ls.item(),\n",
    "                        gaus_ls.item(),lap_ls.item(), en_ls_bl02.item(),sink_ls_bl02.item(),\n",
    "                        gaus_ls_bl02.item(),lap_ls_bl02.item()]],\n",
    "                      index=None,  columns=['Name','CD_gt_to_pred','CD_pred_to_gt','Chamfer_loss',\n",
    "                                            'Energy_loss','Sinkhorn_loss','Gaussian_loss'\n",
    "                                            ,'Laplassian_loss','Energy_loss_blure02','Sinkhorn_loss_blure02','Gaussian_loss_blure02'\n",
    "                                            ,'Laplassian_loss_blure02'])\n",
    "    if not os.path.exists(meta_exp_name+'/metrics/'):\n",
    "        os.makedirs(meta_exp_name+'/metrics/')\n",
    "    \n",
    "    if not os.path.exists(meta_exp_name+'/metrics/'+meta_exp_name + '_pretified_vectorization_final_metrics.csv'):\n",
    "        df.to_csv(meta_exp_name+'/metrics/'+meta_exp_name + '_pretified_vectorization_final_metrics.csv', index = False,sep=';')\n",
    "    else:\n",
    "        df.to_csv(meta_exp_name+'/metrics/'+meta_exp_name + '_pretified_vectorization_final_metrics.csv', mode='a', header=None, index = False,sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ee1403",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CD_gt_to_pred_mm, CD_pred_to_gt_mm, chamf_l_mm, sink_ls_mm, en_ls_mm, gaus_ls_mm, lap_ls_mm  = metric_calculation(pred_sampling,points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2596d2b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "write_to_file(meta_exp_name+'/'+folder_name+'/metrics/','chosing_pretified_vectorization_final',CD_gt_to_pred_mm, CD_pred_to_gt_mm, chamf_l_mm, sink_ls_mm, en_ls_mm, gaus_ls_mm, lap_ls_mm)\n",
    "\n",
    "df = pd.DataFrame([[folder_name,chamf_l_mm[0].item(),en_ls_mm.item(),sink_ls_mm.item(),gaus_ls_mm.item(),lap_ls_mm.item()]],\n",
    "                  index=None,  columns=['Name','Chamfer_loss','Energy_loss','Sinkhorn_loss','Gaussian_loss','Laplassian_loss'])\n",
    "\n",
    "if not os.path.exists(meta_exp_name+'/metrics/'):\n",
    "    os.makedirs(meta_exp_name+'/metrics/')\n",
    "    \n",
    "if not os.path.exists(meta_exp_name+'/metrics/' + meta_exp_name + '_chosing_pretified_vectorization_final_metrics.csv'):\n",
    "    df.to_csv(meta_exp_name+'/metrics/'+meta_exp_name + '_chosing_pretified_vectorization_final_metrics.csv', index = False,sep=';')\n",
    "else:\n",
    "    df.to_csv(meta_exp_name+'/metrics/'+meta_exp_name + '_chosing_pretified_vectorization_final_metrics.csv', mode='a', header=None, index = False,sep=';')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 12.203975,
   "end_time": "2023-01-25T15:47:38.036089",
   "environment_variables": {},
   "exception": null,
   "input_path": "parametric_curve_move_method.ipynb",
   "output_path": "output_notebook/parametric_curve_move_method_1.ipynb",
   "parameters": {
    "cornerness_threshold": 0.7,
    "id_it": 1,
    "sharpness_threshold": 0.06
   },
   "start_time": "2023-01-25T15:47:25.832114",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}