{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('/home/user/project/sharp_features/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12208593.0 out of 4733 items are sharp\n"
     ]
    }
   ],
   "source": [
    "from sharpf.models import load_model, MODEL_BY_NAME\n",
    "from sharpf.modules.base import load_with_spec\n",
    "from sharpf.modules import module_by_kind\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import json\n",
    "spec = json.load(open('/home/user/project/sharp_features/sharpf/models/specs/dgcnn.json', 'r'))\n",
    "\n",
    "from sharpf.data.data import ABCData\n",
    "\n",
    "data_label = 'points'\n",
    "target_label = 'distances'\n",
    "data_root = '/home/user/project/point_patches/'\n",
    "dtst = ABCData(\n",
    "    data_path=data_root, partition='train',\n",
    "    data_label=data_label,\n",
    "    target_label=target_label\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "def weights_init(m):\n",
    "    seed = 139\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    modules = list(m.children())\n",
    "    if not modules:\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            weight = cached_weights.get(str(m) + '_weight', None)\n",
    "            bias = cached_weights.get(str(m) + '_bias', None)\n",
    "            if weight is not None:\n",
    "                m.weight = torch.nn.Parameter(weight)\n",
    "                if bias is not None:\n",
    "                    m.bias = torch.nn.Parameter(bias)\n",
    "            else:\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                cached_weights[str(m) + '_weight'] = m.weight.detach()\n",
    "                if m.bias is not None:\n",
    "                    nn.init.xavier_uniform_(m.bias)\n",
    "                    cached_weights[str(m) + '_bias'] = m.bias.detach()\n",
    "        elif isinstance(m, nn.BatchNorm2d):\n",
    "            nn.init.ones_(m.weight)\n",
    "            nn.init.zeros_(m.bias)\n",
    "        return\n",
    "    else:\n",
    "        for item in modules:\n",
    "            weights_init(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------\n",
      "tensor([[0.4394, 0.6323, 0.5088,  ..., 0.5647, 0.5794, 0.4952],\n",
      "        [0.4394, 0.6323, 0.5088,  ..., 0.5647, 0.5794, 0.4952],\n",
      "        [0.4394, 0.6323, 0.5088,  ..., 0.5647, 0.5794, 0.4952],\n",
      "        ...,\n",
      "        [0.4394, 0.6323, 0.5088,  ..., 0.5647, 0.5794, 0.4952],\n",
      "        [0.4394, 0.6323, 0.5088,  ..., 0.5647, 0.5794, 0.4952],\n",
      "        [0.4394, 0.6323, 0.5088,  ..., 0.5647, 0.5794, 0.4952]],\n",
      "       device='cuda:2', grad_fn=<SqueezeBackward0>)\n",
      "tensor([[0.4394, 0.6323, 0.5088,  ..., 0.5647, 0.5794, 0.4952],\n",
      "        [0.4394, 0.6323, 0.5088,  ..., 0.5647, 0.5794, 0.4952],\n",
      "        [0.4394, 0.6323, 0.5088,  ..., 0.5647, 0.5794, 0.4952],\n",
      "        ...,\n",
      "        [0.4394, 0.6323, 0.5088,  ..., 0.5647, 0.5794, 0.4952],\n",
      "        [0.4394, 0.6323, 0.5088,  ..., 0.5647, 0.5794, 0.4952],\n",
      "        [0.4394, 0.6323, 0.5088,  ..., 0.5647, 0.5794, 0.4952]],\n",
      "       device='cuda:2', grad_fn=<SqueezeBackward0>)\n",
      "-----------\n",
      "-----------\n",
      "tensor([[0.6224, 0.5878, 0.6186,  ..., 0.6279, 0.6783, 0.6340],\n",
      "        [0.6224, 0.5878, 0.6186,  ..., 0.6279, 0.6783, 0.6340],\n",
      "        [0.6224, 0.5878, 0.6186,  ..., 0.6279, 0.6783, 0.6340],\n",
      "        ...,\n",
      "        [0.6224, 0.5878, 0.6186,  ..., 0.6279, 0.6783, 0.6340],\n",
      "        [0.6224, 0.5878, 0.6186,  ..., 0.6279, 0.6783, 0.6340],\n",
      "        [0.6224, 0.5878, 0.6186,  ..., 0.6279, 0.6783, 0.6340]],\n",
      "       device='cuda:2', grad_fn=<SqueezeBackward0>)\n",
      "tensor([[0.6224, 0.5878, 0.6186,  ..., 0.6279, 0.6783, 0.6340],\n",
      "        [0.6224, 0.5878, 0.6186,  ..., 0.6279, 0.6783, 0.6340],\n",
      "        [0.6224, 0.5878, 0.6186,  ..., 0.6279, 0.6783, 0.6340],\n",
      "        ...,\n",
      "        [0.6224, 0.5878, 0.6186,  ..., 0.6279, 0.6783, 0.6340],\n",
      "        [0.6224, 0.5878, 0.6186,  ..., 0.6279, 0.6783, 0.6340],\n",
      "        [0.6224, 0.5878, 0.6186,  ..., 0.6279, 0.6783, 0.6340]],\n",
      "       device='cuda:2', grad_fn=<SqueezeBackward0>)\n",
      "-----------\n",
      "-----------\n",
      "tensor([[-0.5065, -0.4780, -0.5288,  ..., -0.5014, -0.6014, -0.4353],\n",
      "        [-0.5065, -0.4780, -0.5288,  ..., -0.5014, -0.6014, -0.4353],\n",
      "        [-0.5065, -0.4780, -0.5288,  ..., -0.5014, -0.6014, -0.4353],\n",
      "        ...,\n",
      "        [-0.5065, -0.4780, -0.5288,  ..., -0.5014, -0.6014, -0.4353],\n",
      "        [-0.5065, -0.4780, -0.5288,  ..., -0.5014, -0.6014, -0.4353],\n",
      "        [-0.5065, -0.4780, -0.5288,  ..., -0.5014, -0.6014, -0.4353]],\n",
      "       device='cuda:2', grad_fn=<SqueezeBackward0>)\n",
      "tensor([[-0.5065, -0.4780, -0.5288,  ..., -0.5014, -0.6014, -0.4353],\n",
      "        [-0.5065, -0.4780, -0.5288,  ..., -0.5014, -0.6014, -0.4353],\n",
      "        [-0.5065, -0.4780, -0.5288,  ..., -0.5014, -0.6014, -0.4353],\n",
      "        ...,\n",
      "        [-0.5065, -0.4780, -0.5288,  ..., -0.5014, -0.6014, -0.4353],\n",
      "        [-0.5065, -0.4780, -0.5288,  ..., -0.5014, -0.6014, -0.4353],\n",
      "        [-0.5065, -0.4780, -0.5288,  ..., -0.5014, -0.6014, -0.4353]],\n",
      "       device='cuda:2', grad_fn=<SqueezeBackward0>)\n",
      "-----------\n",
      "-----------\n",
      "tensor([[-0.0169, -0.0038,  0.0047,  ...,  0.0640,  0.0360,  0.0054],\n",
      "        [-0.0169, -0.0038,  0.0047,  ...,  0.0640,  0.0360,  0.0054],\n",
      "        [-0.0169, -0.0038,  0.0047,  ...,  0.0640,  0.0360,  0.0054],\n",
      "        ...,\n",
      "        [-0.0169, -0.0038,  0.0047,  ...,  0.0640,  0.0360,  0.0054],\n",
      "        [-0.0169, -0.0038,  0.0047,  ...,  0.0640,  0.0360,  0.0054],\n",
      "        [-0.0169, -0.0038,  0.0047,  ...,  0.0640,  0.0360,  0.0054]],\n",
      "       device='cuda:2', grad_fn=<SqueezeBackward0>)\n",
      "tensor([[-0.0169, -0.0038,  0.0047,  ...,  0.0640,  0.0360,  0.0054],\n",
      "        [-0.0169, -0.0038,  0.0047,  ...,  0.0640,  0.0360,  0.0054],\n",
      "        [-0.0169, -0.0038,  0.0047,  ...,  0.0640,  0.0360,  0.0054],\n",
      "        ...,\n",
      "        [-0.0169, -0.0038,  0.0047,  ...,  0.0640,  0.0360,  0.0054],\n",
      "        [-0.0169, -0.0038,  0.0047,  ...,  0.0640,  0.0360,  0.0054],\n",
      "        [-0.0169, -0.0038,  0.0047,  ...,  0.0640,  0.0360,  0.0054]],\n",
      "       device='cuda:2', grad_fn=<SqueezeBackward0>)\n",
      "-----------\n",
      "tensor(False)\n"
     ]
    }
   ],
   "source": [
    "from model_seg import DGCNN\n",
    "from collections import namedtuple\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "device = 'cuda:2'\n",
    "points = dtst[0][0]\n",
    "points = torch.tensor(np.stack([points for idx in range(10)]), device=device)\n",
    "\n",
    "artons_model = load_with_spec(spec, MODEL_BY_NAME).to(device).eval()\n",
    "Args = namedtuple('Args', ['k', 'dropout'])\n",
    "args = Args(10, 0.5)\n",
    "dgcnn_model = DGCNN(args).to(device).eval()\n",
    "\n",
    "N = 100\n",
    "res_eq = []\n",
    "for idx in range(N):\n",
    "    cached_weights = {}\n",
    "    weights_init(dgcnn_model)\n",
    "    weights_init(artons_model)\n",
    "\n",
    "    art_res = artons_model(points)\n",
    "    dgcnn_res = dgcnn_model(points.permute(0,2,1))\n",
    "    res_eq.append(torch.equal(art_res, dgcnn_res))\n",
    "    if not torch.equal(art_res, dgcnn_res):\n",
    "        print('-----------')\n",
    "        print(art_res)\n",
    "        print(dgcnn_res)\n",
    "        print('-----------')\n",
    "print(torch.tensor(res_eq).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_eq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DGCNN(\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn8): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv2d(6, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (conv3): Sequential(\n",
       "    (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (conv4): Sequential(\n",
       "    (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (conv5): Sequential(\n",
       "    (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (conv6): Sequential(\n",
       "    (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (conv7): Sequential(\n",
       "    (0): Conv2d(192, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (conv8): Sequential(\n",
       "    (0): Conv2d(1216, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (conv9): Sequential(\n",
       "    (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (conv10): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (max_pooling): MaxPool2d(kernel_size=[1024, 1], stride=[1024, 1], padding=0, dilation=1, ceil_mode=False)\n",
       "  (dp1): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dgcnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (1): ConvBase()\n",
       "  (2): ConvBase()\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artons_model.decoder_blocks[2]._op[2].conv[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dgcnn_model.conv10"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
