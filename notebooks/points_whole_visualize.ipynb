{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade k3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install msgpack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary config/cache directory at /tmp/matplotlib-qu6orq0q because the default path (/home/user/.cache/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "import json\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "import k3d\n",
    "import yaml\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sharpf.utils.abc_utils.hdf5.dataset import Hdf5File, PreloadTypes\n",
    "import sharpf.utils.abc_utils.hdf5.io_struct as io_struct\n",
    "import sharpf.utils.abc_utils.hdf5.io_struct as io\n",
    "from sharpf.utils.plotting import display_depth_sharpness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_sharpness(mesh=None, plot_meshvert=True,\n",
    "                      samples=None, samples_distances=None,\n",
    "                      sharp_vert=None, sharp_curves=None,\n",
    "                      directions=None, directions_width=0.0025,\n",
    "                      samples_color=0x0000ff, samples_psize=0.002, \n",
    "                      mesh_color=0xbbbbbb, meshvert_color=0x666666, meshvert_psize=0.0025,\n",
    "                      sharpvert_color=0xff0000, sharpvert_psize=0.0025,\n",
    "                      sharpcurve_color=None, sharpcurve_width=0.0025,\n",
    "                      as_image=False, plot_height=768,\n",
    "                      cmap=k3d.colormaps.matplotlib_color_maps.coolwarm_r, \n",
    "                      plot=None, display=True):\n",
    "    \n",
    "    if None is plot:\n",
    "        plot = k3d.plot(height=plot_height)\n",
    "    \n",
    "    if None is not mesh:\n",
    "        k3d_mesh = k3d.mesh(mesh.vertices, mesh.faces, color=mesh_color)\n",
    "        plot += k3d_mesh\n",
    "\n",
    "        if plot_meshvert:\n",
    "            k3d_points = k3d.points(mesh.vertices, \n",
    "                                    point_size=meshvert_psize, color=meshvert_color)\n",
    "            plot += k3d_points\n",
    "            k3d_points.shader='flat'\n",
    "\n",
    "    if None is not samples:\n",
    "        colors = None\n",
    "        if None is not samples_distances and not np.all(samples_distances == 1.0):\n",
    "            max_dist = 1.0\n",
    "\n",
    "            colors = k3d.helpers.map_colors(\n",
    "                samples_distances, cmap, [0, max_dist]\n",
    "            ).astype(np.uint32)\n",
    "            k3d_points = k3d.points(samples, point_size=samples_psize, colors=colors)\n",
    "        else:\n",
    "            v = -np.array([0., 1., 0.])\n",
    "            max_dist = np.max(np.dot(samples, v))\n",
    "            min_dist = np.min(np.dot(samples, v))\n",
    "            colors = k3d.helpers.map_colors(\n",
    "                np.dot(samples, v), k3d.colormaps.matplotlib_color_maps.viridis, [min_dist, max_dist]\n",
    "            ).astype(np.uint32)\n",
    "            k3d_points = k3d.points(samples, point_size=samples_psize, colors=colors)\n",
    "\n",
    "        plot += k3d_points\n",
    "        k3d_points.shader='flat'\n",
    "        \n",
    "        if None is not directions:\n",
    "            vectors = k3d.vectors(\n",
    "                samples,\n",
    "                directions * samples_distances[..., np.newaxis],\n",
    "                use_head=False, \n",
    "                line_width=directions_width)\n",
    "            print(vectors)\n",
    "            plot += vectors\n",
    "\n",
    "#             directions_to_plot = np.hstack((samples, samples + directions))\n",
    "            \n",
    "#             for i, dir_to_plot in enumerate(directions_to_plot):\n",
    "#                 dir_to_plot = dir_to_plot.reshape((2, 3))\n",
    "#                 if np.all(dir_to_plot[0] == dir_to_plot[1]):\n",
    "#                     continue\n",
    "#                 color = int(colors[i]) if None is not colors else samples_color\n",
    "#                 plt_line = k3d.line(dir_to_plot, \n",
    "#                                     shader='mesh', width=directions_width, color=color)\n",
    "#                 plot += plt_line\n",
    "\n",
    "    if None is not sharp_vert:\n",
    "        k3d_points = k3d.points(sharp_vert,\n",
    "                                point_size=sharpvert_psize, color=sharpvert_color)\n",
    "        plot += k3d_points\n",
    "        k3d_points.shader='flat'\n",
    "        \n",
    "        if None is not sharp_curves:            \n",
    "            if None is not sharpcurve_color:\n",
    "                color = sharpcurve_color\n",
    "            else:\n",
    "                import randomcolor\n",
    "                rand_color = randomcolor.RandomColor()\n",
    "            for i, vert_ind in enumerate(sharp_curves):\n",
    "                sharp_points_curve = mesh.vertices[vert_ind]\n",
    "                \n",
    "                if None is sharpcurve_color:\n",
    "                    color = rand_color.generate(hue='red')[0]\n",
    "                    color = int('0x' + color[1:], 16)\n",
    "                plt_line = k3d.line(sharp_points_curve, \n",
    "                                    shader='mesh', width=sharpcurve_width, color=color)\n",
    "                plot += plt_line\n",
    "        \n",
    "    plot.grid_visible = False\n",
    "    if display:\n",
    "        plot.display()\n",
    "    \n",
    "    if as_image:\n",
    "        plot.fetch_screenshot()\n",
    "        return Image(data=b64decode(plot.screenshot))\n",
    "    \n",
    "    return plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mm/pixel\n",
    "HIGH_RES = 0.02\n",
    "MED_RES = 0.05\n",
    "LOW_RES = 0.125\n",
    "XLOW_RES = 0.25\n",
    "\n",
    "DISPLAY_RES = 0.02 * 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "PointPatchPredictionsIO = io_struct.HDF5IO(\n",
    "        {'points': io_struct.Float64('points'),\n",
    "         'distances': io_struct.Float64('distances')},\n",
    "        len_label='distances',\n",
    "        compression='lzf')\n",
    "\n",
    "WholeDepthMapIO = io.HDF5IO({\n",
    "        'image': io.Float64('image'),\n",
    "        'normals': io.Float64('normals'),\n",
    "        'distances': io.Float64('distances'),\n",
    "        'directions': io.Float64('directions'),\n",
    "        'indexes_in_whole': io.Float64('indexes_in_whole'),\n",
    "        'item_id': io.AsciiString('item_id'),\n",
    "        'orig_vert_indices': io.VarInt32('orig_vert_indices'),\n",
    "        'orig_face_indexes': io.VarInt32('orig_face_indexes'),\n",
    "        'has_sharp': io.Bool('has_sharp'),\n",
    "        'num_sharp_curves': io.Int8('num_sharp_curves'),\n",
    "        'num_surfaces': io.Int8('num_surfaces'),\n",
    "        'camera_pose': io.Float64('camera_pose'),\n",
    "        'mesh_scale': io.Float64('mesh_scale'),\n",
    "        'has_smell_coarse_surfaces_by_num_faces': io.Bool('has_smell_coarse_surfaces_by_num_faces'),\n",
    "        'has_smell_coarse_surfaces_by_angles': io.Bool('has_smell_coarse_surfaces_by_angles'),\n",
    "        'has_smell_deviating_resolution': io.Bool('has_smell_deviating_resolution'),\n",
    "        'has_smell_sharpness_discontinuities': io.Bool('has_smell_sharpness_discontinuities'),\n",
    "        'has_smell_bad_face_sampling': io.Bool('has_smell_bad_face_sampling'),\n",
    "        'has_smell_mismatching_surface_annotation': io.Bool('has_smell_mismatching_surface_annotation'),\n",
    "        'has_smell_raycasting_background': io.Bool('has_smell_raycasting_background'),\n",
    "        'has_smell_depth_discontinuity': io.Bool('has_smell_depth_discontinuity'),\n",
    "        'has_smell_mesh_self_intersections': io.Bool('has_smell_mesh_self_intersections'),\n",
    "    },\n",
    "    len_label='has_sharp',\n",
    "    compression='lzf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_sharpness2(mesh=None, plot_meshvert=True,\n",
    "                      samples=None, samples_distances=None,\n",
    "                      sharp_vert=None, sharp_curves=None,\n",
    "                      directions=None, directions_width=0.0025,\n",
    "                      samples_color=0x0000ff, samples_psize=0.002, \n",
    "                      mesh_color=0xbbbbbb, meshvert_color=0x666666, meshvert_psize=0.0025,\n",
    "                      sharpvert_color=0xff0000, sharpvert_psize=0.0025,\n",
    "                      sharpcurve_color=None, sharpcurve_width=0.0025,\n",
    "                      as_image=False, plot_height=768,\n",
    "                      cmap=k3d.colormaps.matplotlib_color_maps.coolwarm_r):\n",
    "    \n",
    "    plot = k3d.plot(height=plot_height)\n",
    "    \n",
    "    if None is not mesh:\n",
    "        k3d_mesh = k3d.mesh(mesh.vertices, mesh.faces, color=mesh_color)\n",
    "        plot += k3d_mesh\n",
    "\n",
    "        if plot_meshvert:\n",
    "            k3d_points = k3d.points(mesh.vertices, \n",
    "                                    point_size=meshvert_psize, color=meshvert_color)\n",
    "            plot += k3d_points\n",
    "            k3d_points.shader='flat'\n",
    "\n",
    "    if None is not samples:\n",
    "        colors = None\n",
    "        if None is not samples_distances:\n",
    "            max_dist = 1.0\n",
    "\n",
    "            colors = k3d.helpers.map_colors(\n",
    "                samples_distances, cmap, [0, max_dist]\n",
    "            ).astype(np.uint32)\n",
    "            k3d_points = k3d.points(samples, point_size=samples_psize, colors=colors)\n",
    "        else:\n",
    "            if samples_color == 'z':\n",
    "                v = -np.array([0., 1., 0.])\n",
    "                max_dist = np.max(np.dot(samples, v))\n",
    "                min_dist = np.min(np.dot(samples, v))\n",
    "                colors = k3d.helpers.map_colors(\n",
    "                    np.dot(samples, v), k3d.colormaps.matplotlib_color_maps.viridis, [min_dist, max_dist]\n",
    "                ).astype(np.uint32)\n",
    "                k3d_points = k3d.points(samples, point_size=samples_psize, colors=colors)\n",
    "                \n",
    "            else:\n",
    "                k3d_points = k3d.points(samples, point_size=samples_psize, color=samples_color)\n",
    "                \n",
    "        plot += k3d_points\n",
    "        k3d_points.shader='flat'\n",
    "        \n",
    "        if None is not directions:\n",
    "            vectors = k3d.vectors(\n",
    "                samples,\n",
    "                directions * samples_distances[..., np.newaxis],\n",
    "                use_head=False, \n",
    "                line_width=directions_width)\n",
    "            print(vectors)\n",
    "            plot += vectors\n",
    "\n",
    "#             directions_to_plot = np.hstack((samples, samples + directions))\n",
    "            \n",
    "#             for i, dir_to_plot in enumerate(directions_to_plot):\n",
    "#                 dir_to_plot = dir_to_plot.reshape((2, 3))\n",
    "#                 if np.all(dir_to_plot[0] == dir_to_plot[1]):\n",
    "#                     continue\n",
    "#                 color = int(colors[i]) if None is not colors else samples_color\n",
    "#                 plt_line = k3d.line(dir_to_plot, \n",
    "#                                     shader='mesh', width=directions_width, color=color)\n",
    "#                 plot += plt_line\n",
    "\n",
    "    if None is not sharp_vert:\n",
    "        k3d_points = k3d.points(sharp_vert,\n",
    "                                point_size=sharpvert_psize, color=sharpvert_color)\n",
    "        plot += k3d_points\n",
    "        k3d_points.shader='flat'\n",
    "        \n",
    "        if None is not sharp_curves:            \n",
    "            if None is not sharpcurve_color:\n",
    "                color = sharpcurve_color\n",
    "            else:\n",
    "                import randomcolor\n",
    "                rand_color = randomcolor.RandomColor()\n",
    "            for i, vert_ind in enumerate(sharp_curves):\n",
    "                sharp_points_curve = mesh.vertices[vert_ind]\n",
    "                \n",
    "                if None is sharpcurve_color:\n",
    "                    color = rand_color.generate(hue='red')[0]\n",
    "                    color = int('0x' + color[1:], 16)\n",
    "                plt_line = k3d.line(sharp_points_curve, \n",
    "                                    shader='mesh', width=sharpcurve_width, color=color)\n",
    "                plot += plt_line\n",
    "        \n",
    "    plot.grid_visible = False\n",
    "    plot.display()\n",
    "    \n",
    "    if as_image:\n",
    "        plot.fetch_screenshot()\n",
    "        return Image(data=b64decode(plot.screenshot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UnlabeledPointCloudIO = io.HDF5IO({\n",
    "#         'points': io.Float64('points'),\n",
    "#         'indexes_in_whole': io.Int32('indexes_in_whole'),\n",
    "#         'distances': io.Float64('distances'),\n",
    "#         'item_id': io.AsciiString('item_id'),\n",
    "#     },\n",
    "#     len_label='points',\n",
    "#     compression='lzf')\n",
    "\n",
    "# ground_truth_dataset = Hdf5File(\n",
    "#     '/logs/whole_models_inference_final/gt/points/real_world/small_40.hdf5',\n",
    "#     io=UnlabeledPointCloudIO,\n",
    "#     preload=PreloadTypes.LAZY,\n",
    "#     labels='*')\n",
    "\n",
    "# idx = np.random.choice(len(ground_truth_dataset))\n",
    "\n",
    "# ground_truth = [patch for patch in ground_truth_dataset]\n",
    "# points = ground_truth_dataset[idx]['points']\n",
    "# # distances = ground_truth_dataset[idx]['distances']\n",
    "# distances = np.load('/logs/whole_models_inference_final/predictions/points/real_world_high/0.0/d6-v/regression/small_40/predictions/test_{}.npy'.format(idx))\n",
    "\n",
    "# display_sharpness2(\n",
    "#     None, plot_meshvert=False, meshvert_psize=0.01,\n",
    "#     samples=points, \n",
    "#     samples_distances=distances,\n",
    "#     samples_color=0x0000ff, samples_psize=0.1,\n",
    "#     directions=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_nice_visuals(\n",
    "    ground_truth_filename,\n",
    "    pred_filename,\n",
    "    output_filename=None,\n",
    "    display=False,\n",
    "    display_res=DISPLAY_RES,\n",
    "    invert=False,\n",
    "    min_thr=1.0,\n",
    "):\n",
    "# item_id = '00500166_5894bbd701b2bb0fc88a6978_007'\n",
    "\n",
    "# ground_truth_filename = os.path.join(\n",
    "#     '/logs/whole_models_inference_final/combined/images/high_res/0.0/resnet152/regression/abc_0050_{}__ground_truth.hdf5'.format(item_id))\n",
    "    ground_truth_dataset = Hdf5File(\n",
    "        ground_truth_filename,\n",
    "        io=PointPatchPredictionsIO,\n",
    "        preload=PreloadTypes.LAZY,\n",
    "        labels='*')\n",
    "\n",
    "#     ground_truth = [patch for patch in ground_truth_dataset]\n",
    "    points = ground_truth_dataset[0]['points']\n",
    "    distances = ground_truth_dataset[0]['distances']\n",
    "    print(len(points))\n",
    "    if invert:\n",
    "        distances = 1. - distances\n",
    "\n",
    "    plot = display_sharpness(\n",
    "        None, plot_meshvert=False, meshvert_psize=0.01,\n",
    "        samples=points, \n",
    "        samples_distances=distances,\n",
    "        samples_color=0x0000ff, samples_psize=display_res,\n",
    "        directions=None,\n",
    "        plot=None, display=False)\n",
    "\n",
    "\n",
    "#     pred_filename = os.path.join(\n",
    "#         '/logs/whole_models_inference_final/combined/images/high_res/0.0/resnet152/regression/abc_0050_{}__min.hdf5'.format(item_id))\n",
    "    pred_dataset = Hdf5File(\n",
    "        pred_filename,\n",
    "        io=PointPatchPredictionsIO,\n",
    "        preload=PreloadTypes.LAZY,\n",
    "        labels='*')\n",
    "    pred_points = pred_dataset[0]['points']\n",
    "    pred_distances = pred_dataset[0]['distances']\n",
    "    if invert:\n",
    "        pred_distances = 1. - pred_distances\n",
    "    \n",
    "    pred_distances[pred_distances > min_thr] = min_thr\n",
    "    pred_distances /= min_thr\n",
    "\n",
    "    plot = display_sharpness(\n",
    "        None, plot_meshvert=False, meshvert_psize=0.01,\n",
    "        samples=pred_points, \n",
    "        samples_distances=pred_distances,\n",
    "        samples_color=0x0000ff, samples_psize=display_res,\n",
    "        directions=None,\n",
    "        plot=plot, display=display)\n",
    "    \n",
    "    if None is not output_filename:\n",
    "        with open(output_filename, 'w') as f:\n",
    "            f.write(plot.get_snapshot())\n",
    "    \n",
    "    return plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2696516\n"
     ]
    }
   ],
   "source": [
    "item_id = 'nozel_decimated_17_nonoise.obj__13.2mm'\n",
    "d = '/logs/whole_models_inference_final/combined/images/real_world_high/0.08/resnet152/regression'\n",
    "ground_truth_filename = os.path.join(d, '{}__ground_truth.hdf5'.format(item_id))\n",
    "pred_filename = os.path.join(d, '{}__min.hdf5'.format(item_id))\n",
    "\n",
    "make_nice_visuals(\n",
    "    ground_truth_filename,\n",
    "    pred_filename,\n",
    "    display=True,\n",
    "    min_thr=0.2,\n",
    "    output_filename='x.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/logs/whole_models_inference_final/printed_models.txt') as f:\n",
    "    instance_names = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "modality = 'images'\n",
    "base_dir = os.path.join('/logs/whole_models_inference_final/combined', modality)\n",
    "visuals_dir = '/logs/whole_models_inference_final/combined/visuals'\n",
    "pred_variant = 'min'\n",
    "noise_by_res = {\n",
    "    'high_res': ['0.0', '0.005', '0.02', '0.08'],\n",
    "    'med_res': ['0.0'],\n",
    "    'low_res': ['0.0'],\n",
    "}\n",
    "RES_BY_NAME = {\n",
    "    'high_res': HIGH_RES,\n",
    "    'med_res': MED_RES,\n",
    "    'low_res': LOW_RES,\n",
    "}\n",
    "\n",
    "for instance_name in instance_names:\n",
    "    for res in ['high_res', 'med_res', 'low_res']:\n",
    "        for noise in noise_by_res[res]:\n",
    "#             for model in ['d6', 'd6-v']:\n",
    "            for model in ['resnet152']:\n",
    "                for task in ['regression', 'segmentation']:\n",
    "                    print(modality, res, noise, model, task, instance_name)\n",
    "\n",
    "                    ground_truth_filename = os.path.join(\n",
    "                        base_dir, \n",
    "                        res,\n",
    "                        noise,\n",
    "                        model,\n",
    "                        task,\n",
    "                        'abc_0050_{}__ground_truth.hdf5'.format(instance_name))\n",
    "                    pred_filename = os.path.join(\n",
    "                        base_dir, \n",
    "                        res,\n",
    "                        noise,\n",
    "                        model,\n",
    "                        task,\n",
    "                        'abc_0050_{}__{}.hdf5'.format(instance_name, pred_variant))\n",
    "\n",
    "                    if not os.path.exists(ground_truth_filename):\n",
    "    #                     print('GT {} does not exist, skipping'.format(ground_truth_filename))\n",
    "                        continue \n",
    "\n",
    "                    if not os.path.exists(pred_filename):\n",
    "    #                     print('PRED {} does not exist, skipping'.format(pred_filename))\n",
    "                        continue\n",
    "\n",
    "                    output_filename = os.path.join(\n",
    "                        visuals_dir,\n",
    "                        '{modality}_{res}_{noise}_{model}_{task}_{file}'.format(\n",
    "                            modality=modality,\n",
    "                            res=res,\n",
    "                            noise=noise,\n",
    "                            model=model,\n",
    "                            task=task,\n",
    "                            file='abc_0050_{}__ground_truth__{}.html'.format(instance_name, pred_variant)\n",
    "                        ))\n",
    "                    if os.path.exists(output_filename):\n",
    "    #                     print('OUTPUT {} exists, skipping'.format(output_filename))\n",
    "                        continue\n",
    "\n",
    "                    print(ground_truth_filename)\n",
    "                    print(pred_filename)\n",
    "                    print(output_filename)\n",
    "                    print()\n",
    "\n",
    "#                     make_nice_visuals(\n",
    "#                         ground_truth_filename,\n",
    "#                         pred_filename,\n",
    "#                         display=False,\n",
    "#                         output_filename=output_filename,\n",
    "#                         display_res=RES_BY_NAME[res] * 1.5,\n",
    "#                     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/logs/whole_models_inference_final/ct_scans.txt') as f:\n",
    "    instance_names = f.read().splitlines()\n",
    "    \n",
    "modality = 'images'\n",
    "base_dir = os.path.join('/logs/whole_models_inference_final/combined', modality)\n",
    "visuals_dir = '/logs/whole_models_inference_final/combined/visuals'\n",
    "pred_variant = 'min'\n",
    "noise_by_res = {\n",
    "    'high_res': ['0.0', '0.005', '0.02', '0.08'],\n",
    "    'med_res': ['0.0'],\n",
    "    'low_res': ['0.0'],\n",
    "}\n",
    "RES_BY_NAME = {\n",
    "    'high_res': HIGH_RES,\n",
    "    'med_res': MED_RES,\n",
    "    'low_res': LOW_RES,\n",
    "}\n",
    "\n",
    "for instance_name in instance_names:\n",
    "    for res in ['high', 'med', 'low']:\n",
    "        for noise in noise_by_res[res + '_res']:\n",
    "#             for model in ['d6', 'd6-v']:\n",
    "            for model in ['resnet152']:\n",
    "                for task in ['regression', 'segmentation']:\n",
    "                    print(modality, res, noise, model, task, instance_name)\n",
    "\n",
    "                    ground_truth_filename = os.path.join(\n",
    "                        base_dir, \n",
    "                        'real_world_' + res,\n",
    "                        noise,\n",
    "                        model,\n",
    "                        task,\n",
    "                        '{}__ground_truth.hdf5'.format(instance_name))\n",
    "                    pred_filename = os.path.join(\n",
    "                        base_dir, \n",
    "                        'real_world_' + res,\n",
    "                        noise,\n",
    "                        model,\n",
    "                        task,\n",
    "                        '{}__{}.hdf5'.format(instance_name, pred_variant))\n",
    "\n",
    "                    if not os.path.exists(ground_truth_filename):\n",
    "                        print('GT {} does not exist, skipping'.format(ground_truth_filename))\n",
    "                        continue \n",
    "\n",
    "                    if not os.path.exists(pred_filename):\n",
    "    #                     print('PRED {} does not exist, skipping'.format(pred_filename))\n",
    "                        continue\n",
    "\n",
    "                    output_filename = os.path.join(\n",
    "                        visuals_dir,\n",
    "                        '{modality}_{res}_{noise}_{model}_{task}_{file}'.format(\n",
    "                            modality=modality,\n",
    "                            res='real_world_' + res,\n",
    "                            noise=noise,\n",
    "                            model=model,\n",
    "                            task=task,\n",
    "                            file='{}__ground_truth__{}.html'.format(instance_name, pred_variant)\n",
    "                        ))\n",
    "                    if os.path.exists(output_filename):\n",
    "    #                     print('OUTPUT {} exists, skipping'.format(output_filename))\n",
    "                        continue\n",
    "\n",
    "                    print(ground_truth_filename)\n",
    "                    print(pred_filename)\n",
    "                    print(output_filename)\n",
    "                    print()\n",
    "\n",
    "                    make_nice_visuals(\n",
    "                        ground_truth_filename,\n",
    "                        pred_filename,\n",
    "                        display=False,\n",
    "                        output_filename=output_filename,\n",
    "                        display_res=RES_BY_NAME[res + '_res'] * 1.5,\n",
    "                    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /logs/whole_models_inference_final/combined/images/high_res/0.0/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/logs/whole_models_inference_final/sl_scans_points.txt') as f:\n",
    "    instance_names = f.read().splitlines()\n",
    "\n",
    "modality = 'points'\n",
    "base_dir = os.path.join('/logs/whole_models_inference_final/combined', modality)\n",
    "visuals_dir = '/logs/whole_models_inference_final/combined/visuals'\n",
    "pred_variant = 'crop__adv60__min'\n",
    "noise_by_res = {\n",
    "    'high_res': ['0.0', '0.005', '0.02', '0.08'],\n",
    "    'med_res': ['0.0'],\n",
    "    'low_res': ['0.0'],\n",
    "}\n",
    "RES_BY_NAME = {\n",
    "    'high_res': HIGH_RES,\n",
    "    'med_res': MED_RES,\n",
    "    'low_res': LOW_RES,\n",
    "}\n",
    "\n",
    "for instance_name in instance_names:\n",
    "    for res in ['high', 'med', 'low']:\n",
    "        for noise in noise_by_res[res + '_res']:\n",
    "            for model in ['d6-v']:\n",
    "#             for model in ['resnet152']:\n",
    "                for task in ['regression']:\n",
    "                    print(modality, res, noise, model, task, instance_name)\n",
    "\n",
    "                    ground_truth_filename = os.path.join(\n",
    "                        base_dir, \n",
    "                        'real_world_' + res,\n",
    "                        noise,\n",
    "                        model,\n",
    "                        task,\n",
    "                        '{}__ground_truth.hdf5'.format(instance_name))\n",
    "                    pred_filename = os.path.join(\n",
    "                        base_dir, \n",
    "                        'real_world_' + res,\n",
    "                        noise,\n",
    "                        model,\n",
    "                        task,\n",
    "                        '{}__{}.hdf5'.format(instance_name, pred_variant))\n",
    "\n",
    "                    if not os.path.exists(ground_truth_filename):\n",
    "                        print('GT {} does not exist, skipping'.format(ground_truth_filename))\n",
    "                        continue \n",
    "\n",
    "                    if not os.path.exists(pred_filename):\n",
    "    #                     print('PRED {} does not exist, skipping'.format(pred_filename))\n",
    "                        continue\n",
    "\n",
    "                    output_filename = os.path.join(\n",
    "                        visuals_dir,\n",
    "                        '{modality}_{res}_{noise}_{model}_{task}_{file}'.format(\n",
    "                            modality=modality,\n",
    "                            res='real_world_' + res,\n",
    "                            noise=noise,\n",
    "                            model=model,\n",
    "                            task=task,\n",
    "                            file='{}__ground_truth__{}.html'.format(instance_name, pred_variant)\n",
    "                        ))\n",
    "                    if os.path.exists(output_filename):\n",
    "    #                     print('OUTPUT {} exists, skipping'.format(output_filename))\n",
    "                        continue\n",
    "\n",
    "                    print(ground_truth_filename)\n",
    "                    print(pred_filename)\n",
    "                    print(output_filename)\n",
    "                    print()\n",
    "\n",
    "#                     make_nice_visuals(\n",
    "#                         ground_truth_filename,\n",
    "#                         pred_filename,\n",
    "#                         display=False,\n",
    "#                         output_filename=output_filename,\n",
    "#                         display_res=RES_BY_NAME[res + '_res'] * 1.5,\n",
    "#                     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/logs/whole_models_inference_final/printed_models.txt') as f:\n",
    "    instance_names = f.read().splitlines()\n",
    "\n",
    "modality = 'points'\n",
    "base_dir = os.path.join('/logs/whole_models_inference_final/combined', modality)\n",
    "visuals_dir = '/logs/whole_models_inference_final/combined/visuals'\n",
    "pred_variant = 'vote_0.50'\n",
    "noise_by_res = {\n",
    "    'high_res': ['0.0', '0.005', '0.02', '0.08'],\n",
    "    'med_res': ['0.0'],\n",
    "    'low_res': ['0.0'],\n",
    "}\n",
    "RES_BY_NAME = {\n",
    "    'high_res': HIGH_RES,\n",
    "    'med_res': MED_RES,\n",
    "    'low_res': LOW_RES,\n",
    "}\n",
    "\n",
    "for instance_name in instance_names:\n",
    "    for res in ['high', 'med', 'low']:\n",
    "        for noise in noise_by_res[res + '_res']:\n",
    "            for model in ['voronoi', 'sharpness', 'ecnet']:\n",
    "                    print(modality, res, noise, model, instance_name)\n",
    "\n",
    "                    ground_truth_filename = os.path.join(\n",
    "                        base_dir, \n",
    "                        res + '_res',\n",
    "                        noise,\n",
    "                        model,\n",
    "                        'abc_0050_{}__ground_truth.hdf5'.format(instance_name))\n",
    "                    pred_filename = os.path.join(\n",
    "                        base_dir, \n",
    "                        res + '_res',\n",
    "                        noise,\n",
    "                        model,\n",
    "                        'abc_0050_{}__{}.hdf5'.format(instance_name, pred_variant))\n",
    "\n",
    "                    if not os.path.exists(ground_truth_filename):\n",
    "                        print('GT {} does not exist, skipping'.format(ground_truth_filename))\n",
    "                        continue \n",
    "\n",
    "                    if not os.path.exists(pred_filename):\n",
    "                        print('PRED {} does not exist, skipping'.format(pred_filename))\n",
    "                        continue\n",
    "\n",
    "                    output_filename = os.path.join(\n",
    "                        visuals_dir,\n",
    "                        '{modality}_{res}_{noise}_{model}_{file}'.format(\n",
    "                            modality=modality,\n",
    "                            res=res + '_res',\n",
    "                            noise=noise,\n",
    "                            model=model,\n",
    "                            file='{}__ground_truth__{}.html'.format(instance_name, pred_variant)\n",
    "                        ))\n",
    "                    if os.path.exists(output_filename):\n",
    "    #                     print('OUTPUT {} exists, skipping'.format(output_filename))\n",
    "                        continue\n",
    "\n",
    "                    print(ground_truth_filename)\n",
    "                    print(pred_filename)\n",
    "                    print(output_filename)\n",
    "                    print()\n",
    "\n",
    "                    make_nice_visuals(\n",
    "                        ground_truth_filename,\n",
    "                        pred_filename,\n",
    "                        display=False,\n",
    "                        output_filename=output_filename,\n",
    "                        display_res=RES_BY_NAME[res + '_res'] * 1.5,\n",
    "                        invert=True\n",
    "                    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls /logs/whole_models_inference_final/combined/points/high/0.0/voronoi/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/logs/whole_models_inference_final/sl_scans_points.txt') as f:\n",
    "    instance_names = f.read().splitlines()\n",
    "\n",
    "modality = 'points'\n",
    "base_dir = os.path.join('/logs/whole_models_inference_final/combined', modality)\n",
    "visuals_dir = '/logs/whole_models_inference_final/combined/visuals'\n",
    "pred_variant = 'vote_0.50'\n",
    "\n",
    "for instance_name in instance_names:\n",
    "    for model in ['voronoi']:\n",
    "        print(modality, model, instance_name)\n",
    "\n",
    "        ground_truth_filename = os.path.join(\n",
    "            base_dir, \n",
    "            'real_world',\n",
    "            model,\n",
    "            '{}__ground_truth.hdf5'.format(instance_name))\n",
    "        pred_filename = os.path.join(\n",
    "            base_dir,\n",
    "            'real_world',\n",
    "            model,\n",
    "            '{}__{}.hdf5'.format(instance_name, pred_variant))\n",
    "\n",
    "        if not os.path.exists(ground_truth_filename):\n",
    "            print('GT {} does not exist, skipping'.format(ground_truth_filename))\n",
    "            continue \n",
    "\n",
    "        if not os.path.exists(pred_filename):\n",
    "#                     print('PRED {} does not exist, skipping'.format(pred_filename))\n",
    "            continue\n",
    "\n",
    "        output_filename = os.path.join(\n",
    "            visuals_dir,\n",
    "            '{modality}_{model}_{file}'.format(\n",
    "                modality=modality,\n",
    "                res='real_world',\n",
    "                model=model,\n",
    "                file='{}__ground_truth__{}.html'.format(instance_name, pred_variant)\n",
    "            ))\n",
    "        if os.path.exists(output_filename):\n",
    "#                     print('OUTPUT {} exists, skipping'.format(output_filename))\n",
    "            continue\n",
    "\n",
    "        print(ground_truth_filename)\n",
    "        print(pred_filename)\n",
    "        print(output_filename)\n",
    "        print()\n",
    "\n",
    "        make_nice_visuals(\n",
    "            ground_truth_filename,\n",
    "            pred_filename,\n",
    "            display=False,\n",
    "            output_filename=output_filename,\n",
    "            display_res=RES_BY_NAME[res + '_res'] * 1.5,\n",
    "            invert=True\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_dataset = Hdf5File(\n",
    "    '/logs/whole_models_inference_final/combined/points/real_world/voronoi/bat_320__ground_truth.hdf5',\n",
    "    io=PointPatchPredictionsIO,\n",
    "    preload=PreloadTypes.LAZY,\n",
    "    labels='*')\n",
    "\n",
    "points = ground_truth_dataset[0]['points']\n",
    "distances = ground_truth_dataset[0]['distances']\n",
    "print(len(points))\n",
    "\n",
    "display_sharpness2(\n",
    "    None, plot_meshvert=False, meshvert_psize=0.01,\n",
    "    samples=points, \n",
    "    samples_distances=distances,\n",
    "    samples_color=0x0000ff, samples_psize=0.01,\n",
    "    directions=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WholeDepthMapIO.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_images_dataset = Hdf5File(\n",
    "    '/logs/whole_models_inference_final/gt/images/real_world/nozel_decimated_17_nonoise.obj__13.2mm.hdf5',\n",
    "    io=WholeDepthMapIO,\n",
    "    preload=PreloadTypes.LAZY,\n",
    "    labels='*')\n",
    "\n",
    "pred_images_dataset = Hdf5File(\n",
    "    '/logs/whole_models_inference_final/combined/images/real_world_high/0.08/resnet152/regression/nozel_decimated_17_nonoise.obj__13.2mm__predictions.hdf5',\n",
    "    io=WholeDepthMapIO,\n",
    "    preload=PreloadTypes.LAZY,\n",
    "    labels='*')\n",
    "\n",
    "gt_images = [p['image'][256:-256, 256:-256] for p in gt_images_dataset]\n",
    "# gt_distances = [p['distances'][256:-256, 256:-256] for p in gt_images_dataset]\n",
    "pred_images_distances = [p['distances'][256:-256, 256:-256] for p in pred_images_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_images_distances_masked = []\n",
    "for image, distances in zip(gt_images, pred_images_distances):\n",
    "    distances_masked = np.zeros_like(distances)\n",
    "    distances_masked[image == 0.] = 0.\n",
    "    distances_masked[image != 0.] = distances[image != 0.]\n",
    "    pred_images_distances_masked.append(distances_masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(gt_images[0].ravel()[gt_images[0].ravel()!=0] - min(gt_images[0].ravel()[gt_images[0].ravel()!=0]), bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# display_depth_sharpness(\n",
    "#     depth_images=gt_images,\n",
    "#     sharpness_images=pred_images_distances_masked,\n",
    "#     axes_size=(16, 16),\n",
    "#     ncols=1\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_filename = os.path.join('/logs/whole_models_inference/abc_0022_00220226_b79b40ef8721383269a6542c_000__crop__linreg.hdf5')\n",
    "pred_filename = os.path.join('/logs/whole_images/arbitrary/abc_0022_00221312_0cdd179f2b755db6d27ea303_001__min.hdf5')\n",
    "pred_dataset = Hdf5File(\n",
    "    pred_filename,\n",
    "    io=PointPatchPredictionsIO,\n",
    "    preload=PreloadTypes.LAZY,\n",
    "    labels='*')\n",
    "\n",
    "pred_points = pred_dataset[0]['points']\n",
    "pred_distances = pred_dataset[0]['distances']\n",
    "\n",
    "\n",
    "display_sharpness(None, plot_meshvert=False, meshvert_psize=0.01,\n",
    "                  samples=pred_points, \n",
    "                  samples_distances=pred_distances,\n",
    "                  samples_color=0x0000ff, samples_psize=DISPLAY_RES,\n",
    "                  directions=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
