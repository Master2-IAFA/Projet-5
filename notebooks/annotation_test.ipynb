{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary config/cache directory at /tmp/matplotlib-de7sz7xa because the default path (/home/user/.cache/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "import k3d\n",
    "import yaml\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import trimesh.transformations as tt\n",
    "\n",
    "import igl\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def appendSpherical_np(xyz):\n",
    "    ptsnew = np.hstack((xyz, np.zeros(xyz.shape)))\n",
    "    xy = xyz[:,0]**2 + xyz[:,1]**2\n",
    "    ptsnew[:,3] = np.sqrt(xy + xyz[:,2]**2)\n",
    "    ptsnew[:,4] = np.arctan2(np.sqrt(xy), xyz[:,2]) # for elevation angle defined from Z-axis down\n",
    "    #ptsnew[:,4] = np.arctan2(xyz[:,2], np.sqrt(xy)) # for elevation angle defined from XY-plane up\n",
    "    ptsnew[:,5] = np.arctan2(xyz[:,1], xyz[:,0])\n",
    "    return ptsnew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colorize_normals(normals, flip_y=False):\n",
    "    normals = torch.as_tensor(normals)\n",
    "    \n",
    "    normals = normals.clone()\n",
    "    normals[2] *= -1\n",
    "    normals[2].clamp_(0, 1)\n",
    "    \n",
    "    if flip_y:\n",
    "        normals[1] *= -1\n",
    "    \n",
    "    normals = torch.clamp((normals + 1) / 2 * 255, 0, 255).type(torch.uint8)\n",
    "    return normals.numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_sharpness_old(mesh=None, plot_meshvert=True,\n",
    "                      samples=None, samples_distances=None,\n",
    "                      sharp_vert=None, sharp_curves=None,\n",
    "                      directions=None, directions_width=0.0025,\n",
    "                      samples_color=0x0000ff, samples_psize=0.002, \n",
    "                      mesh_color=0xbbbbbb, meshvert_color=0x666666, meshvert_psize=0.0025,\n",
    "                      sharpvert_color=0xff0000, sharpvert_psize=0.0025,\n",
    "                      sharpcurve_color=None, sharpcurve_width=0.0025,\n",
    "                      as_image=False, plot_height=768,\n",
    "                      cmap=k3d.colormaps.matplotlib_color_maps.coolwarm_r):\n",
    "    \n",
    "    plot = k3d.plot(height=plot_height)\n",
    "    \n",
    "    if None is not mesh:\n",
    "        k3d_mesh = k3d.mesh(mesh.vertices, mesh.faces, color=mesh_color)\n",
    "        plot += k3d_mesh\n",
    "\n",
    "        if plot_meshvert:\n",
    "            k3d_points = k3d.points(mesh.vertices, \n",
    "                                    point_size=meshvert_psize, color=meshvert_color)\n",
    "            plot += k3d_points\n",
    "            k3d_points.shader='flat'\n",
    "\n",
    "    if None is not samples:\n",
    "        colors = None\n",
    "        if None is not samples_distances:\n",
    "            max_dist = 1.0\n",
    "\n",
    "            colors = k3d.helpers.map_colors(\n",
    "                samples_distances, cmap, [0, max_dist]\n",
    "            ).astype(np.uint32)\n",
    "            k3d_points = k3d.points(samples, point_size=samples_psize, colors=colors)\n",
    "        else:\n",
    "            k3d_points = k3d.points(samples, point_size=samples_psize, color=samples_color)\n",
    "        plot += k3d_points\n",
    "        k3d_points.shader='flat'\n",
    "        \n",
    "        if None is not directions:\n",
    "            vectors = k3d.vectors(\n",
    "                samples,\n",
    "                directions * samples_distances[..., np.newaxis],\n",
    "                use_head=False, \n",
    "                line_width=directions_width)\n",
    "            print(vectors)\n",
    "            plot += vectors\n",
    "\n",
    "#             directions_to_plot = np.hstack((samples, samples + directions))\n",
    "            \n",
    "#             for i, dir_to_plot in enumerate(directions_to_plot):\n",
    "#                 dir_to_plot = dir_to_plot.reshape((2, 3))\n",
    "#                 if np.all(dir_to_plot[0] == dir_to_plot[1]):\n",
    "#                     continue\n",
    "#                 color = int(colors[i]) if None is not colors else samples_color\n",
    "#                 plt_line = k3d.line(dir_to_plot, \n",
    "#                                     shader='mesh', width=directions_width, color=color)\n",
    "#                 plot += plt_line\n",
    "\n",
    "    if None is not sharp_vert:\n",
    "        k3d_points = k3d.points(sharp_vert,\n",
    "                                point_size=sharpvert_psize, color=sharpvert_color)\n",
    "        plot += k3d_points\n",
    "        k3d_points.shader='flat'\n",
    "        \n",
    "        if None is not sharp_curves:            \n",
    "            if None is not sharpcurve_color:\n",
    "                color = sharpcurve_color\n",
    "            else:\n",
    "                import randomcolor\n",
    "                rand_color = randomcolor.RandomColor()\n",
    "            for i, vert_ind in enumerate(sharp_curves):\n",
    "                sharp_points_curve = mesh.vertices[vert_ind]\n",
    "                \n",
    "                if None is sharpcurve_color:\n",
    "                    color = rand_color.generate(hue='red')[0]\n",
    "                    color = int('0x' + color[1:], 16)\n",
    "                plt_line = k3d.line(sharp_points_curve, \n",
    "                                    shader='mesh', width=sharpcurve_width, color=color)\n",
    "                plot += plt_line\n",
    "        \n",
    "    plot.grid_visible = False\n",
    "    plot.display()\n",
    "    \n",
    "    if as_image:\n",
    "        plot.fetch_screenshot()\n",
    "        return Image(data=b64decode(plot.screenshot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "k3d.plot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_sharpness(\n",
    "    mesh=None,\n",
    "    plot_meshvert=True,\n",
    "    plot_mesh_wireframe=False,\n",
    "    mesh_wireframe_color=0x000000,\n",
    "    samples=None,\n",
    "    samples_distances=None,\n",
    "    sharp_vert=None,\n",
    "    sharp_curves=None,\n",
    "    directions=None,\n",
    "    directions_width=0.0025,\n",
    "    directions_color=0x000000,\n",
    "    samples_color=0x0000ff,\n",
    "    samples_psize=0.002, \n",
    "    mesh_color=0xbbbbbb,\n",
    "    meshvert_color=0x666666,\n",
    "    meshvert_psize=0.0025,\n",
    "    sharpvert_color=0xff0000,\n",
    "    sharpvert_psize=0.0025,\n",
    "    sharpcurve_color=None,\n",
    "    sharpcurve_width=0.0025,\n",
    "    as_image=False,\n",
    "    plot_height=768,\n",
    "    camera_fov=60.0,\n",
    "    lighting=1.5,\n",
    "    camera_auto_fit=False):\n",
    "    \n",
    "    plot = k3d.plot(\n",
    "        height=plot_height,\n",
    "        camera_fov=camera_fov,\n",
    "        lighting=lighting, \n",
    "        camera_auto_fit=camera_auto_fit,\n",
    "        grid_visible=False)\n",
    "    \n",
    "    if None is not mesh:\n",
    "        k3d_mesh = k3d.mesh(\n",
    "            mesh.vertices,\n",
    "            mesh.faces,\n",
    "            color=mesh_color)\n",
    "        plot += k3d_mesh\n",
    "\n",
    "        if plot_meshvert:\n",
    "            k3d_points = k3d.points(\n",
    "                mesh.vertices, \n",
    "                point_size=meshvert_psize,\n",
    "                color=meshvert_color)\n",
    "            plot += k3d_points\n",
    "            k3d_points.shader='3d'\n",
    "        \n",
    "        if plot_mesh_wireframe:\n",
    "            k3d_mesh = k3d.mesh(\n",
    "                mesh.vertices,\n",
    "                mesh.faces,\n",
    "                wireframe=True,\n",
    "                color=mesh_wireframe_color)\n",
    "            plot += k3d_mesh\n",
    "\n",
    "    if None is not samples:\n",
    "        colors = None\n",
    "        if None is not samples_distances:\n",
    "            max_dist = 0.5\n",
    "\n",
    "            colors = k3d.helpers.map_colors(\n",
    "                samples_distances,\n",
    "                k3d.colormaps.matplotlib_color_maps.coolwarm_r,\n",
    "                [0, max_dist]\n",
    "            ).astype(np.uint32)\n",
    "            k3d_points = k3d.points(samples, point_size=samples_psize, colors=colors)\n",
    "        else:\n",
    "            k3d_points = k3d.points(samples, point_size=samples_psize, color=samples_color)\n",
    "        plot += k3d_points\n",
    "        k3d_points.shader='flat'\n",
    "        \n",
    "        if None is not directions:\n",
    "            \n",
    "#             max_dist = np.max(samples[:, 1] + samples[:, 2])\n",
    "#             colors = k3d.helpers.map_colors(\n",
    "#                 samples[:, 1] + samples[:, 2], k3d.colormaps.matplotlib_color_maps.viridis, [0, max_dist]\n",
    "#             ).astype(np.uint32)\n",
    "            \n",
    "            vectors = k3d.vectors(\n",
    "                samples, directions * samples_distances[..., np.newaxis],\n",
    "                color=directions_color,\n",
    "                use_head=False,\n",
    "            )\n",
    "            plot += vectors\n",
    "\n",
    "#             directions_to_plot = np.hstack((samples, samples + directions))\n",
    "            \n",
    "#             for i, dir_to_plot in enumerate(directions_to_plot):\n",
    "#                 dir_to_plot = dir_to_plot.reshape((2, 3))\n",
    "#                 if np.all(dir_to_plot[0] == dir_to_plot[1]):\n",
    "#                     continue\n",
    "#                 color = int(colors[i]) if None is not colors else samples_color\n",
    "#                 plt_line = k3d.line(dir_to_plot, \n",
    "#                                     shader='mesh', width=directions_width, color=color)\n",
    "#                 plot += plt_line\n",
    "\n",
    "    if None is not sharp_vert:\n",
    "        k3d_points = k3d.points(sharp_vert,\n",
    "                                point_size=sharpvert_psize, color=sharpvert_color)\n",
    "        plot += k3d_points\n",
    "        k3d_points.shader='flat'\n",
    "        \n",
    "    if None is not sharp_curves:            \n",
    "        if None is not sharpcurve_color:\n",
    "            color = sharpcurve_color\n",
    "        else:\n",
    "            import randomcolor\n",
    "            rand_color = randomcolor.RandomColor()\n",
    "        for i, vert_ind in enumerate(sharp_curves):\n",
    "#             print(i, vert_ind)\n",
    "            sharp_points_curve = mesh.vertices[vert_ind]\n",
    "\n",
    "            if None is sharpcurve_color:\n",
    "                color = rand_color.generate(hue='red')[0]\n",
    "                color = int('0x' + color[1:], 16)\n",
    "            plt_line = k3d.line(sharp_points_curve, \n",
    "                                shader='mesh', \n",
    "                                width=sharpcurve_width, \n",
    "                                color=color)\n",
    "            plot += plt_line\n",
    "        \n",
    "    plot.camera_fov = camera_fov\n",
    "    plot.display()\n",
    "    \n",
    "    if as_image:\n",
    "        plot.fetch_screenshot()\n",
    "        return Image(data=b64decode(plot.screenshot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mm/pixel\n",
    "HIGH_RES = 0.02\n",
    "MED_RES = 0.05\n",
    "LOW_RES = 0.125\n",
    "XLOW_RES = 0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Working with point patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sharpf.utils.abc_utils.abc.abc_data import ABCModality, ABCChunk, ABC_7Z_FILEMASK, ABCItem\n",
    "from sharpf.data.annotation import ANNOTATOR_BY_TYPE\n",
    "from sharpf.data.mesh_nbhoods import NBHOOD_BY_TYPE\n",
    "from sharpf.data.noisers import NOISE_BY_TYPE\n",
    "from sharpf.data.point_samplers import SAMPLER_BY_TYPE\n",
    "from sharpf.utils.py_utils.console import eprint\n",
    "# from sharpf.utils.abc_utils.mesh.io import trimesh_load\n",
    "\n",
    "from sharpf.utils.abc_utils.abc.feature_utils import (\n",
    "    get_adjacent_features_by_bfs_with_depth1,\n",
    "    build_surface_patch_graph,\n",
    "    get_curves_extents,\n",
    "    compute_features_nbhood,\n",
    "    remove_boundary_features)\n",
    "from sharpf.utils.geometry import dist_vector_proj, mean_mmd\n",
    "from sharpf.utils.py_utils.config import load_func_from_config\n",
    "from sharpf.utils.abc_utils.mesh.indexing import reindex_zerobased\n",
    "\n",
    "\n",
    "import sharpf.utils.camera_utils.camera_pose as c\n",
    "\n",
    "from sharpf.data import DataGenerationException\n",
    "from sharpf.utils.abc_utils.abc.abc_data import ABCModality, ABCChunk, ABC_7Z_FILEMASK\n",
    "from sharpf.data.annotation import ANNOTATOR_BY_TYPE\n",
    "from sharpf.data.camera_pose_manager import POSE_MANAGER_BY_TYPE\n",
    "from sharpf.data.datasets.sharpf_io import save_depth_maps\n",
    "from sharpf.data.imaging import IMAGING_BY_TYPE\n",
    "from sharpf.data.noisers import NOISE_BY_TYPE\n",
    "from sharpf.utils.abc_utils.abc import feature_utils\n",
    "from sharpf.utils.py_utils.console import eprint_t\n",
    "from sharpf.utils.py_utils.os import add_suffix\n",
    "from sharpf.utils.py_utils.config import load_func_from_config\n",
    "from sharpf.utils.abc_utils.mesh.io import trimesh_load\n",
    "from sharpf.utils.plotting import display_depth_sharpness\n",
    "from sharpf.utils.camera_utils.camera_pose import camera_to_display\n",
    "import sharpf.data.data_smells as smells\n",
    "from sharpf.utils.abc_utils.mesh.indexing import reindex_zerobased, compute_relative_indexes\n",
    "from sharpf.utils.camera_utils.camera_pose import CameraPose\n",
    "import sharpf.data.datasets.sharpf_io as io\n",
    "from sharpf.utils.abc_utils.hdf5.dataset import Hdf5File, PreloadTypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "\n",
    "import trimesh\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def trimesh_load(io: BytesIO) -> trimesh.base.Trimesh:\n",
    "    \"\"\"Read the mesh: since trimesh messes the indices, this has to be done manually.\"\"\"\n",
    "\n",
    "    vertices, faces = [], []\n",
    "\n",
    "    for line in io.read().splitlines():\n",
    "        values = line.strip().split()\n",
    "        if not values:\n",
    "            continue\n",
    "        if values[0] == 'v':\n",
    "            vertices.append(np.array(values[1:4], dtype='float'))\n",
    "        elif values[0] == 'f':\n",
    "            faces.append(np.array([values[1].split('//')[0], values[2].split('//')[0], values[3].split('//')[0]],\n",
    "                                  dtype='int'))\n",
    "\n",
    "    vertices = np.array(vertices)\n",
    "    faces = np.array(faces) - 1\n",
    "\n",
    "    mesh = trimesh.base.Trimesh(vertices=vertices, faces=faces, process=False)  # create a mesh from the vertices\n",
    "    return mesh\n",
    "\n",
    "\n",
    "def igl_load(filename):\n",
    "    v, _, n, f, _, ni = igl.read_obj(filename)\n",
    "    return trimesh.Trimesh(\n",
    "        vertices=v,\n",
    "        faces=f,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_item_by_id(base_path_list, item_id):\n",
    "    item_prefix = item_id.split('_')[0]\n",
    "    \n",
    "    obj_dir, feat_dir = base_path_list\n",
    "    \n",
    "    item_obj_filename = os.path.join(\n",
    "        obj_dir,\n",
    "        '{}_trimesh_*.obj'.format(item_id)\n",
    "    )\n",
    "    item_obj_filename = glob.glob(item_obj_filename)[0]\n",
    "    \n",
    "    item_feat_filename = os.path.join(\n",
    "        feat_dir,\n",
    "        '{}_features_*.yml'.format(item_id)\n",
    "    )\n",
    "    item_feat_filename = glob.glob(item_feat_filename)[0]\n",
    "\n",
    "    with open(item_obj_filename) as item_obj:\n",
    "        mesh = trimesh_load(item_obj)\n",
    "#     mesh = igl_load(item_obj_filename)\n",
    "        \n",
    "    with open(item_feat_filename) as item_feat:\n",
    "        features = yaml.load(item_feat, Loader=yaml.Loader)\n",
    "\n",
    "    return ABCItem(obj=mesh, feat=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3D_normals_dataset_generation.ipynb  eccv_test\t     scannet\r\n",
      "ShapeNetCore.v2\t\t\t     mesh_denoising  sharp_features_data\r\n",
      "abc\t\t\t\t     meshden\t     toy\r\n",
      "cvpr_abc_challenge\t\t     nbv\r\n"
     ]
    }
   ],
   "source": [
    "!ls /data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ABCChunk(['/data/abc/abc_0050_obj_v00.7z', '/data/abc/abc_0050_feat_v00.7z']) as data_holder:\n",
    "    item = data_holder.get('00501216_5894ff84fca3da0f6b67497b_012')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_points = {\n",
    "  \"shape_fabrication_extent\": 10.0,\n",
    "  \"short_curve_quantile\": 0.25,\n",
    "  \"base_n_points_per_short_curve\": 8,\n",
    "  \"base_resolution_3d\": 0.125,\n",
    "  \"neighbourhood\": {\n",
    "    \"type\": \"random_euclidean_sphere\",\n",
    "    \"max_patches_per_mesh\": 128,\n",
    "    \"n_vertices\": None,\n",
    "    \"centroid\": None,\n",
    "    \"centroid_mode\": \"poisson_disk\",\n",
    "    \"radius_base\": 10.0,\n",
    "    \"radius_delta\": 0.0,\n",
    "    \"geodesic_patches\": True,\n",
    "    \"radius_scale_mode\": \"no_scale\"\n",
    "  },\n",
    "  \"sampling\": {\n",
    "    \"type\": \"poisson_disk\",\n",
    "    \"n_points\": 4096,\n",
    "    \"resolution_3d\": 0.05,\n",
    "    \"make_n_points\": \"crop_center\"\n",
    "  },\n",
    "  \"noise\": {\n",
    "    \"type\": \"many_noisers\",\n",
    "    \"subtype\": \"isotropic_gaussian\",\n",
    "    \"scale\": [0.0]\n",
    "  },\n",
    "  \"annotation\": {\n",
    "    \"type\": \"surface_based_aabb\",\n",
    "    \"distance_upper_bound\": 1.0\n",
    "  },\n",
    "  \"smell_coarse_surfaces_by_num_edges\": {\n",
    "    \"num_edges_threshold\": 8\n",
    "  },\n",
    "  \"smell_coarse_surfaces_by_angles\": {\n",
    "    \"max_angle_threshold_degrees\": 10.0\n",
    "  },\n",
    "  \"smell_deviating_resolution\": {\n",
    "    \"resolution_3d\": 0.125,\n",
    "    \"resolution_deviation_tolerance\": 0.0625\n",
    "  },\n",
    "  \"smell_sharpness_discontinuities\": {\n",
    "  },\n",
    "  \"smell_bad_face_sampling\": {\n",
    "    \"min_points_per_face\": 0.02,\n",
    "    \"max_points_per_face\": 20.0\n",
    "  }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_images = {\n",
    "  \"shape_fabrication_extent\": 10.0,\n",
    "  \"short_curve_quantile\": 0.25,\n",
    "  \"base_n_points_per_short_curve\": 8,\n",
    "  \"base_resolution_3d\": 0.125,\n",
    "  \"camera_pose\": {\n",
    "    \"type\": \"composite\",\n",
    "    \"sequences\": [\n",
    "      {\n",
    "        \"type\": \"sphere_to_origin\",\n",
    "        \"n_images\": 100\n",
    "      }\n",
    "    ]\n",
    "  },\n",
    "  \"imaging\": {\n",
    "    \"type\": \"raycasting\",\n",
    "    \"projection\": \"ortho\",\n",
    "    \"resolution_image\": 64,\n",
    "    \"resolution_3d\": 0.05,\n",
    "    \"fov\": [115, 85, 80],\n",
    "    \"validate_image\": True\n",
    "  },\n",
    "  \"noise\": {\n",
    "    \"type\": \"z_direction\",\n",
    "    \"scale\": 0.0\n",
    "  },\n",
    "  \"annotation\": {\n",
    "    \"type\": \"surface_based_aabb\",\n",
    "    \"distance_upper_bound\": 1.0\n",
    "  },\n",
    "  \"smell_coarse_surfaces_by_num_edges\": {\n",
    "    \"num_edges_threshold\": 8\n",
    "  },\n",
    "  \"smell_coarse_surfaces_by_angles\": {\n",
    "    \"max_angle_threshold_degrees\": 10.0\n",
    "  },\n",
    "  \"smell_deviating_resolution\": {\n",
    "    \"resolution_3d\": 0.125,\n",
    "    \"resolution_deviation_tolerance\": 0.0625\n",
    "  },\n",
    "  \"smell_sharpness_discontinuities\": { },\n",
    "  \"smell_bad_face_sampling\": {\n",
    "    \"min_points_per_face\": 0.02,\n",
    "    \"max_points_per_face\": 20.0\n",
    "  },\n",
    "  \"smell_raycasting_background\": { },\n",
    "  \"smell_mesh_self_intersections\": { },\n",
    "  \"smell_depth_discontinuity\": {\n",
    "    \"depth_discontinuity_threshold\": 0.5\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = config_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_fabrication_extent = config.get('shape_fabrication_extent', 10.0)\n",
    "base_n_points_per_short_curve = config.get('base_n_points_per_short_curve', 8)\n",
    "base_resolution_3d = config.get('base_resolution_3d', LOW_RES)\n",
    "\n",
    "short_curve_quantile = config.get('short_curve_quantile', 0.05)\n",
    "\n",
    "nbhood_extractor = load_func_from_config(NBHOOD_BY_TYPE, config_points['neighbourhood'])\n",
    "sampler = load_func_from_config(SAMPLER_BY_TYPE, config_points['sampling'])\n",
    "annotator = load_func_from_config(ANNOTATOR_BY_TYPE, config_points['annotation'])\n",
    "\n",
    "pose_manager = load_func_from_config(POSE_MANAGER_BY_TYPE, config_images['camera_pose'])\n",
    "imaging = load_func_from_config(IMAGING_BY_TYPE, config_images['imaging'])\n",
    "\n",
    "# Specific to this script only: override radius of neighbourhood extractor\n",
    "# to reflect actual point cloud resolution:\n",
    "# we extract spheres of radius r, such that area of a (plane) disk with radius r\n",
    "# is equal to the total area of 3d points (as if we scanned a plane wall)\n",
    "nbhood_extractor.radius_base = np.sqrt(sampler.n_points) * 0.5 * sampler.resolution_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_mesh(mesh, features, shape_fabrication_extent, resolution_3d,\n",
    "               short_curve_quantile=0.05, n_points_per_short_curve=4):\n",
    "    # compute standard size spatial extent\n",
    "    mesh_extent = np.max(mesh.bounding_box.extents)\n",
    "    mesh = mesh.apply_scale(shape_fabrication_extent / mesh_extent)\n",
    "\n",
    "    # compute lengths of curves\n",
    "    sharp_curves_lengths = feature_utils.get_curves_extents(mesh, features)\n",
    "\n",
    "    least_len = np.quantile(sharp_curves_lengths, short_curve_quantile)\n",
    "    least_len_mm = resolution_3d * n_points_per_short_curve\n",
    "\n",
    "    scale = least_len_mm / least_len\n",
    "    mesh = mesh.apply_scale(scale)\n",
    "\n",
    "    return mesh, scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh, _, _ = trimesh_load(item.obj)\n",
    "features = yaml.load(item.feat, Loader=yaml.Loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_orig = deepcopy(mesh)\n",
    "feat_orig = deepcopy(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1096,
   "metadata": {},
   "outputs": [],
   "source": [
    "sharp_curves = [curve['vert_indices'] for curve in features['curves'] if curve['sharp']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mesh_like_rendering(mesh, mesh_color=0x76d8ad, **kwargs):\n",
    "    defaults = dict(\n",
    "        plot_meshvert=False, meshvert_psize=sampler.resolution_3d, \n",
    "        plot_mesh_wireframe=False,\n",
    "        sharp_vert=None, sharpvert_psize=2. * sampler.resolution_3d,\n",
    "        samples=None, samples_psize=1. * sampler.resolution_3d,\n",
    "        sharp_curves=None, sharpcurve_color=0x000000, sharpcurve_width=0.01,\n",
    "        camera_fov=60., lighting=0.5, camera_auto_fit=False\n",
    "    )\n",
    "    defaults.update(**kwargs)\n",
    "    display_sharpness(mesh, mesh_color=mesh_color, **defaults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mesh_like_with_sharp_rendering(mesh, sharp_curves, mesh_color=0x76d8ad, **kwargs):\n",
    "    defaults = dict(\n",
    "        plot_meshvert=False, meshvert_psize=sampler.resolution_3d, \n",
    "        plot_mesh_wireframe=True,\n",
    "        sharp_vert=None, sharpvert_psize=2. * sampler.resolution_3d,\n",
    "        samples=None, samples_psize=1. * sampler.resolution_3d,\n",
    "        sharpcurve_color=0xc4295d, sharpcurve_width=0.04,\n",
    "        camera_fov=60., lighting=0.5, camera_auto_fit=False\n",
    "    )\n",
    "    defaults.update(**kwargs)\n",
    "    display_sharpness(mesh, sharp_curves=sharp_curves, mesh_color=mesh_color, **defaults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 959,
   "metadata": {},
   "outputs": [],
   "source": [
    "def brep_like_rendering(mesh, sharp_curves, mesh_color=0x76d8ad):\n",
    "    display_sharpness(\n",
    "        mesh, plot_meshvert=False, meshvert_psize=sampler.resolution_3d, mesh_color=mesh_color,\n",
    "        sharp_vert=None, sharpvert_psize=2. * sampler.resolution_3d,\n",
    "        samples=None, samples_psize=1. * sampler.resolution_3d,\n",
    "        sharp_curves=sharp_curves, sharpcurve_color=0x000000, sharpcurve_width=0.02,\n",
    "        camera_fov=15., lighting=0.5, camera_auto_fit=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sharp_line_rendering(mesh, sharp_curves, mesh_color=0xdddddd):\n",
    "    display_sharpness(\n",
    "        mesh, plot_meshvert=False, meshvert_psize=sampler.resolution_3d, mesh_color=mesh_color,\n",
    "        sharp_vert=None, sharpvert_psize=2. * sampler.resolution_3d,\n",
    "        samples=None, samples_psize=1. * sampler.resolution_3d,\n",
    "        sharp_curves=sharp_curves, sharpcurve_color=0xc4295d, sharpcurve_width=0.04,\n",
    "        camera_fov=15., lighting=0.5, camera_auto_fit=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 888,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5f61948d25a458fb1ff98240be19c24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mesh = mesh_orig.copy()\n",
    "\n",
    "\n",
    "mesh, mesh_scale = scale_mesh(mesh, features, shape_fabrication_extent, base_resolution_3d,\n",
    "                              short_curve_quantile=short_curve_quantile,\n",
    "                              n_points_per_short_curve=base_n_points_per_short_curve)\n",
    "mesh = mesh.apply_translation(-mesh.vertices.mean(axis=0))\n",
    "\n",
    "\n",
    "\n",
    "mesh.apply_translation([-7.5, -10, -12.5])\n",
    "\n",
    "# mesh_extent = np.max(mesh.bounding_box.extents)\n",
    "# scale = 7.5 / mesh_extent\n",
    "# # print(scale)\n",
    "# mesh = mesh.apply_scale(scale)\n",
    "\n",
    "# [z x y]\n",
    "def _n(a):\n",
    "    a = np.array(a)\n",
    "    return a / np.linalg.norm(a)\n",
    "\n",
    "\n",
    "R = tt.rotation_matrix(-75*np.pi/180, _n([0., 1., 0.]), np.mean(mesh.vertices, axis=0))\n",
    "mesh.apply_transform(R)\n",
    "\n",
    "R = tt.rotation_matrix(180*np.pi/180, _n([1., 0., 0.]), np.mean(mesh.vertices, axis=0))\n",
    "mesh.apply_transform(R)\n",
    "\n",
    "# R = tt.rotation_matrix(-75*np.pi/180, _n([0., -1., 1.]), np.mean(mesh.vertices, axis=0))\n",
    "# mesh.apply_transform(R)\n",
    "\n",
    "# R = tt.rotation_matrix(-15*np.pi/180, _n([1., 0., 0.]), np.mean(mesh.vertices, axis=0))\n",
    "# mesh.apply_transform(R)\n",
    "\n",
    "# R = tt.rotation_matrix(45*np.pi/180, [1., 0., 0.], np.mean(mesh.vertices, axis=0))\n",
    "# mesh.apply_transform(R)\n",
    "\n",
    "# R = tt.rotation_matrix(45*np.pi/180, _n([1., 0., 0.]), np.mean(mesh.vertices, axis=0))\n",
    "# mesh.apply_transform(R)\n",
    "\n",
    "# R = tt.rotation_matrix(-75*np.pi/180, _n([0., -1., 1.]), np.mean(mesh.vertices, axis=0))\n",
    "# mesh.apply_transform(R)\n",
    "# mesh.apply_translation([2, 1, 0])\n",
    "\n",
    "# brep_like_rendering(mesh, sharp_curves)\n",
    "mesh_like_rendering(mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# config_n_points = config_points['sampling']['n_points']\n",
    "\n",
    "# full_model_resolution_discount = 4.0\n",
    "# nbhood_extractor.radius_base = np.sqrt(config_n_points) * 0.5 * sampler.resolution_3d / full_model_resolution_discount\n",
    "# print(nbhood_extractor.radius_base)\n",
    "\n",
    "nbhood_extractor.index(mesh)\n",
    "\n",
    "# full_model_resolution_discount = 1.0\n",
    "# nbhood_extractor.radius_base = np.sqrt(config_n_points) * 0.5 * sampler.resolution_3d / full_model_resolution_discount\n",
    "# print(nbhood_extractor.radius_base)\n",
    "\n",
    "len(nbhood_extractor.centroids_cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bd5be42d2ef4c2db18ad01fe8a2f689",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_sharpness(mesh, sharp_vert=nbhood_extractor.centroids_cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -8.15826402, -15.74325202,  -8.7429058 ])"
      ]
     },
     "execution_count": 698,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbhood_extractor.centroids_cache[24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-8.40053243, -4.32806253, -8.62741812])"
      ]
     },
     "execution_count": 705,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbhood_extractor.centroids_cache[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1213,
   "metadata": {},
   "outputs": [],
   "source": [
    "LARGEST_PROCESSABLE_MESH_VERTICES = 20000\n",
    "\n",
    "nbhood_extractor.current_patch_idx = 24\n",
    "\n",
    "# extract neighbourhood\n",
    "try:\n",
    "    nbhood, mesh_vertex_indexes, mesh_face_indexes, scaler = nbhood_extractor.get_nbhood()\n",
    "    if len(nbhood.vertices) > LARGEST_PROCESSABLE_MESH_VERTICES:\n",
    "        raise DataGenerationException('Too large number of vertices in crop: {}'.format(len(nbhood.vertices)))\n",
    "except DataGenerationException as e:\n",
    "    eprint_t(str(e))\n",
    "centroid = nbhood_extractor.centroid\n",
    "\n",
    "# mesh_like_rendering(nbhood.copy().apply_translation(-nbhood.vertices.mean(axis=0)))\n",
    "# mesh_like_rendering(nbhood, mesh_color=0xFF495C)\n",
    "# display_sharpness(mesh, sharp_vert=nbhood.vertices, sharpvert_psize=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample the neighbourhood to form a point patch\n",
    "try:\n",
    "    points, normals = sampler.sample(nbhood, centroid=None)\n",
    "except Exception as e:\n",
    "    eprint(str(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 933,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0882aa3cf6b4329be751bfb040b0c34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_normals(samples=points - np.array([-10, -17.5, -10]), camera_auto_fit=False, samples_psize=0.125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create annotations: condition the features onto the nbhood\n",
    "nbhood_features = compute_features_nbhood(mesh, features, mesh_face_indexes, mesh_vertex_indexes=mesh_vertex_indexes)\n",
    "\n",
    "# remove vertices lying on the boundary (sharp edges found in 1 face only)\n",
    "nbhood_features = remove_boundary_features(nbhood, nbhood_features, how='edges')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "       [ 0.00000000e+00,  6.12323400e-17, -1.00000000e+00,\n",
       "        -2.51654364e+01],\n",
       "       [ 0.00000000e+00,  1.00000000e+00,  6.12323400e-17,\n",
       "         7.15915545e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00]])"
      ]
     },
     "execution_count": 1235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt.rotation_matrix(np.pi/2, [1., 0., 0.], point=np.mean(nbhood.vertices, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9364885a74144cafa0b7a505c51730be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#     nbhood.copy().apply_translation(- np.array([-10, -17.5, -10])),\n",
    "\n",
    "mesh_like_with_sharp_rendering(\n",
    "    nbhood.copy() \\\n",
    "        .apply_translation(-np.array([-10, -17.5, -10])) \\\n",
    "        .apply_transform(tt.rotation_matrix(np.pi/2, [0., 0., 1.])),\n",
    "    sharp_curves=get_sharp_curves_list(nbhood, nbhood_features),\n",
    "    mesh_color=0xdddddd\n",
    ")\n",
    "\n",
    "# brep_like_rendering(\n",
    "#     nbhood,\n",
    "#     sharp_curves=get_sharp_curves_list(nbhood, nbhood_features),\n",
    "#     mesh_color=0xFF495C\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1243,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    distances, directions, has_sharp = annotator.annotate(nbhood, nbhood_features, points)\n",
    "except DataGenerationException as e:\n",
    "    eprint_t(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14d3e94479b44fa9bbffa9ee23cd9c41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_sharpness(\n",
    "    samples=points - np.array([-10, -17.5, -10]),\n",
    "    camera_auto_fit=False,\n",
    "    samples_psize=0.125,\n",
    "    samples_distances=distances\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9b7ac1338584b67a66ea6c47da33fca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_normals(\n",
    "    samples=points - np.array([-10, -17.5, -10]),\n",
    "    camera_auto_fit=True,\n",
    "    samples_psize=0.125,\n",
    "#     samples_distances=distances,\n",
    "    directions=directions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate camera poses\n",
    "pose_manager.prepare(mesh)\n",
    "pose_manager_iter = iter(pose_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14.36620842, -8.89557619, -6.63755267])"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "camera_pose.frame_origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_coor(n, r):\n",
    "    phi, theta = np.mgrid[0:np.pi-0:n, 0:2 * np.pi:n]\n",
    "    x = r * np.sin(phi) * np.cos(theta)\n",
    "    y = r * np.sin(phi) * np.sin(theta)\n",
    "    z = r * np.cos(phi)\n",
    "    return np.stack((np.ravel(x), np.ravel(y), np.ravel(z))).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sharpf.utils.camera_utils.fibonacci_sphere_sampling import fibonacci_sphere_sampling\n",
    "from sharpf.utils.camera_utils.camera_pose import CameraPose, create_rotation_matrix_z, rotate_to_world_origin\n",
    "\n",
    "# XYZ coordinates of camera frame origin in world frame\n",
    "camera_origins = make_coor(\n",
    "    np.pi / 10, np.max(mesh.bounding_box.extents))\n",
    "\n",
    "# creating transforms matrices\n",
    "camera_poses = [\n",
    "    CameraPose.from_camera_axes(\n",
    "        R=rotate_to_world_origin(camera_origin),\n",
    "        t=camera_origin)\n",
    "    for camera_origin in camera_origins\n",
    "]\n",
    "\n",
    "pose_manager_iter = iter(camera_poses[20:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "metadata": {},
   "outputs": [],
   "source": [
    "pose = camera_pose.camera_to_world_4x4.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1202,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# camera_pose = next(pose_manager_iter)\n",
    "camera_pose = CameraPose(pose)\n",
    "\n",
    "translation = -nbhood_extractor.centroids_cache[14]\n",
    "mesh_centered = mesh.copy().apply_translation(translation)\n",
    "\n",
    "# extract neighbourhood\n",
    "try:\n",
    "    image, points, normals, mesh_face_indexes = \\\n",
    "        imaging.get_image_from_pose(mesh_centered, camera_pose, return_hit_face_indexes=True)\n",
    "except DataGenerationException as e:\n",
    "    eprint_t(str(e))\n",
    "    \n",
    "else:\n",
    "    nbhood, mesh_vertex_indexes, mesh_face_indexes = \\\n",
    "                feature_utils.submesh_from_hit_surfaces(mesh_centered, features, mesh_face_indexes)\n",
    "\n",
    "    # create annotations: condition the features onto the nbhood\n",
    "    nbhood_features = feature_utils.compute_features_nbhood(\n",
    "        mesh_centered, features, mesh_face_indexes, mesh_vertex_indexes=mesh_vertex_indexes,\n",
    "        deduce_verts_from_faces=False)\n",
    "\n",
    "    # remove vertices lying on the boundary (sharp edges found in 1 face only)\n",
    "    nbhood_features = feature_utils.remove_boundary_features(nbhood, nbhood_features, how='edges')\n",
    "\n",
    "\n",
    "#     display_sharpness(\n",
    "#         nbhood.copy().apply_translation(-translation),\n",
    "#         plot_meshvert=False, meshvert_psize=imaging.resolution_3d / 2,\n",
    "#         samples=points - translation, samples_psize=0.1,\n",
    "#         sharp_vert=[camera_pose.frame_origin], sharpvert_psize=1.0,\n",
    "#         directions=None\n",
    "#     )\n",
    "\n",
    "#     brep_like_rendering(\n",
    "#         nbhood.apply_translation(-translation),\n",
    "#         sharp_curves,\n",
    "#         mesh_color=0x256EFF\n",
    "#     )\n",
    "    \n",
    "#     display_depth_sharpness(\n",
    "#         depth_images=[image[::-1][::-1]]\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132"
      ]
     },
     "execution_count": 1203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sharp_curves = get_sharp_curves_list(nbhood, nbhood_features)\n",
    "len(sharp_curves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1079,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.95105652,   0.0954915 ,  -0.29389263,   5.33539642],\n",
       "       [  0.30901699,  -0.29389263,   0.9045085 , -16.42066174],\n",
       "       [  0.        ,  -0.95105652,  -0.30901699,   5.60996779],\n",
       "       [  0.        ,   0.        ,   0.        ,   1.        ]])"
      ]
     },
     "execution_count": 1079,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sharp_curves_list(mesh, features):\n",
    "    sharp_curves = np.concatenate([\n",
    "        mesh.edges_unique[\n",
    "            np.where(\n",
    "                np.all(np.isin(mesh.edges_unique, curve['vert_indices']), axis=1)\n",
    "            )[0]\n",
    "        ]\n",
    "        for curve in features['curves'] if curve['sharp']])\n",
    "    return sharp_curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1212,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# #     nbhood.copy().apply_translation(-translation).apply_translation(np.array([5,5,5])),\n",
    "\n",
    "# # sharp_curves = get_sharp_curves_list(nbhood, nbhood_features)\n",
    "# mesh_like_with_sharp_rendering(\n",
    "#     nbhood,\n",
    "#     sharp_curves=sharp_edge_indexes,\n",
    "#     mesh_color=0xdddddd, \n",
    "#     samples=points\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1045,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# compute the TSharpDF\n",
    "try:\n",
    "    distances, directions, has_sharp = annotator.annotate(\n",
    "        nbhood.copy().apply_translation(-translation),\n",
    "        nbhood_features,\n",
    "        points + nbhood_extractor.centroids_cache[14])\n",
    "except DataGenerationException as e:\n",
    "    eprint_t(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1046,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display_sharpness_old(\n",
    "#     nbhood.copy().apply_translation(-translation),\n",
    "#     plot_meshvert=False, meshvert_psize=imaging.resolution_3d / 2,\n",
    "#     samples=points + nbhood_extractor.centroids_cache[14], samples_psize=0.1,\n",
    "# #     sharp_vert=[camera_pose.frame_origin], sharpvert_psize=1.0,\n",
    "#     samples_distances=distances\n",
    "# )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1047,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert everything to images\n",
    "ray_indexes = np.where(image.ravel() != 0)[0]\n",
    "noisy_image = imaging.points_to_image(points, ray_indexes)\n",
    "normals = imaging.points_to_image(normals, ray_indexes, assign_channels=[0, 1, 2])\n",
    "distances = imaging.points_to_image(distances.reshape(-1, 1), ray_indexes, assign_channels=[0])\n",
    "directions = imaging.points_to_image(directions, ray_indexes, assign_channels=[0, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1090,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/code/sharpf/utils/plotting.py:185: MatplotlibDeprecationWarning: You are modifying the state of a globally registered colormap. In future versions, you will not be able to modify a registered colormap in-place. To remove this warning, you can make a copy of the colormap first. cmap = copy.copy(mpl.cm.get_cmap(\"viridis\"))\n",
      "  depth_cmap.set_bad(color='black')\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x1152 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display_depth_sharpness(\n",
    "#     depth_images=[image[::-1][::-1]],\n",
    "#     shar\n",
    "# )\n",
    "\n",
    "display_depth_sharpness(\n",
    "    depth_images=[image[:, ::-1]],\n",
    "#     sharpness_images=[distances[::-1][::-1]],\n",
    "#     sharpness_images=[distances[:, ::-1]],\n",
    "    axes_size=(16, 16), \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40c6b10729b54c6a9b5d7308f36bb4f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# mesh.apply_translation([0, -1, 0])\n",
    "\n",
    "mesh_like_rendering(mesh.apply_translation([-10, -10, -10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 824,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sharp_line_rendering(mesh, sharp_curves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "submeshes = [\n",
    "    reindex_zerobased(mesh, surface['vert_indices'], surface['face_indices'])\n",
    "    for surface in features['surfaces']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_patches_sharpness(\n",
    "        submeshes,\n",
    "        mesh=None,\n",
    "        plot_mesh_wireframe=False,\n",
    "        explode=0.0,\n",
    "        mesh_wireframe_color=0x000000,\n",
    "        plot_height=768, camera_fov=60.0, lighting=1.5):\n",
    "    \n",
    "    import randomcolor\n",
    "    rand_color = randomcolor.RandomColor()\n",
    "\n",
    "    plot = k3d.plot(\n",
    "        height=plot_height,\n",
    "        camera_fov=camera_fov,\n",
    "        lighting=lighting, \n",
    "        camera_auto_fit=False,\n",
    "        grid_visible=False)\n",
    "    \n",
    "    center_mass = np.mean(\n",
    "        mesh.vertices, axis=0\n",
    "    )\n",
    "    \n",
    "    for submesh in submeshes:\n",
    "        center_mass_submesh = np.mean(\n",
    "            submesh.vertices, axis=0\n",
    "        )\n",
    "            \n",
    "        color = rand_color.generate(hue='green')[0]\n",
    "        mesh_color = int('0x' + color[1:], 16)\n",
    "        k3d_mesh = k3d.mesh(\n",
    "            submesh.vertices + explode * (center_mass_submesh - center_mass),\n",
    "            submesh.faces,\n",
    "            color=mesh_color)\n",
    "        plot += k3d_mesh\n",
    "        \n",
    "        if plot_mesh_wireframe:\n",
    "            k3d_mesh = k3d.mesh(\n",
    "                submesh.vertices + explode * (center_mass_submesh - center_mass),\n",
    "                submesh.faces,\n",
    "                wireframe=True,\n",
    "                color=mesh_wireframe_color)\n",
    "            plot += k3d_mesh\n",
    "\n",
    "    plot.camera_fov = camera_fov\n",
    "    plot.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df487367d86f441f9f9bab6d1b3bf785",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_patches_sharpness(\n",
    "    submeshes, \n",
    "    mesh=mesh, \n",
    "    plot_mesh_wireframe=0, \n",
    "    mesh_wireframe_color=0x444444,\n",
    "    explode=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brep_like_rendering(mesh, sharp_curves=sharp_curves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler.n_points = 10000\n",
    "sampler.resolution_deviation_tolerance = 0\n",
    "sampler.crop_center = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample the neighbourhood to form a point patch\n",
    "try:\n",
    "    points, normals = sampler.sample(mesh, centroid=None)\n",
    "except Exception as e:\n",
    "    eprint(str(e))\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 932,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_normals(\n",
    "    mesh=None,\n",
    "    samples=None, \n",
    "    samples_color=None, samples_psize=0.002, \n",
    "    directions=None, \n",
    "    directions_width=0.0025, directions_color=0x000000, directions_line_width=0.01,\n",
    "    plot_meshvert=True, plot_mesh_wireframe=False, mesh_wireframe_color=0x000000,\n",
    "    mesh_color=0xbbbbbb, meshvert_color=0x666666, meshvert_psize=0.0025,\n",
    "    as_image=False, plot_height=768, camera_fov=60.0, lighting=1.5, camera_auto_fit=False):\n",
    "    \n",
    "    plot = k3d.plot(\n",
    "        height=plot_height,\n",
    "        camera_fov=camera_fov,\n",
    "        lighting=lighting, \n",
    "        camera_auto_fit=camera_auto_fit,\n",
    "        grid_visible=False)\n",
    "    \n",
    "    if None is not mesh:\n",
    "        k3d_mesh = k3d.mesh(\n",
    "            mesh.vertices,\n",
    "            mesh.faces,\n",
    "            color=mesh_color)\n",
    "        plot += k3d_mesh\n",
    "\n",
    "        if plot_meshvert:\n",
    "            k3d_points = k3d.points(\n",
    "                mesh.vertices, \n",
    "                point_size=meshvert_psize,\n",
    "                color=meshvert_color)\n",
    "            plot += k3d_points\n",
    "            k3d_points.shader='3d'\n",
    "        \n",
    "        if plot_mesh_wireframe:\n",
    "            k3d_mesh = k3d.mesh(\n",
    "                mesh.vertices,\n",
    "                mesh.faces,\n",
    "                wireframe=True,\n",
    "                color=mesh_wireframe_color)\n",
    "            plot += k3d_mesh\n",
    "\n",
    "\n",
    "    if None is not samples:\n",
    "        if None is not samples_color:\n",
    "            k3d_points = k3d.points(\n",
    "                samples,\n",
    "                point_size=samples_psize,\n",
    "                color=samples_color)\n",
    "\n",
    "        else:\n",
    "            v = -np.array([0., 1., 1.])\n",
    "            max_dist = np.max(np.dot(samples, v))\n",
    "            min_dist = np.min(np.dot(samples, v))\n",
    "            colors = k3d.helpers.map_colors(\n",
    "                np.dot(samples, v), k3d.colormaps.matplotlib_color_maps.viridis, [min_dist, max_dist]\n",
    "            ).astype(np.uint32)\n",
    "            k3d_points = k3d.points(samples, point_size=samples_psize, colors=colors)\n",
    "\n",
    "        plot += k3d_points\n",
    "        k3d_points.shader='flat'\n",
    "\n",
    "    \n",
    "    if None is not directions:\n",
    "        if None is not directions_color:\n",
    "            vectors = k3d.vectors(\n",
    "                samples, directions,\n",
    "                color=directions_color,\n",
    "                use_head=False,\n",
    "                line_width=directions_line_width\n",
    "            )\n",
    "            \n",
    "        else:\n",
    "            normals_colors = colorize_normals(directions).astype(np.uint32)\n",
    "            red, green, blue = normals_colors[:, 0], normals_colors[:, 1], normals_colors[:, 2]\n",
    "            colors = (red << 16) + (green << 8) + blue\n",
    "\n",
    "            vectors = k3d.vectors(\n",
    "                samples, directions,\n",
    "                colors=list(zip(colors, colors)),\n",
    "                use_head=False,\n",
    "                line_width=directions_line_width\n",
    "            )\n",
    "\n",
    "        plot += vectors\n",
    "\n",
    "    plot.camera_fov = camera_fov\n",
    "    plot.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13bdfdd556ef48caad246a4f8ea4d077",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot = k3d.plot(\n",
    "#     height=768,\n",
    "#     camera_auto_fit=False,\n",
    "#     grid_visible=False)\n",
    "\n",
    "# normals_colors = colorize_normals(mesh.vertex_normals).astype(np.uint32)\n",
    "# red, green, blue = normals_colors[:, 0], normals_colors[:, 1], normals_colors[:, 2]\n",
    "# colors = (red << 16) + (green << 8) + blue\n",
    "\n",
    "# vectors = k3d.vectors(\n",
    "#     mesh.vertices, mesh.vertex_normals*0.05,\n",
    "#     colors=list(zip(colors, colors)),\n",
    "#     use_head=False,\n",
    "#     line_width=0.01)\n",
    "\n",
    "# plot += vectors\n",
    "\n",
    "# plot += k3d.points(\n",
    "#             mesh.vertices,\n",
    "#             point_size=0.2,\n",
    "#             colors=colors)\n",
    "\n",
    "# plot.display()\n",
    "\n",
    "plot = k3d.plot(\n",
    "    height=768,\n",
    "    camera_auto_fit=False,\n",
    "    grid_visible=False)\n",
    "\n",
    "normals_colors = colorize_normals(directions).astype(np.uint32)\n",
    "red, green, blue = normals_colors[:, 0], normals_colors[:, 1], normals_colors[:, 2]\n",
    "colors = (red << 16) + (green << 8) + blue\n",
    "\n",
    "vectors = k3d.vectors(\n",
    "    points, directions*0.05,\n",
    "    colors=list(zip(colors, colors)),\n",
    "    use_head=False,\n",
    "    line_width=0.01)\n",
    "\n",
    "plot += vectors\n",
    "\n",
    "plot += k3d.points(\n",
    "            points,\n",
    "            point_size=0.2,\n",
    "            colors=colors)\n",
    "\n",
    "plot.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ad6d72caac1438da76b954128cf0006",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display_normals(points, directions=normals*0.1, samples_psize=0.1)\n",
    "# display_normals(samples=points, \n",
    "#                 directions=normals * 0.2, \n",
    "#                 samples_psize=0.2, samples_color=None,\n",
    "#                 directions_color=None, directions_line_width=0.02)\n",
    "display_normals(mesh=mesh,\n",
    "    samples=mesh.vertices,\n",
    "                samples_psize=0.05, samples_color=None,\n",
    "                directions=mesh.vertex_normals * 0.05, \n",
    "                directions_color=None, directions_line_width=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniconda/envs/py36/lib/python3.6/site-packages/traittypes/traittypes.py:101: UserWarning: Given trait value dtype \"int64\" does not match required type \"uint32\". A coerced copy has been created.\n",
      "  np.dtype(self.dtype).name))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d6057aa08b34e8b8fac2b08af231817",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_sharpness(\n",
    "    mesh,\n",
    "    plot_meshvert=False,\n",
    "    mesh_color=0x76d8ad,\n",
    "    samples_distances=np.ones(len(mesh.vertices)) * 0.05,\n",
    "    samples=mesh.vertices,\n",
    "    directions=mesh.vertex_normals,\n",
    "    sharp_curves=None, sharpcurve_color=0x000000, sharpcurve_width=0.02,\n",
    "    directions_color=0x222222, directions_width=0.005,\n",
    "    camera_fov=15., lighting=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def appendSpherical_np(xyz):\n",
    "    ptsnew = np.hstack((xyz, np.zeros(xyz.shape)))\n",
    "    xy = xyz[:,0]**2 + xyz[:,1]**2\n",
    "    ptsnew[:,3] = np.sqrt(xy + xyz[:,2]**2)\n",
    "    ptsnew[:,4] = np.arctan2(np.sqrt(xy), xyz[:,2]) # for elevation angle defined from Z-axis down\n",
    "    #ptsnew[:,4] = np.arctan2(xyz[:,2], np.sqrt(xy)) # for elevation angle defined from XY-plane up\n",
    "    ptsnew[:,5] = np.arctan2(xyz[:,1], xyz[:,0])\n",
    "    return ptsnew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2404.,  851., 4867., 1205.,  861., 2353., 1116., 4936., 1031.,\n",
       "        1059.]),\n",
       " array([-3.14117917e+00, -2.51297318e+00, -1.88476719e+00, -1.25656120e+00,\n",
       "        -6.28355210e-01, -1.49220808e-04,  6.28056769e-01,  1.25626276e+00,\n",
       "         1.88446875e+00,  2.51267474e+00,  3.14088073e+00]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "appendSpherical_np(mesh.vertex_normals)[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '/data/ShapeNetCore.v2/02958343/02958343/fdcc09ad608e95b4b631b59d5abd1cf8/models/model_normalized.obj'\n",
    "v, _, n, f, _, ni = igl.read_obj(filename)\n",
    "shapenet_mesh = trimesh.Trimesh(\n",
    "    vertices=v,\n",
    "    faces=f,\n",
    ")\n",
    "mesh_orig = shapenet_mesh.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapenet_mesh = mesh_orig.copy()\n",
    "mesh_extent = np.max(mesh.bounding_box.extents)\n",
    "shapenet_mesh = shapenet_mesh.apply_scale(80 / mesh_extent)\n",
    "\n",
    "# [z x y]\n",
    "def _n(a):\n",
    "    a = np.array(a)\n",
    "    return a / np.linalg.norm(a)\n",
    "\n",
    "\n",
    "R = tt.rotation_matrix(-90*np.pi/180, [0., 0., 1.], np.mean(shapenet_mesh.vertices, axis=0))\n",
    "shapenet_mesh.apply_transform(R)\n",
    "\n",
    "R = tt.rotation_matrix(180*np.pi/180, _n([1., 0., 0.]), np.mean(shapenet_mesh.vertices, axis=0))\n",
    "shapenet_mesh.apply_transform(R)\n",
    "\n",
    "R = tt.rotation_matrix(-10*np.pi/180, _n([0., -1., 1.]), np.mean(shapenet_mesh.vertices, axis=0))\n",
    "shapenet_mesh.apply_transform(R)\n",
    "shapenet_mesh.apply_translation([0, 0, 0])\n",
    "\n",
    "mesh_like_rendering(shapenet_mesh, mesh_color=0xdddddd)\n",
    "# brep_like_rendering(shapenet_mesh, None, mesh_color=0xdddddd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '/data/scannet/scene0535_00_vh_clean_2.labels.obj'\n",
    "\n",
    "with open(filename) as ply_obj:\n",
    "    scannet_mesh = trimesh.load(ply_obj, file_type='obj')\n",
    "    \n",
    "mesh_orig = scannet_mesh.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d897af32e2b4415affd9f783dd73e0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scannet_mesh = mesh_orig.copy()\n",
    "mesh_extent = np.max(scannet_mesh.bounding_box.extents)\n",
    "scannet_mesh = scannet_mesh.apply_scale(5 / mesh_extent)\n",
    "\n",
    "# [z x y]\n",
    "def _n(a):\n",
    "    a = np.array(a)\n",
    "    return a / np.linalg.norm(a)\n",
    "\n",
    "\n",
    "R = tt.rotation_matrix(90*np.pi/180, [0., 1., 0.], np.mean(scannet_mesh.vertices, axis=0))\n",
    "scannet_mesh.apply_transform(R)\n",
    "\n",
    "R = tt.rotation_matrix(120*np.pi/180, _n([1., 0., 0.]), np.mean(scannet_mesh.vertices, axis=0))\n",
    "scannet_mesh.apply_transform(R)\n",
    "\n",
    "R = tt.rotation_matrix(-30*np.pi/180, _n([0., -1., 1.]), np.mean(scannet_mesh.vertices, axis=0))\n",
    "scannet_mesh.apply_transform(R)\n",
    "scannet_mesh.apply_translation([-1, -3, 0])\n",
    "\n",
    "mesh_like_rendering(scannet_mesh, mesh_color=0xdddddd)\n",
    "# brep_like_rendering(scannet_mesh, None, mesh_color=0xdddddd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0a1e0f4a8854a1aa32c93401df15fd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_sharpness(\n",
    "    mesh, plot_meshvert=False, meshvert_psize=sampler.resolution_3d, mesh_color=0x76d8ad,\n",
    "    plot_mesh_wireframe=True,\n",
    "    sharp_vert=None, sharpvert_psize=2. * sampler.resolution_3d,\n",
    "    samples=None, samples_psize=1. * sampler.resolution_3d,\n",
    "    sharp_curves=None, sharpcurve_color=0x000000, sharpcurve_width=0.01,\n",
    "    camera_fov=15., lighting=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbhood_extractor.radius_base = np.sqrt(sampler.n_points) * 0.5 * sampler.resolution_3d * scale\n",
    "\n",
    "\n",
    "# index the mesh using a neighbourhood functions class\n",
    "# (this internally may call indexing, so for repeated invocation one passes the mesh)\n",
    "nbhood_extractor.index(mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids_cache = nbhood_extractor.centroids_cache.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 906,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler.resolution_3d = MED_RES\n",
    "\n",
    "nbhood_extractor.radius_base = np.sqrt(sampler.n_points) * 0.5 * sampler.resolution_3d * scale\n",
    "\n",
    "nbhood_extractor.current_patch_idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 907,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4beff91c3944492f8d1443eca7891ca4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_sharpness(\n",
    "    mesh, plot_meshvert=False, meshvert_psize=sampler.resolution_3d, mesh_color=0x76d8ad,\n",
    "    plot_mesh_wireframe=True,\n",
    "    sharp_vert=nbhood_extractor.centroids_cache, sharpvert_psize=5. * sampler.resolution_3d,\n",
    "    samples=None, samples_psize=1. * sampler.resolution_3d,\n",
    "    sharp_curves=None, sharpcurve_color=0x000000, sharpcurve_width=0.01,\n",
    "    camera_fov=15., lighting=0.5, camera_auto_fit=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 908,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbhood_extractor.current_patch_idx = 45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 909,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# extract neighbourhood\n",
    "try:\n",
    "    nbhood, mesh_vertex_indexes, mesh_face_indexes, scaler = nbhood_extractor.get_nbhood()\n",
    "except Exception as e:\n",
    "    eprint(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 910,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24c98339d5d1416da20be2629888d799",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "    \n",
    "display_sharpness(\n",
    "    nbhood, plot_meshvert=False, meshvert_psize=sampler.resolution_3d, mesh_color=0x76d8ad,\n",
    "    plot_mesh_wireframe=True,\n",
    "    sharp_vert=None, sharpvert_psize=2. * sampler.resolution_3d,\n",
    "    samples=None, samples_psize=1. * sampler.resolution_3d,\n",
    "    sharp_curves=None, sharpcurve_color=0x000000, sharpcurve_width=0.01,\n",
    "    camera_fov=15., lighting=1.75, camera_auto_fit=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 911,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create annotations: condition the features onto the nbhood\n",
    "nbhood_features = compute_features_nbhood(mesh, features, mesh_vertex_indexes, mesh_face_indexes)\n",
    "\n",
    "# remove vertices lying on the boundary (sharp edges found in 1 face only)\n",
    "nbhood_features = remove_boundary_features(nbhood, nbhood_features, how='edges')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 912,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 []\n",
      "1 []\n",
      "2 []\n",
      "3 []\n",
      "4 []\n",
      "5 []\n",
      "6 [ 0  1 20 21 22 23 24 25]\n",
      "7 [ 0  2 26 27 28 29 30 31]\n",
      "8 [ 2  3 32 33 34 35 36 37]\n",
      "9 [ 1  3 38 39 40 41 42 43]\n",
      "10 [ 4 44 45 46 47 48 49]\n",
      "11 [ 4  5 50 51 52 53 54 55 56 57 58 59]\n",
      "12 [5 6]\n",
      "13 [ 6  7 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75]\n",
      "14 [7 8]\n",
      "15 [ 8  9 76 77 78 79 80 81 82 83 84 85]\n",
      "16 [ 9 86 87 88 89 90]\n",
      "17 [10 11 91 92 93 94 95 96]\n",
      "18 [ 11  12 106 107 108 109 110 111]\n",
      "19 [ 12  13 112 113 114 115 116 117]\n",
      "20 [ 10  13 121 122 123 124 125 126]\n",
      "21 [  9  14 127 128 129]\n",
      "22 [ 14 130 131 132 133]\n",
      "23 [ 14  15 134 135 136 137 138 139 140 141 142 143]\n",
      "24 [  8  15 144 145 146]\n",
      "25 [15 16]\n",
      "26 [  7  16 147 148 149]\n",
      "27 [ 16  17 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165]\n",
      "28 [  6  17 166 167 168]\n",
      "29 [17 18]\n",
      "30 [  5  18 169 170 171]\n",
      "31 [ 18  19 172 173 174 175 176 177 178 179 180 181]\n",
      "32 [  4  19 182 183 184]\n",
      "33 [ 19 185 186 187 188 189]\n",
      "34 []\n",
      "35 []\n",
      "36 []\n",
      "37 []\n",
      "38 []\n",
      "39 []\n",
      "40 []\n",
      "41 []\n",
      "42 []\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52bf988d9a354bc49ef2d0855f6935e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_sharpness(\n",
    "    nbhood, plot_meshvert=False, meshvert_psize=sampler.resolution_3d, mesh_color=0xdddddd,\n",
    "    sharp_curves=[f['vert_indices'] for f in nbhood_features['curves'] if f['sharp']], \n",
    "    sharpcurve_color=0xc4295d, sharpcurve_width=0.01,\n",
    "    camera_fov=15., lighting=1.75, camera_auto_fit=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 913,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# if any(c['sharp'] for c in nbhood_features['curves']):\n",
    "#     sharp_verts = np.concatenate([nbhood.vertices[c['vert_indices']] \n",
    "#                                   for c in nbhood_features['curves'] if c['sharp']])\n",
    "# else:\n",
    "#     sharp_verts = []\n",
    "    \n",
    "\n",
    "# surf_vert_indices = np.array(nbhood_features['surfaces'][2]['vert_indices'])\n",
    "# surf_verts = nbhood.vertices[surf_vert_indices]\n",
    "\n",
    "\n",
    "\n",
    "# display_sharpness(\n",
    "#     nbhood, plot_meshvert=True, meshvert_psize=sampler.resolution_3d,\n",
    "#     sharp_vert=sharp_verts, sharpvert_psize=1. * sampler.resolution_3d,\n",
    "#     samples=surf_verts, samples_psize=sampler.resolution_3d,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 914,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler.resolution_deviation_tolerance = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 915,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample the neighbourhood to form a point patch\n",
    "try:\n",
    "    points, normals = sampler.sample(nbhood, centroid=nbhood_extractor.centroid)\n",
    "except DataGenerationException as e:\n",
    "    eprint(str(e))\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 916,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b4ef0a8bb3740b8a4395447130a547e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_normals(points, samples_psize=MED_RES, camera_auto_fit=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 897,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = iter(noiser.make_noise(points, normals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 898,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create a noisy sample\n",
    "# c, noisy_points = next(i)\n",
    "\n",
    "# display_sharpness(nbhood, plot_meshvert=True, meshvert_psize=sampler.resolution_3d/2,\n",
    "#                   samples=noisy_points, samples_distances=None,\n",
    "#                   samples_color=0x0000ff, samples_psize=sampler.resolution_3d,\n",
    "#                   sharp_vert=sharp_verts, sharpvert_psize=2*sampler.resolution_3d,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 899,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotator.validate_annotation = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 900,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotator.distance_upper_bound = 1.0\n",
    "# compute the TSharpDF\n",
    "distances, directions, has_sharp = annotator.annotate(nbhood, nbhood_features, points)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 901,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3aaee9be9f34f7c95c54cb29bc8c76d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_sharpness(None, plot_meshvert=False, meshvert_psize=0.01,\n",
    "                  sharp_vert=None, sharpvert_psize=2 * sampler.resolution_3d,\n",
    "                  samples=points, samples_distances=distances,\n",
    "                  samples_color=0x0000ff, samples_psize=MED_RES,\n",
    "                  directions=None, camera_auto_fit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 904,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentations = np.ones_like(distances)\n",
    "segmentations[distances < sampler.resolution_3d/2] = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 905,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abccba4bd57045659c0818c130361bd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_sharpness(None, plot_meshvert=False, meshvert_psize=0.01,\n",
    "                  sharp_vert=None, sharpvert_psize=2 * sampler.resolution_3d,\n",
    "                  samples=points, samples_distances=segmentations,\n",
    "                  samples_color=0x0000ff, samples_psize=MED_RES,\n",
    "                  directions=None, camera_auto_fit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacent_sharp_features, adjacent_surfaces = build_surface_patch_graph(nbhood_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surface_idx = 17\n",
    "surface = nbhood_features['surfaces'][surface_idx]\n",
    "adjacent_sharp_indexes = get_adjacent_features_by_bfs_with_depth1(\n",
    "                surface_idx, adjacent_sharp_features, adjacent_surfaces)\n",
    "surface_adjacent_features = {\n",
    "    'curves': [nbhood_features['curves'][idx]\n",
    "               for idx in np.unique(adjacent_sharp_indexes)]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sharp_adjacent_2 = np.concatenate([nbhood.vertices[\n",
    "#     nbhood_features['curves'][sharp_curve_id]['vert_indices']\n",
    "# ] for sharp_curve_id in adjacent_sharp_features[2]])\n",
    "sharp_adjacent_2 = np.concatenate([nbhood.vertices[\n",
    "    nbhood_features['curves'][sharp_curve_id]['vert_indices']\n",
    "] for sharp_curve_id in adjacent_sharp_features[17]])\n",
    "\n",
    "sharp_adjacent_2_with_bfs = np.concatenate([nbhood.vertices[\n",
    "    curve['vert_indices']\n",
    "] for curve in surface_adjacent_features['curves']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_sharpness(None,\n",
    "                 sharp_vert = sharp_adjacent_2, sharpvert_psize=0.05,\n",
    "                 samples=sharp_adjacent_2_with_bfs, samples_psize=0.05,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sharpf.utils.mesh_utils.indexing import reindex_zerobased, compute_relative_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surface = nbhood_features['surfaces'][surface_idx]\n",
    "\n",
    "surface_face_indexes = np.where(np.isin(nbhood.faces, surface['vert_indices']).all(axis=1))[0]\n",
    "\n",
    "surface_mesh = reindex_zerobased(nbhood, surface['vert_indices'], surface_face_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "display_sharpness(surface_mesh,\n",
    "                 sharp_vert = sharp_adjacent_2_with_bfs, sharpvert_psize=0.05,\n",
    "                 samples=None, samples_psize=0.05,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_boundary_features(mesh, features, how='none'):\n",
    "    \"\"\"Removes features indexed into vertex edges adjacent to 1 face only.\n",
    "    :param how: 'all_verts': remove entire feature curve if all vertices are boundary\n",
    "                'edges': remove vertices that belong to boundary edges only (not to other edges)\n",
    "                'verts': remove vertices that are boundary\n",
    "                'none': do nothing\n",
    "    \"\"\"\n",
    "    if how == 'none':\n",
    "        return features\n",
    "\n",
    "    mesh_edge_indexes, mesh_edge_counts = np.unique(\n",
    "        mesh.faces_unique_edges.flatten(), return_counts=True)\n",
    "\n",
    "    boundary_edges = mesh.edges_unique[mesh_edge_indexes[np.where(mesh_edge_counts == 1)[0]]]\n",
    "    boundary_vertex_indexes = np.unique(boundary_edges.flatten())\n",
    "\n",
    "    non_boundary_curves = []\n",
    "    for curve in features['curves']:\n",
    "        non_boundary_curve = deepcopy(curve)\n",
    "\n",
    "        if how == 'all_verts':\n",
    "            if np.all([vert_index in boundary_vertex_indexes\n",
    "                       for vert_index in curve['vert_indices']]):\n",
    "                continue\n",
    "\n",
    "        elif how == 'verts':\n",
    "            non_boundary_vert_indices = np.array([\n",
    "                vert_index for vert_index in curve['vert_indices']\n",
    "                if vert_index not in boundary_vertex_indexes\n",
    "            ])\n",
    "            if len(non_boundary_vert_indices) == 0:\n",
    "                continue\n",
    "            non_boundary_curve['vert_indices'] = non_boundary_vert_indices\n",
    "\n",
    "        elif how == 'edges':\n",
    "            curve_edges = mesh.edges_unique[\n",
    "                np.where(\n",
    "                    np.all(np.isin(mesh.edges_unique, curve['vert_indices']), axis=1)\n",
    "                )[0]\n",
    "            ]\n",
    "            non_boundary = (curve_edges[:, None] != boundary_edges).any(2).all(1)\n",
    "            non_boundary_vert_indices = np.unique(curve_edges[non_boundary])\n",
    "            non_boundary_curve['vert_indices'] = non_boundary_vert_indices\n",
    "\n",
    "        non_boundary_curves.append(non_boundary_curve)\n",
    "\n",
    "    non_boundary_features = {\n",
    "        'curves': non_boundary_curves,\n",
    "        'surfaces': features.get('surfaces', [])\n",
    "    }\n",
    "    return non_boundary_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surface_adjacent_features = remove_boundary_features(surface_mesh, surface_adjacent_features, how='verts')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_sharpness(surface_mesh,\n",
    "                 sharp_vert = sharp_adjacent_2, sharpvert_psize=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import cKDTree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_distances, nn_indexes = cKDTree(noisy_points, leafsize=16).query(noisy_points, k=2, n_jobs=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances[nn_indexes[:, 0]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = np.abs(distances[nn_indexes[:, 0]] - distances[nn_indexes[:, 1]]) / nn_distances[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values[np.where(values > 1.1)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_sharpness(nbhood, plot_meshvert=False, meshvert_psize=0.01,\n",
    "                  sharp_vert=points[np.where(values > 1.1)[0]], sharpvert_psize=2 * sampler.resolution_3d,\n",
    "                  samples=noisy_points, samples_distances=distances,\n",
    "                  samples_color=0x0000ff, samples_psize=sampler.resolution_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import igl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, point_face_indexes, _ = \\\n",
    "    igl.point_mesh_squared_distance(noisy_points, nbhood.vertices, nbhood.faces)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sharpf.utils.abc_utils import get_adjacent_features_by_bfs_with_depth1, build_surface_patch_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# understand which surface patches are adjacent to which sharp features\n",
    "# and other surface patches\n",
    "adjacent_sharp_features, adjacent_surfaces = build_surface_patch_graph(nbhood_features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacent_sharp_features, adjacent_surfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# compute distance, iterating over points sampled from corresponding surface patches\n",
    "distances, projections = np.ones(len(points)) * annotator.distance_upper_bound, np.zeros_like(points)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surface_idx, surface = 3, nbhood_features['surfaces'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# constrain distance computation to certain sharp features only\n",
    "adjacent_sharp_indexes = get_adjacent_features_by_bfs_with_depth1(\n",
    "    surface_idx, adjacent_sharp_features, adjacent_surfaces)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacent_sharp_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surface_adjacent_features = {\n",
    "    'curves': [nbhood_features['curves'][idx]\n",
    "               for idx in np.unique(adjacent_sharp_indexes)]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(surface_adjacent_features['curves'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sharpf.utils.mesh_utils.indexing import in2d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_cloud_indexes = np.where(\n",
    "    in2d(nbhood.faces[point_face_indexes], surface['face_indices'])\n",
    ")[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_cloud_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute distances using parent class AABB method\n",
    "surface_matching_edges, surface_projections, surface_distances = \\\n",
    "    annotator.compute_aabb_nearest_points(nbhood, surface_adjacent_features, noisy_points[point_cloud_indexes])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances[point_cloud_indexes], projections[point_cloud_indexes] = surface_distances, surface_projections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_sharpness(nbhood, plot_meshvert=False, meshvert_psize=0.01,\n",
    "                  sharp_vert=None, sharpvert_psize=2 * sampler.resolution_3d,\n",
    "                  samples=noisy_points, samples_distances=distances,\n",
    "                  samples_color=0x0000ff, samples_psize=sampler.resolution_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bounded_labels(points, projections, distances=None, max_distance=np.inf, distance_scaler=1.0):\n",
    "    if distances is None:\n",
    "        distances = np.linalg.norm(projections - points, axis=1)\n",
    "\n",
    "    distances = distances / distance_scaler\n",
    "    # boolean mask marking objects far away from sharp curves\n",
    "    far_from_sharp = distances > max_distance\n",
    "    distances[far_from_sharp] = max_distance\n",
    "    distances = distances.reshape(-1, 1)\n",
    "    # compute directions for points close to sharp curves\n",
    "    directions = np.zeros_like(points)\n",
    "    directions[~far_from_sharp] = projections[~far_from_sharp] - points[~far_from_sharp]\n",
    "    eps = 1e-6\n",
    "    directions[~far_from_sharp] /= (np.linalg.norm(directions[~far_from_sharp], axis=1, keepdims=True) + eps)\n",
    "    return distances, directions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "distances, directions = compute_bounded_labels(\n",
    "    noisy_points, projections, distances=distances,\n",
    "    max_distance=annotator.distance_upper_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_sharpness(nbhood, plot_meshvert=False, meshvert_psize=0.01,\n",
    "                  sharp_vert=None, sharpvert_psize=2 * sampler.resolution_3d,\n",
    "                  samples=noisy_points, samples_distances=distances,\n",
    "                  samples_color=0x0000ff, samples_psize=sampler.resolution_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import cKDTree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_distances, nn_indexes = cKDTree(noisy_points, leafsize=16).query(noisy_points, k=2, n_jobs=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_distances.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = np.abs(distances[nn_indexes[:, 0]] - distances[nn_indexes[:, 1]]) / np.atleast_2d(nn_distances[:, 1]).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ii, jj = np.where(values > 1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_sharpness(nbhood, plot_meshvert=False, meshvert_psize=0.01,\n",
    "                  sharp_vert=None, sharpvert_psize=2 * sampler.resolution_3d,\n",
    "                  samples=noisy_points[ii, jj], samples_distances=distances[ii, jj],\n",
    "                  samples_color=0x0000ff, samples_psize=sampler.resolution_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # constrain distance computation to certain sharp features only\n",
    "    adjacent_sharp_indexes = get_adjacent_features_by_bfs_with_depth1(\n",
    "        surface_idx, adjacent_sharp_features, adjacent_surfaces)\n",
    "    surface_adjacent_features = {\n",
    "        'curves': [features_patch['curves'][idx]\n",
    "                   for idx in np.unique(adjacent_sharp_indexes)]\n",
    "    }\n",
    "    if len(surface_adjacent_features['curves']) == 0:\n",
    "        continue\n",
    "\n",
    "    point_cloud_indexes = np.where(\n",
    "        in2d(mesh_patch.faces[point_face_indexes], surface['face_indices'])\n",
    "    )[0]\n",
    "    # point_cloud_indexes = np.where(np.isin(closest_nbhood_vertex_idx, surface['vert_indices']))[0]\n",
    "    if len(point_cloud_indexes) == 0:\n",
    "        continue\n",
    "    # compute distances using parent class AABB method\n",
    "    surface_matching_edges, surface_projections, surface_distances = \\\n",
    "        self.compute_aabb_nearest_points(mesh_patch, surface_adjacent_features, points[point_cloud_indexes])\n",
    "    distances[point_cloud_indexes], projections[point_cloud_indexes] = surface_distances, surface_projections\n",
    "\n",
    "return projections, distances\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbhood.vertices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_sharpness(nbhood, plot_meshvert=False, meshvert_psize=0.01,\n",
    "                  sharp_vert=None, sharpvert_psize=2 * sampler.resolution_3d,\n",
    "                  samples=noisy_points, samples_distances=distances,\n",
    "                  samples_color=0x0000ff, samples_psize=sampler.resolution_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_mmd(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/data/abc/test_trimesh.obj') as item_obj:\n",
    "    mesh = trimesh_load(item_obj)\n",
    "\n",
    "with open('/data/abc/test_features.yml') as item_feat:\n",
    "    features = yaml.load(item_feat, Loader=yaml.Loader)\n",
    "\n",
    "mesh_orig = mesh.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item_id = '00009684_f3f3f0459fff4bcb8d7ab694'\n",
    "# item_id = '00009533_40bd0c14c7b442c083075cac'\n",
    "\n",
    "item_id = '00009533_40bd0c14c7b442c083075cac'\n",
    "\n",
    "item = get_item_by_id(\n",
    "    ['/data/abc/abc_0000_obj_v00', '/data/abc/abc_0000_feat_v00'], \n",
    "    item_id)\n",
    "\n",
    "mesh = item.obj\n",
    "features = item.feat\n",
    "mesh_orig = mesh.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mesh = mesh_orig.copy()\n",
    "\n",
    "mesh = scale_mesh(mesh, features, shape_fabrication_extent, base_resolution_3d,\n",
    "                  short_curve_quantile=short_curve_quantile,\n",
    "                  n_points_per_short_curve=base_n_points_per_short_curve)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
