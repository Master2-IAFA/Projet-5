{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary config/cache directory at /tmp/matplotlib-wgz9l51w because the default path (/home/user/.cache/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "from collections import defaultdict\n",
    "import json\n",
    "import warnings\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import k3d\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "k3d.vectors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_sharpness(mesh=None, plot_meshvert=True,\n",
    "                      samples=None, samples_distances=None,\n",
    "                      sharp_vert=None, sharp_curves=None,\n",
    "                      directions=None, directions_width=0.0025,\n",
    "                      samples_color=0x0000ff, samples_psize=0.002, \n",
    "                      mesh_color=0xbbbbbb, meshvert_color=0x666666, meshvert_psize=0.0025,\n",
    "                      sharpvert_color=0xff0000, sharpvert_psize=0.0025,\n",
    "                      sharpcurve_color=None, sharpcurve_width=0.0025,\n",
    "                      as_image=False, plot_height=768):\n",
    "    \n",
    "    plot = k3d.plot(height=plot_height)\n",
    "    \n",
    "    if None is not mesh:\n",
    "        k3d_mesh = k3d.mesh(mesh.vertices, mesh.faces, color=mesh_color)\n",
    "        plot += k3d_mesh\n",
    "\n",
    "        if plot_meshvert:\n",
    "            k3d_points = k3d.points(mesh.vertices, \n",
    "                                    point_size=meshvert_psize, color=meshvert_color)\n",
    "            plot += k3d_points\n",
    "            k3d_points.shader='flat'\n",
    "\n",
    "    if None is not samples:\n",
    "        colors = None\n",
    "        if None is not samples_distances:\n",
    "            max_dist = 0.5\n",
    "\n",
    "            colors = k3d.helpers.map_colors(\n",
    "                samples_distances, k3d.colormaps.matplotlib_color_maps.coolwarm_r, [0, max_dist]\n",
    "            ).astype(np.uint32)\n",
    "            k3d_points = k3d.points(samples, point_size=samples_psize, colors=colors)\n",
    "        else:\n",
    "            k3d_points = k3d.points(samples, point_size=samples_psize, color=samples_color)\n",
    "        plot += k3d_points\n",
    "        k3d_points.shader='flat'\n",
    "        \n",
    "        if None is not directions:\n",
    "            vectors = k3d.vectors(\n",
    "                samples,\n",
    "                directions * samples_distances[..., np.newaxis],\n",
    "                use_head=False, \n",
    "                line_width=directions_width)\n",
    "            print(vectors)\n",
    "            plot += vectors\n",
    "\n",
    "#             directions_to_plot = np.hstack((samples, samples + directions))\n",
    "            \n",
    "#             for i, dir_to_plot in enumerate(directions_to_plot):\n",
    "#                 dir_to_plot = dir_to_plot.reshape((2, 3))\n",
    "#                 if np.all(dir_to_plot[0] == dir_to_plot[1]):\n",
    "#                     continue\n",
    "#                 color = int(colors[i]) if None is not colors else samples_color\n",
    "#                 plt_line = k3d.line(dir_to_plot, \n",
    "#                                     shader='mesh', width=directions_width, color=color)\n",
    "#                 plot += plt_line\n",
    "\n",
    "    if None is not sharp_vert:\n",
    "        k3d_points = k3d.points(sharp_vert,\n",
    "                                point_size=sharpvert_psize, color=sharpvert_color)\n",
    "        plot += k3d_points\n",
    "        k3d_points.shader='flat'\n",
    "        \n",
    "        if None is not sharp_curves:            \n",
    "            if None is not sharpcurve_color:\n",
    "                color = sharpcurve_color\n",
    "            else:\n",
    "                import randomcolor\n",
    "                rand_color = randomcolor.RandomColor()\n",
    "            for i, vert_ind in enumerate(sharp_curves):\n",
    "                sharp_points_curve = mesh.vertices[vert_ind]\n",
    "                \n",
    "                if None is sharpcurve_color:\n",
    "                    color = rand_color.generate(hue='red')[0]\n",
    "                    color = int('0x' + color[1:], 16)\n",
    "                plt_line = k3d.line(sharp_points_curve, \n",
    "                                    shader='mesh', width=sharpcurve_width, color=color)\n",
    "                plot += plt_line\n",
    "        \n",
    "    plot.grid_visible = False\n",
    "    plot.display()\n",
    "    \n",
    "    if as_image:\n",
    "        plot.fetch_screenshot()\n",
    "        return Image(data=b64decode(plot.screenshot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sharpf.utils.abc_utils.hdf5.dataset import Hdf5File, PreloadTypes\n",
    "import sharpf.utils.abc_utils.hdf5.io_struct as io\n",
    "from sharpf.data.datasets.sharpf_io import PointCloudIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "PointCloudIO = io.HDF5IO({\n",
    "    'points': io.Float64('points'),\n",
    "    'normals': io.Float64('normals'),\n",
    "    'distances': io.Float64('distances'),\n",
    "    'directions': io.Float64('directions'),\n",
    "    'item_id': io.AsciiString('item_id'),\n",
    "    'orig_vert_indices': io.VarInt32('orig_vert_indices'),\n",
    "    'orig_face_indexes': io.VarInt32('orig_face_indexes'),\n",
    "    'has_sharp': io.Bool('has_sharp'),\n",
    "    'num_sharp_curves': io.Int8('num_sharp_curves'),\n",
    "    'num_surfaces': io.Int8('num_surfaces'),\n",
    "    'has_smell_coarse_surfaces_by_num_faces': io.Bool('has_smell_coarse_surfaces_by_num_faces'),\n",
    "    'has_smell_coarse_surfaces_by_angles': io.Bool('has_smell_coarse_surfaces_by_angles'),\n",
    "    'has_smell_deviating_resolution': io.Bool('has_smell_deviating_resolution'),\n",
    "    'has_smell_sharpness_discontinuities': io.Bool('has_smell_sharpness_discontinuities'),\n",
    "    'has_smell_bad_face_sampling': io.Bool('has_smell_bad_face_sampling'),\n",
    "    'has_smell_mismatching_surface_annotation': io.Bool('has_smell_mismatching_surface_annotation'),\n",
    "# 'voronoi': io.Float64('voronoi'),\n",
    "# 'normals_estimation_10': io.Float64('normals_estimation_10'),\n",
    "# 'normals_estimation_100': io.Float64('normals_estimation_100'),\n",
    "\n",
    "},\n",
    "len_label='has_sharp',\n",
    "compression='lzf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abc_0000_620_630_0.01.hdf5    fix_abc_0000_620_630_0.01_0.hdf5    \u001b[0m\u001b[01;34min\u001b[0m/\r\n",
      "abc_0000_6420_6430_0.02.hdf5  fix_abc_0000_6420_6430_0.02_0.hdf5  \u001b[01;34mout\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "ls /logs/repair_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_dataset = Hdf5File('/logs/repair_data/abc_0000_6420_6430_0.02.hdf5',\n",
    "                   io=PointCloudIO,\n",
    "                   preload=PreloadTypes.LAZY,\n",
    "                   labels='*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_dataset = Hdf5File('/logs/repair_data/fix_abc_0000_6420_6430_0.02_0.hdf5',\n",
    "                   io=PointCloudIO,\n",
    "                   preload=PreloadTypes.LAZY,\n",
    "                   labels='*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 386/386 [00:01<00:00, 355.26it/s]\n"
     ]
    }
   ],
   "source": [
    "MAX_DISTANCE = 1.0\n",
    "\n",
    "\n",
    "for i in tqdm(range(len(fix_dataset))):\n",
    "    \n",
    "    item = orig_dataset[i]\n",
    "    item_fix = fix_dataset[i]\n",
    "    \n",
    "#     directions = item['directions']\n",
    "#     distances = item['distances']\n",
    "# #     if np.any(distances < 1.0):\n",
    "# #         print(i)\n",
    "    \n",
    "#     far_from_sharp_distances = distances == MAX_DISTANCE\n",
    "    \n",
    "#     far_from_sharp_directions = (directions == 0).all(axis=1)\n",
    "    \n",
    "#     print(i, np.sum(far_from_sharp_distances == far_from_sharp_directions))\n",
    "    \n",
    "    for key in PointCloudIO.datasets:\n",
    "        if key in ['directions', 'distances', 'has_sharp', 'num_sharp_curves', 'item_id', 'has_smell_sharpness_discontinuities']:\n",
    "            continue\n",
    "        assert np.allclose(item[key], item_fix[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orig: True Fix: True\n",
      "Orig: 2 Fix: 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "314b5099c2894d58b06fa0d0fa6413a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = np.random.choice(len(orig_dataset))\n",
    "\n",
    "item = orig_dataset[idx]\n",
    "item_fix = fix_dataset[idx]\n",
    "\n",
    "points = np.concatenate((\n",
    "    item['points'],\n",
    "    item_fix['points'] + 1.0\n",
    "))\n",
    "distances = np.concatenate((\n",
    "    item['distances'],\n",
    "    item_fix['distances']\n",
    "))\n",
    "directions = np.concatenate((\n",
    "    item['directions'],\n",
    "    item_fix['directions']\n",
    "))\n",
    "\n",
    "print('Orig:', item['has_sharp'], 'Fix:', item_fix['has_sharp'])\n",
    "print('Orig:', item['num_sharp_curves'], 'Fix:', item_fix['num_sharp_curves'])\n",
    "\n",
    "display_sharpness(\n",
    "    mesh=None,\n",
    "    samples=points, samples_psize=0.03,\n",
    "    samples_distances=distances,\n",
    "    directions=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'has_smell_mismatching_surface_annotation': True,\n",
       " 'num_sharp_curves': 1,\n",
       " 'has_smell_coarse_surfaces_by_num_faces': False,\n",
       " 'item_id': b'00008920_9bfa988a35b44008848ee6c6_002',\n",
       " 'orig_vert_indices': array([    0,    51,    52,  1742,  1797,  2008,  2020,  2464,  2602,\n",
       "         2696,  2796, 15570, 15574, 15710], dtype=int32),\n",
       " 'points': array([[  2.21759859, -14.00891746,  -9.9172038 ],\n",
       "        [  2.22362587, -13.97707418,  -9.85334705],\n",
       "        [  2.18617541, -13.98002775,  -9.87605155],\n",
       "        ...,\n",
       "        [  2.44443316, -14.94824712,  -9.87028865],\n",
       "        [  2.79883901, -14.82575634,  -9.87337967],\n",
       "        [  1.94116076, -14.76577858, -10.43676926]]),\n",
       " 'normals': array([[ 0.        ,  0.        , -1.        ],\n",
       "        [ 0.        ,  0.        , -1.        ],\n",
       "        [ 0.        ,  0.        , -1.        ],\n",
       "        ...,\n",
       "        [ 0.        ,  0.        , -1.        ],\n",
       "        [ 0.        ,  0.        , -1.        ],\n",
       "        [ 0.96588654,  0.25831997,  0.01827536]]),\n",
       " 'directions': array([[-0.82931862, -0.55413355,  0.07185355],\n",
       "        [-0.83063896, -0.55501584, -0.04464046],\n",
       "        [-0.83145947, -0.55556394, -0.00448127],\n",
       "        ...,\n",
       "        [-0.98065284, -0.19506424, -0.01630753],\n",
       "        [-0.98076765, -0.19508709, -0.00579233],\n",
       "        [-0.07094684, -0.01411219,  0.99737847]]),\n",
       " 'orig_face_indexes': array([  487,   552,   859,  1379,  1604,  1710,  1748,  1771,  1789,\n",
       "         1880,  2747, 30383, 30384, 30609, 30622], dtype=int32),\n",
       " 'has_smell_coarse_surfaces_by_angles': False,\n",
       " 'distances': array([0.5397741 , 0.56164135, 0.52830686, ..., 0.49856595, 0.87000713,\n",
       "        0.55981703]),\n",
       " 'num_surfaces': 2,\n",
       " 'has_sharp': True,\n",
       " 'has_smell_bad_face_sampling': True,\n",
       " 'has_smell_sharpness_discontinuities': False,\n",
       " 'has_smell_deviating_resolution': False}"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sharpf.data import DataGenerationException\n",
    "from sharpf.utils.abc_utils.abc.abc_data import ABCModality, ABCChunk, ABC_7Z_FILEMASK\n",
    "from sharpf.data.annotation import ANNOTATOR_BY_TYPE\n",
    "from sharpf.data.datasets.sharpf_io import save_point_patches\n",
    "from sharpf.data.mesh_nbhoods import NBHOOD_BY_TYPE\n",
    "from sharpf.data.noisers import NOISE_BY_TYPE\n",
    "from sharpf.data.point_samplers import SAMPLER_BY_TYPE\n",
    "from sharpf.utils.abc_utils.abc.feature_utils import compute_features_nbhood, remove_boundary_features, get_curves_extents\n",
    "from sharpf.utils.py_utils.console import eprint_t\n",
    "from sharpf.utils.py_utils.os import add_suffix\n",
    "from sharpf.utils.py_utils.config import load_func_from_config\n",
    "from sharpf.utils.abc_utils.mesh.io import trimesh_load\n",
    "from sharpf.utils.geometry import mean_mmd\n",
    "import sharpf.data.data_smells as smells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ABCChunk(['/data/abc/abc_0001_obj_v00.7z', '/data/abc/abc_0001_feat_v00.7z']) as data_holder:\n",
    "    item_abc = data_holder.get(item['item_id'].decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mesh, vertex_normals, vertex_normal_indices = trimesh_load(item.obj)\n",
    "mesh, _, _ = trimesh_load(item_abc.obj)\n",
    "\n",
    "features = yaml.load(item_abc.feat, Loader=yaml.Loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/code/scripts/data_scripts/configs/pointcloud_datasets/dataset_config_high_res_clean.json') as config_file:\n",
    "    config = json.load(config_file)\n",
    "\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_mesh(mesh, features, shape_fabrication_extent, resolution_3d,\n",
    "               short_curve_quantile=0.05, n_points_per_short_curve=4):\n",
    "    # compute standard size spatial extent\n",
    "    mesh_extent = np.max(mesh.bounding_box.extents)\n",
    "    mesh = mesh.apply_scale(shape_fabrication_extent / mesh_extent)\n",
    "\n",
    "    # compute lengths of curves\n",
    "    sharp_curves_lengths = get_curves_extents(mesh, features)\n",
    "\n",
    "    least_len = np.quantile(sharp_curves_lengths, short_curve_quantile)\n",
    "    least_len_mm = resolution_3d * n_points_per_short_curve\n",
    "\n",
    "    mesh = mesh.apply_scale(least_len_mm / least_len)\n",
    "\n",
    "    return mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mm/pixel\n",
    "HIGH_RES = 0.02\n",
    "MED_RES = 0.05\n",
    "LOW_RES = 0.125\n",
    "XLOW_RES = 0.25\n",
    "\n",
    "shape_fabrication_extent = config.get('shape_fabrication_extent', 10.0)\n",
    "base_n_points_per_short_curve = config.get('base_n_points_per_short_curve', 8)\n",
    "base_resolution_3d = config.get('base_resolution_3d', LOW_RES)\n",
    "\n",
    "short_curve_quantile = config.get('short_curve_quantile', 0.05)\n",
    "\n",
    "mesh = scale_mesh(mesh, features, shape_fabrication_extent, base_resolution_3d,\n",
    "                      short_curve_quantile=short_curve_quantile,\n",
    "                      n_points_per_short_curve=base_n_points_per_short_curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotator = load_func_from_config(ANNOTATOR_BY_TYPE, config['annotation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# surf_vert_indices = np.array(features['surfaces'][0]['vert_indices'])\n",
    "# surf_verts = mesh.vertices[surf_vert_indices]\n",
    "# surf_vert_indices2 = np.array(features['surfaces'][0]['vert_indices'])\n",
    "# surf_verts2 = mesh.vertices[surf_vert_indices]\n",
    "\n",
    "\n",
    "display_sharpness(\n",
    "    mesh, plot_meshvert=True, meshvert_psize=HIGH_RES,\n",
    "    sharp_vert=None, \n",
    "    sharpvert_psize=HIGH_RES,\n",
    "#     sharp_vert=mesh.vertices[boundary_curves[1]['vert_indices']],\n",
    "    samples_psize=HIGH_RES,\n",
    "    samples=item['points'],\n",
    "    samples_distances=distances,\n",
    "    directions=directions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sharpf.utils.abc_utils.mesh.indexing import reindex_array, reindex_zerobased\n",
    "from sharpf.utils.abc_utils.abc.feature_utils import get_surface_as_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbhood = reindex_zerobased(mesh, item['orig_vert_indices'], item['orig_face_indexes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_features_nbhood(\n",
    "        mesh,\n",
    "        features,\n",
    "        mesh_face_indexes,\n",
    "        mesh_vertex_indexes=None,\n",
    "        deduce_verts_from_faces=False,\n",
    "):\n",
    "    \"\"\"Extracts curves for the neighbourhood.\"\"\"\n",
    "\n",
    "    if deduce_verts_from_faces:\n",
    "        mesh_vertex_indexes = np.unique(mesh.faces[mesh_face_indexes].ravel())\n",
    "\n",
    "    nbhood_curves = []\n",
    "    for curve in features['curves']:\n",
    "        curve_vertex_indexes = np.array(curve['vert_indices'])\n",
    "        curve_vertex_indexes = curve_vertex_indexes[\n",
    "            np.where(np.isin(curve_vertex_indexes, mesh_vertex_indexes))[0]]\n",
    "        if len(curve_vertex_indexes) == 0:\n",
    "            continue\n",
    "\n",
    "        curve_vertex_indexes = reindex_array(curve_vertex_indexes, mesh_vertex_indexes)\n",
    "\n",
    "        nbhood_curve = deepcopy(curve)\n",
    "        nbhood_curve['vert_indices'] = curve_vertex_indexes\n",
    "        nbhood_curves.append(nbhood_curve)\n",
    "\n",
    "    nbhood_surfaces = []\n",
    "    for idx, surface in enumerate(features['surfaces']):\n",
    "        surface_face_indexes = np.array(surface['face_indices'])\n",
    "        surface_face_indexes = surface_face_indexes[\n",
    "            np.where(np.isin(surface_face_indexes, mesh_face_indexes))[0]]\n",
    "        if len(surface_face_indexes) == 0:\n",
    "            continue\n",
    "\n",
    "        surface_faces = reindex_array(mesh.faces[surface_face_indexes], mesh_vertex_indexes)\n",
    "\n",
    "        nbhood_surface = deepcopy(surface)\n",
    "        nbhood_surface['face_indices'] = reindex_array(surface_face_indexes, mesh_face_indexes)\n",
    "        nbhood_surface['vert_indices'] = np.unique(surface_faces)\n",
    "        nbhood_surfaces.append(nbhood_surface)\n",
    "\n",
    "    nbhood_features = {\n",
    "        'curves': nbhood_curves,\n",
    "        'surfaces': nbhood_surfaces,\n",
    "    }\n",
    "    return nbhood_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_boundary_vertex_indexes(mesh):\n",
    "    mesh_edge_indexes, mesh_edge_counts = np.unique(\n",
    "        mesh.faces_unique_edges.flatten(), return_counts=True\n",
    "    )\n",
    "    boundary_edges = mesh.edges_unique[\n",
    "        mesh_edge_indexes[\n",
    "            np.where(mesh_edge_counts == 1)[0]\n",
    "        ]\n",
    "    ]\n",
    "    boundary_vertex_indexes = np.unique(boundary_edges.flatten())\n",
    "    return boundary_vertex_indexes, boundary_edges\n",
    "\n",
    "\n",
    "def remove_boundary_features(mesh, features, how='none'):\n",
    "    \"\"\"Removes features indexed into vertex edges adjacent to 1 face only.\n",
    "    :param how: 'all_verts': remove entire feature curve if all vertices are boundary\n",
    "                'edges': remove vertices that belong to boundary edges only (not to other edges)\n",
    "                'verts': remove vertices that are boundary\n",
    "                'none': do nothing\n",
    "    \"\"\"\n",
    "    if how == 'none':\n",
    "        return features\n",
    "\n",
    "    boundary_vertex_indexes, boundary_edges = get_boundary_vertex_indexes(mesh)\n",
    "\n",
    "    non_boundary_curves = []\n",
    "    for curve in features['curves']:\n",
    "        non_boundary_curve = deepcopy(curve)\n",
    "\n",
    "        if how == 'all_verts':\n",
    "            if np.all([vert_index in boundary_vertex_indexes\n",
    "                       for vert_index in curve['vert_indices']]):\n",
    "                continue\n",
    "\n",
    "        elif how == 'verts':\n",
    "            non_boundary_vert_indices = np.array([\n",
    "                vert_index for vert_index in curve['vert_indices']\n",
    "                if vert_index not in boundary_vertex_indexes\n",
    "            ])\n",
    "            if len(non_boundary_vert_indices) == 0:\n",
    "                continue\n",
    "            non_boundary_curve['vert_indices'] = non_boundary_vert_indices\n",
    "\n",
    "        elif how == 'edges':\n",
    "            curve_edges = mesh.edges_unique[\n",
    "                np.where(\n",
    "                    np.all(np.isin(mesh.edges_unique, curve['vert_indices']), axis=1)\n",
    "                )[0]\n",
    "            ]\n",
    "            non_boundary = (curve_edges[:, None] != boundary_edges).any(2).all(1)\n",
    "            non_boundary_vert_indices = np.unique(curve_edges[non_boundary])\n",
    "#             if len(non_boundary_vert_indices) == 0:\n",
    "#                 continue\n",
    "            non_boundary_curve['vert_indices'] = non_boundary_vert_indices\n",
    "\n",
    "        non_boundary_curves.append(non_boundary_curve)\n",
    "\n",
    "    non_boundary_features = {\n",
    "        'curves': non_boundary_curves,\n",
    "        'surfaces': features.get('surfaces', [])\n",
    "    }\n",
    "    return non_boundary_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbhood_features = compute_features_nbhood(\n",
    "    mesh,\n",
    "    features,\n",
    "    item['orig_face_indexes'],\n",
    "    item['orig_vert_indices'],\n",
    "    deduce_verts_from_faces=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(nbhood_features['curves'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbhood_features = remove_boundary_features(nbhood, nbhood_features, how='edges')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(nbhood_features['curves'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_a, directions_a, has_sharp_a = annotator.annotate(nbhood, nbhood_features, item['points'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projections, distances = annotator.do_annotate(nbhood, nbhood_features, item['points'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances, directions = compute_bounded_labels(\n",
    "    points, projections, distances=distances,\n",
    "    max_distance=self.distance_upper_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_sharpness(\n",
    "    nbhood, plot_meshvert=True, meshvert_psize=HIGH_RES,\n",
    "    sharp_vert=None, \n",
    "    shaarpvert_psize=HIGH_RES,\n",
    "#     sharp_vert=mesh.vertices[boundary_curves[1]['vert_indices']],\n",
    "    samples_psize=HIGH_RES,\n",
    "    samples=item['points'],\n",
    "    samples_distances=distances,\n",
    "    directions=directions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sharpf.data import DataGenerationException\n",
    "from sharpf.utils.abc_utils.abc.abc_data import ABCModality, ABCChunk, ABC_7Z_FILEMASK\n",
    "from sharpf.data.annotation import ANNOTATOR_BY_TYPE\n",
    "from sharpf.data.datasets.sharpf_io import save_point_patches\n",
    "from sharpf.data.mesh_nbhoods import NBHOOD_BY_TYPE\n",
    "from sharpf.data.noisers import NOISE_BY_TYPE\n",
    "from sharpf.data.point_samplers import SAMPLER_BY_TYPE\n",
    "from sharpf.utils.abc_utils.abc.feature_utils import compute_features_nbhood, remove_boundary_features, get_curves_extents\n",
    "from sharpf.utils.py_utils.console import eprint_t\n",
    "from sharpf.utils.py_utils.os import add_suffix\n",
    "from sharpf.utils.py_utils.config import load_func_from_config\n",
    "from sharpf.utils.abc_utils.mesh.io import trimesh_load\n",
    "from sharpf.utils.geometry import mean_mmd\n",
    "import sharpf.data.data_smells as smells\n",
    "from sharpf.utils.abc_utils.mesh.indexing import reindex_array, reindex_zerobased\n",
    "from sharpf.utils.abc_utils.abc.feature_utils import get_surface_as_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mm/pixel\n",
    "HIGH_RES = 0.02\n",
    "MED_RES = 0.05\n",
    "LOW_RES = 0.125\n",
    "XLOW_RES = 0.25\n",
    "\n",
    "data_holders_by_chunk = {\n",
    "    0: None,\n",
    "    1: None,\n",
    "}\n",
    "\n",
    "\n",
    "def get_data_holder(chunk_id):\n",
    "    global data_holders_by_chunk\n",
    "    if None is data_holders_by_chunk.get(chunk_id):\n",
    "        obj_filename = '/data/abc/abc_{}_obj_v00.7z'.format(str(chunk_id).zfill(4))\n",
    "        feat_filename = '/data/abc/abc_{}_feat_v00.7z'.format(str(chunk_id).zfill(4))\n",
    "        data_holders_by_chunk[chunk_id] = ABCChunk([obj_filename, feat_filename])\n",
    "        \n",
    "    data_holder = data_holders_by_chunk[chunk_id]\n",
    "    return data_holder\n",
    "\n",
    "\n",
    "def fix_patch(patch, chunk_ids, config):\n",
    "    \n",
    "    item = None\n",
    "    for chunk_id in chunk_ids:\n",
    "        try:\n",
    "            data_holder = get_data_holder(chunk_id)\n",
    "            item = data_holder.get(patch['item_id'].decode())\n",
    "        except KeyError:\n",
    "            continue\n",
    "            \n",
    "    if None is item:\n",
    "        raise ValueError()\n",
    "\n",
    "    mesh, _, _ = trimesh_load(item.obj)\n",
    "    features = yaml.load(item.feat, Loader=yaml.Loader)\n",
    "\n",
    "\n",
    "    shape_fabrication_extent = config.get('shape_fabrication_extent', 10.0)\n",
    "    base_n_points_per_short_curve = config.get('base_n_points_per_short_curve', 8)\n",
    "    base_resolution_3d = config.get('base_resolution_3d', LOW_RES)\n",
    "    short_curve_quantile = config.get('short_curve_quantile', 0.05)\n",
    "    annotator = load_func_from_config(ANNOTATOR_BY_TYPE, config['annotation'])\n",
    "\n",
    "    mesh = scale_mesh(mesh, features, shape_fabrication_extent, base_resolution_3d,\n",
    "                          short_curve_quantile=short_curve_quantile,\n",
    "                          n_points_per_short_curve=base_n_points_per_short_curve)\n",
    "\n",
    "    nbhood = reindex_zerobased(\n",
    "        mesh,\n",
    "        patch['orig_vert_indices'],\n",
    "        patch['orig_face_indexes'])\n",
    "\n",
    "    nbhood_features = compute_features_nbhood(\n",
    "        mesh,\n",
    "        features,\n",
    "        patch['orig_face_indexes'],\n",
    "        patch['orig_vert_indices'],\n",
    "        deduce_verts_from_faces=False)\n",
    "\n",
    "    nbhood_features = remove_boundary_features(\n",
    "        nbhood,\n",
    "        nbhood_features,\n",
    "        how='edges')\n",
    "    num_sharp_curves = len([curve for curve in nbhood_features['curves'] if curve['sharp']])\n",
    "\n",
    "    distances, directions, has_sharp = annotator.annotate(\n",
    "        nbhood,\n",
    "        nbhood_features,\n",
    "        patch['points'])\n",
    "        \n",
    "    fixed_part = {\n",
    "        'distances': distances,\n",
    "        'directions': directions,\n",
    "        'has_sharp': has_sharp,\n",
    "        'num_sharp_curves': num_sharp_curves,\n",
    "    }\n",
    "        \n",
    "    return fixed_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/code/scripts/data_scripts/configs/pointcloud_datasets/dataset_config_high_res_clean.json') as config_file:\n",
    "    config = json.load(config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_mesh(mesh, features, shape_fabrication_extent, resolution_3d,\n",
    "               short_curve_quantile=0.05, n_points_per_short_curve=4):\n",
    "    # compute standard size spatial extent\n",
    "    mesh_extent = np.max(mesh.bounding_box.extents)\n",
    "    mesh = mesh.apply_scale(shape_fabrication_extent / mesh_extent)\n",
    "\n",
    "    # compute lengths of curves\n",
    "    sharp_curves_lengths = get_curves_extents(mesh, features)\n",
    "\n",
    "    least_len = np.quantile(sharp_curves_lengths, short_curve_quantile)\n",
    "    least_len_mm = resolution_3d * n_points_per_short_curve\n",
    "\n",
    "    mesh = mesh.apply_scale(least_len_mm / least_len)\n",
    "\n",
    "    return mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.9 s, sys: 280 ms, total: 11.2 s\n",
      "Wall time: 11.2 s\n"
     ]
    }
   ],
   "source": [
    "%time fix = fix_patch(dataset[14], [0, 1], config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(fix['directions'], dataset[14]['directions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'distances': array([0.25064018, 0.26161474, 0.2449492 , ..., 0.71209611, 0.02970788,\n",
       "        0.10968887]),\n",
       " 'normals': array([[ 0.        ,  0.        , -1.        ],\n",
       "        [ 0.        ,  0.        , -1.        ],\n",
       "        [ 0.        ,  0.        , -1.        ],\n",
       "        ...,\n",
       "        [ 0.        ,  0.        , -1.        ],\n",
       "        [-0.44120994,  0.89737676,  0.00698177],\n",
       "        [-0.26524471,  0.65872628, -0.70407737]]),\n",
       " 'orig_face_indexes': array([ 1039,  1040,  1199,  1200,  1201,  1202,  1247,  1248,  1249,\n",
       "         1250,  1285,  1286,  1287,  1288,  1381,  1382,  1383,  1384,\n",
       "         1441,  1442,  1443,  1471,  1472,  1495,  1521,  1522,  1543,\n",
       "         1544,  1546,  1567,  1568,  2565,  3184,  3329,  3375,  3422,\n",
       "         3620,  8710,  8766,  8789,  9045,  9085,  9088,  9174,  9226,\n",
       "         9234,  9293,  9305,  9329,  9353,  9393,  9418,  9448,  9489,\n",
       "         9515,  9555,  9770,  9815, 10171, 10177, 10390, 10402, 10437,\n",
       "        10476, 10590, 10616, 10674, 10887, 10954, 10960, 11014, 11078,\n",
       "        11144, 11165, 11246, 11283, 11400, 11428, 11658, 11953, 11967,\n",
       "        12074, 12172, 12208, 12217, 12440, 12727, 12734, 12737, 12746,\n",
       "        12958, 12997, 13208, 13230, 13262, 13354, 13425, 13614, 13626,\n",
       "        13638, 13698, 13711, 14139, 14187, 14235, 14422, 14424, 14427,\n",
       "        14508, 14634, 14646, 14859, 14956, 14962, 15044, 15046],\n",
       "       dtype=int32),\n",
       " 'has_sharp': True,\n",
       " 'has_smell_mismatching_surface_annotation': True,\n",
       " 'normals_estimation_100': array([[ 0.        ,  0.        ,  1.        ],\n",
       "        [ 0.        ,  0.        ,  1.        ],\n",
       "        [ 0.        ,  0.        ,  1.        ],\n",
       "        ...,\n",
       "        [ 0.        ,  0.        ,  1.        ],\n",
       "        [-0.40780352,  0.78704798, -0.46287339],\n",
       "        [-0.28624928,  0.59274764, -0.75280249]]),\n",
       " 'num_surfaces': 3,\n",
       " 'item_id': b'00010781_8b2cd8a04a99446381446301_009',\n",
       " 'normals_estimation_10': array([[ 0.        ,  0.        ,  1.        ],\n",
       "        [ 0.        ,  0.        ,  1.        ],\n",
       "        [ 0.        ,  0.        ,  1.        ],\n",
       "        ...,\n",
       "        [ 0.        ,  0.        ,  1.        ],\n",
       "        [-0.38083411,  0.90749954, -0.17722854],\n",
       "        [-0.26524471,  0.65872628, -0.70407737]]),\n",
       " 'num_sharp_curves': 2,\n",
       " 'points': array([[ 2.09922176, -3.5293723 ,  0.        ],\n",
       "        [ 2.11759184, -3.53113516,  0.        ],\n",
       "        [ 2.11649666, -3.51234917,  0.        ],\n",
       "        ...,\n",
       "        [ 1.82550691, -4.18868755,  0.        ],\n",
       "        [ 1.52499415, -3.22857703,  0.31542143],\n",
       "        [ 1.38508868, -3.51566745,  0.07789261]]),\n",
       " 'voronoi': array([0., 0., 0., ..., 0., 0., 0.], dtype=float32),\n",
       " 'orig_vert_indices': array([ 370,  371,  372,  373,  374,  375,  376,  377,  483,  484,  485,\n",
       "         486,  487, 2212, 2224, 2230, 2242, 2248, 2260, 2266, 2275, 2287,\n",
       "        2293, 2305, 2934, 2963, 2992, 3094, 5490, 5518, 5600, 5686, 5698,\n",
       "        5758, 5861, 5890, 6086, 6122, 6134, 6190, 6256, 6258, 6267, 6439,\n",
       "        6570, 6656, 6721, 6849, 6908, 7039, 7130, 7148, 7162, 7224, 7239,\n",
       "        7241, 7254, 7276, 7521, 7651, 7745, 7790, 7961, 7966, 8169, 8263,\n",
       "        8280, 8297, 8302, 8349, 8363, 8388, 8422], dtype=int32),\n",
       " 'has_smell_bad_face_sampling': True,\n",
       " 'has_smell_coarse_surfaces_by_angles': False,\n",
       " 'has_smell_sharpness_discontinuities': False,\n",
       " 'has_smell_deviating_resolution': False,\n",
       " 'has_smell_coarse_surfaces_by_num_faces': False,\n",
       " 'directions': array([[-0.51516125,  0.85708862,  0.        ],\n",
       "        [-0.51516116,  0.85708887,  0.        ],\n",
       "        [-0.51516142,  0.85708841,  0.        ],\n",
       "        ...,\n",
       "        [-0.40843827,  0.91278441,  0.        ],\n",
       "        [-0.00308232,  0.00626428, -0.99994197],\n",
       "        [ 0.26298408, -0.65311199, -0.7101168 ]])}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectors(colors=array([], dtype=uint32), head_color=255, id=139759872265688, model_matrix=array([[1., 0., 0., 0.],\n",
      "       [0., 1., 0., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 0., 1.]], dtype=float32), origin_color=255, origins=array([[ 2.0992217 , -3.5293722 ,  0.        ],\n",
      "       [ 2.1175919 , -3.531135  ,  0.        ],\n",
      "       [ 2.1164966 , -3.5123491 ,  0.        ],\n",
      "       ...,\n",
      "       [ 1.8255069 , -4.1886873 ,  0.        ],\n",
      "       [ 1.5249941 , -3.2285771 ,  0.31542143],\n",
      "       [ 1.3850887 , -3.5156674 ,  0.07789262]], dtype=float32), type='Vectors', use_head=True, vectors=array([[-1.2912011e-01,  2.1482085e-01,  0.0000000e+00],\n",
      "       [-1.3477376e-01,  2.2422709e-01,  0.0000000e+00],\n",
      "       [-1.2618838e-01,  2.0994312e-01,  0.0000000e+00],\n",
      "       ...,\n",
      "       [-2.9084730e-01,  6.4999020e-01,  0.0000000e+00],\n",
      "       [-9.1569105e-05,  1.8609840e-04, -2.9706152e-02],\n",
      "       [ 2.8846428e-02, -7.1639121e-02, -7.7891916e-02]], dtype=float32))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniconda/envs/py36/lib/python3.6/site-packages/traittypes/traittypes.py:101: UserWarning: Given trait value dtype \"float64\" does not match required type \"float32\". A coerced copy has been created.\n",
      "  np.dtype(self.dtype).name))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31d903c51f8a4834926c5004790a6520",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_sharpness(\n",
    "    None, plot_meshvert=True, meshvert_psize=HIGH_RES,\n",
    "    sharp_vert=None, \n",
    "    sharpvert_psize=HIGH_RES,\n",
    "#     sharp_vert=mesh.vertices[boundary_curves[1]['vert_indices']],\n",
    "    samples_psize=HIGH_RES,\n",
    "    samples=dataset[14]['points'],\n",
    "    samples_distances=fix['distances'],\n",
    "    directions=fix['directions'] / np.linalg.norm()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
