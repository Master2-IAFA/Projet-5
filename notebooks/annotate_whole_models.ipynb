{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary config/cache directory at /tmp/matplotlib-185k5w31 because the default path (/home/user/.cache/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "import k3d\n",
    "import yaml\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "import warnings\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OPENBLAS_NUM_THREADS'] = '10'\n",
    "os.environ['OMP_NUM_THREADS'] = '10'\n",
    "os.environ['MKL_NUM_THREADS'] = '10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_sharpness(mesh=None, plot_meshvert=True,\n",
    "                      samples=None, samples_distances=None,\n",
    "                      sharp_vert=None, sharp_curves=None,\n",
    "                      directions=None, directions_width=0.0025,\n",
    "                      samples_color=0x0000ff, samples_psize=0.002, \n",
    "                      mesh_color=0xbbbbbb, meshvert_color=0x666666, meshvert_psize=0.0025,\n",
    "                      sharpvert_color=0xff0000, sharpvert_psize=0.0025,\n",
    "                      sharpcurve_color=None, sharpcurve_width=0.0025,\n",
    "                      as_image=False, plot_height=768):\n",
    "    \n",
    "    plot = k3d.plot(height=plot_height)\n",
    "    \n",
    "    if None is not mesh:\n",
    "        k3d_mesh = k3d.mesh(mesh.vertices, mesh.faces, color=mesh_color)\n",
    "        plot += k3d_mesh\n",
    "\n",
    "        if plot_meshvert:\n",
    "            k3d_points = k3d.points(mesh.vertices, \n",
    "                                    point_size=meshvert_psize, color=meshvert_color)\n",
    "            plot += k3d_points\n",
    "            k3d_points.shader='flat'\n",
    "\n",
    "    if None is not samples:\n",
    "        colors = None\n",
    "        if None is not samples_distances:\n",
    "            max_dist = 0.5\n",
    "\n",
    "            colors = k3d.helpers.map_colors(\n",
    "                samples_distances, k3d.colormaps.matplotlib_color_maps.coolwarm_r, [0, max_dist]\n",
    "            ).astype(np.uint32)\n",
    "            k3d_points = k3d.points(samples, point_size=samples_psize, colors=colors)\n",
    "        else:\n",
    "            k3d_points = k3d.points(samples, point_size=samples_psize, color=samples_color)\n",
    "        plot += k3d_points\n",
    "        k3d_points.shader='flat'\n",
    "        \n",
    "        if None is not directions:\n",
    "            vectors = k3d.vectors(\n",
    "                samples,\n",
    "                directions * samples_distances[..., np.newaxis],\n",
    "                use_head=False, \n",
    "                line_width=directions_width)\n",
    "            print(vectors)\n",
    "            plot += vectors\n",
    "\n",
    "#             directions_to_plot = np.hstack((samples, samples + directions))\n",
    "            \n",
    "#             for i, dir_to_plot in enumerate(directions_to_plot):\n",
    "#                 dir_to_plot = dir_to_plot.reshape((2, 3))\n",
    "#                 if np.all(dir_to_plot[0] == dir_to_plot[1]):\n",
    "#                     continue\n",
    "#                 color = int(colors[i]) if None is not colors else samples_color\n",
    "#                 plt_line = k3d.line(dir_to_plot, \n",
    "#                                     shader='mesh', width=directions_width, color=color)\n",
    "#                 plot += plt_line\n",
    "\n",
    "    if None is not sharp_vert:\n",
    "        k3d_points = k3d.points(sharp_vert,\n",
    "                                point_size=sharpvert_psize, color=sharpvert_color)\n",
    "        plot += k3d_points\n",
    "        k3d_points.shader='flat'\n",
    "        \n",
    "        if None is not sharp_curves:            \n",
    "            if None is not sharpcurve_color:\n",
    "                color = sharpcurve_color\n",
    "            else:\n",
    "                import randomcolor\n",
    "                rand_color = randomcolor.RandomColor()\n",
    "            for i, vert_ind in enumerate(sharp_curves):\n",
    "                sharp_points_curve = mesh.vertices[vert_ind]\n",
    "                \n",
    "                if None is sharpcurve_color:\n",
    "                    color = rand_color.generate(hue='red')[0]\n",
    "                    color = int('0x' + color[1:], 16)\n",
    "                plt_line = k3d.line(sharp_points_curve, \n",
    "                                    shader='mesh', width=sharpcurve_width, color=color)\n",
    "                plot += plt_line\n",
    "        \n",
    "    plot.grid_visible = False\n",
    "    plot.display()\n",
    "    \n",
    "    if as_image:\n",
    "        plot.fetch_screenshot()\n",
    "        return Image(data=b64decode(plot.screenshot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mm/pixel\n",
    "HIGH_RES = 0.02\n",
    "MED_RES = 0.05\n",
    "LOW_RES = 0.125\n",
    "XLOW_RES = 0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Working with point patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sharpf.data import DataGenerationException\n",
    "from sharpf.utils.abc_utils.abc.abc_data import ABCModality, ABCChunk, ABC_7Z_FILEMASK\n",
    "from sharpf.data.annotation import ANNOTATOR_BY_TYPE\n",
    "from sharpf.data.datasets.sharpf_io import save_point_patches\n",
    "from sharpf.data.mesh_nbhoods import NBHOOD_BY_TYPE\n",
    "from sharpf.data.noisers import NOISE_BY_TYPE\n",
    "from sharpf.data.point_samplers import SAMPLER_BY_TYPE\n",
    "from sharpf.utils.abc_utils.abc.feature_utils import compute_features_nbhood, remove_boundary_features, get_curves_extents\n",
    "from sharpf.utils.py_utils.console import eprint_t\n",
    "from sharpf.utils.py_utils.os import add_suffix\n",
    "from sharpf.utils.py_utils.config import load_func_from_config\n",
    "from sharpf.utils.abc_utils.mesh.io import trimesh_load\n",
    "from sharpf.utils.geometry import mean_mmd\n",
    "import sharpf.data.data_smells as smells\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ABCChunk(['/data/abc/abc_0022_obj_v00.7z', '/data/abc/abc_0022_feat_v00.7z']) as data_holder:\n",
    "    item = data_holder.get('00220090_ec51899db1f5298d674b3205_037')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'00220090_ec51899db1f5298d674b3205_037'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item.item_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mesh, vertex_normals, vertex_normal_indices = trimesh_load(item.obj)\n",
    "mesh, _, _ = trimesh_load(item.obj)\n",
    "\n",
    "features = yaml.load(item.feat, Loader=yaml.Loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh2 = mesh.copy()\n",
    "mesh2._validate = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<trimesh.Trimesh(vertices.shape=(14474, 3), faces.shape=(28944, 3))>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mesh2.process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<trimesh.Trimesh(vertices.shape=(14474, 3), faces.shape=(28944, 3))>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mesh.is_watertight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 False\n",
      "1 False\n",
      "2 False\n",
      "3 False\n",
      "4 True\n",
      "5 True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniconda/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:3: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(features['surfaces'])):\n",
    "    print(i, np.array(np.unique(mesh.faces[features['surfaces'][i]['face_indices']]) == \n",
    "                      np.sort(features['surfaces'][i]['vert_indices'])).all()\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'shape_fabrication_extent': 10.0,\n",
       " 'short_curve_quantile': 0.25,\n",
       " 'base_n_points_per_short_curve': 8,\n",
       " 'base_resolution_3d': 0.125,\n",
       " 'neighbourhood': {'type': 'random_euclidean_sphere',\n",
       "  'max_patches_per_mesh': 10000,\n",
       "  'n_vertices': None,\n",
       "  'centroid': None,\n",
       "  'centroid_mode': 'poisson_disk',\n",
       "  'radius_base': 10.0,\n",
       "  'radius_delta': 0.0,\n",
       "  'geodesic_patches': True,\n",
       "  'radius_scale_mode': 'no_scale'},\n",
       " 'sampling': {'type': 'poisson_disk',\n",
       "  'n_points': 4096,\n",
       "  'resolution_3d': 0.02,\n",
       "  'crop_center': True},\n",
       " 'noise': {'type': 'isotropic_gaussian', 'scale': 0.0},\n",
       " 'annotation': {'type': 'surface_based_aabb', 'distance_upper_bound': 1.0},\n",
       " 'smell_coarse_surfaces_by_num_edges': {'num_edges_threshold': 8},\n",
       " 'smell_coarse_surfaces_by_angles': {'max_angle_threshold_degrees': 10.0},\n",
       " 'smell_deviating_resolution': {'resolution_3d': 0.02,\n",
       "  'resolution_deviation_tolerance': 0.01},\n",
       " 'smell_sharpness_discontinuities': {},\n",
       " 'smell_bad_face_sampling': {'min_points_per_face': 0.02,\n",
       "  'max_points_per_face': 20.0}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('/code/scripts/data_scripts/configs/pointcloud_datasets/dataset_config_high_res_clean.json') as config_file:\n",
    "    config = json.load(config_file)\n",
    "\n",
    "config['neighbourhood']['max_patches_per_mesh'] = 10000\n",
    "# config['sampling']['resolution_3d'] = 0.05\n",
    "# config['smell_deviating_resolution'] = {\n",
    "#     'resolution_3d': 0.05,\n",
    "#     'resolution_deviation_tolerance': 0.05 / 2\n",
    "# }\n",
    "config['noise'] = {\n",
    "    'type': 'isotropic_gaussian',\n",
    "    'scale': 0.0,\n",
    "}\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_fabrication_extent = config.get('shape_fabrication_extent', 10.0)\n",
    "base_n_points_per_short_curve = config.get('base_n_points_per_short_curve', 8)\n",
    "base_resolution_3d = config.get('base_resolution_3d', LOW_RES)\n",
    "short_curve_quantile = config.get('short_curve_quantile', 0.05)\n",
    "\n",
    "nbhood_extractor = load_func_from_config(NBHOOD_BY_TYPE, config['neighbourhood'])\n",
    "sampler = load_func_from_config(SAMPLER_BY_TYPE, config['sampling'])\n",
    "noiser = load_func_from_config(NOISE_BY_TYPE, config['noise'])\n",
    "annotator = load_func_from_config(ANNOTATOR_BY_TYPE, config['annotation'])\n",
    "\n",
    "\n",
    "smell_coarse_surfaces_by_num_edges = smells.SmellCoarseSurfacesByNumEdges.from_config(config['smell_coarse_surfaces_by_num_edges'])\n",
    "smell_coarse_surfaces_by_angles = smells.SmellCoarseSurfacesByAngles.from_config(config['smell_coarse_surfaces_by_angles'])\n",
    "smell_deviating_resolution = smells.SmellDeviatingResolution.from_config(config['smell_deviating_resolution'])\n",
    "smell_sharpness_discontinuities = smells.SmellSharpnessDiscontinuities.from_config(config['smell_sharpness_discontinuities'])\n",
    "smell_bad_face_sampling = smells.SmellBadFaceSampling.from_config(config['smell_bad_face_sampling'])\n",
    "smell_mesh_self_intersections = smells.SmellMeshSelfIntersections()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def scale_mesh(mesh, features, shape_fabrication_extent, resolution_3d,\n",
    "               short_curve_quantile=0.05, n_points_per_short_curve=4):\n",
    "    # compute standard size spatial extent\n",
    "    mesh_extent = np.max(mesh.bounding_box.extents)\n",
    "    mesh = mesh.apply_scale(shape_fabrication_extent / mesh_extent)\n",
    "\n",
    "    # compute lengths of curves\n",
    "    sharp_curves_lengths = get_curves_extents(mesh, features)\n",
    "\n",
    "    least_len = np.quantile(sharp_curves_lengths, short_curve_quantile)\n",
    "    least_len_mm = resolution_3d * n_points_per_short_curve\n",
    "\n",
    "    mesh = mesh.apply_scale(least_len_mm / least_len)\n",
    "\n",
    "    return mesh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mesh = scale_mesh(mesh, features, shape_fabrication_extent, base_resolution_3d,\n",
    "                      short_curve_quantile=short_curve_quantile,\n",
    "                      n_points_per_short_curve=base_n_points_per_short_curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.9233012144397343"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(mesh.bounding_box.extents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smell_mesh_self_intersections.run(mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniconda/envs/py36/lib/python3.6/site-packages/traittypes/traittypes.py:101: UserWarning: Given trait value dtype \"float64\" does not match required type \"float32\". A coerced copy has been created.\n",
      "  np.dtype(self.dtype).name))\n",
      "/home/user/miniconda/envs/py36/lib/python3.6/site-packages/traittypes/traittypes.py:101: UserWarning: Given trait value dtype \"int64\" does not match required type \"uint32\". A coerced copy has been created.\n",
      "  np.dtype(self.dtype).name))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34dcc13c35634082ad0fa4df0f4913f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "surf_vert_indices = np.array(features['surfaces'][0]['vert_indices'])\n",
    "surf_verts = mesh.vertices[surf_vert_indices]\n",
    "surf_vert_indices2 = np.array(features['surfaces'][0]['vert_indices'])\n",
    "surf_verts2 = mesh.vertices[surf_vert_indices]\n",
    "\n",
    "\n",
    "display_sharpness(\n",
    "    mesh, plot_meshvert=True, meshvert_psize=sampler.resolution_3d,\n",
    "    sharp_vert=None, \n",
    "    sharpvert_psize=1. * sampler.resolution_3d,\n",
    "#     sharp_vert=mesh.vertices[boundary_curves[1]['vert_indices']],\n",
    "    samples=None, samples_psize=1. * sampler.resolution_3d,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having surface area $S$, sampling resolution $r$ (= mean distance between points), and considering each point as occupying a surface $\\pi r^2 / 4$, we have the number of points as:\n",
    "$$\n",
    "n = S / \\pi r^2 / 4\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17.25589091593374, 54928)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_points = np.ceil(mesh.area / (np.pi * sampler.resolution_3d ** 2 / 4)).astype(int)\n",
    "mesh.area, n_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sharpf.data.point_samplers import SamplerFunc\n",
    "\n",
    "\n",
    "class PoissonDiskSampler(SamplerFunc):\n",
    "    \"\"\"Sample using the Poisson-Disk-Sampling of a mesh\n",
    "    based on \"Parallel Poisson Disk Sampling with Spectrum\n",
    "    Analysis on Surface\". (Implementation by fwilliams) \"\"\"\n",
    "    # https://github.com/marmakoide/mesh-blue-noise-sampling/blob/master/mesh-sampling.py\n",
    "    def __init__(self, n_points, resolution_3d, make_n_points='crop_center'):\n",
    "        self.make_n_points = make_n_points\n",
    "        super().__init__(n_points, resolution_3d)\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(config['n_points'], config['resolution_3d'], config['make_n_points'])\n",
    "\n",
    "    def _make_dense_mesh(self, mesh, extra_points_factor=10, point_split_factor=4):\n",
    "        # Intuition: take 10x the number of needed n_points,\n",
    "        # keep in mind that each call to `igl.upsample` generates 4x the points,\n",
    "        # then compute the upsampling factor K from the relation:\n",
    "        # 4^K n = 10 n_points\n",
    "        upsampling_factor = np.ceil(\n",
    "            np.log(self.n_points * extra_points_factor / len(mesh.vertices)) /\n",
    "            np.log(point_split_factor)\n",
    "        ).astype(int)\n",
    "\n",
    "        # Generate very dense subdivision samples on the mesh (v, f, n)\n",
    "        # for _ in range(upsampling_factor):\n",
    "        #     mesh = mesh.subdivide()\n",
    "        dense_points, dense_faces = igl.upsample(mesh.vertices, mesh.faces, upsampling_factor)\n",
    "\n",
    "        # compute vertex normals by pushing to trimesh\n",
    "        dense_mesh = trimesh.base.Trimesh(vertices=dense_points, faces=dense_faces, process=False, validate=False)\n",
    "        return dense_mesh\n",
    "\n",
    "    def sample(self, mesh, centroid=None):\n",
    "        # check that the patch will not crash the upsampling function\n",
    "        FF, FFi = igl.triangle_triangle_adjacency(mesh.faces)\n",
    "        if (FF[FFi == -1] != -1).any() or (FFi[FF == -1] != -1).any():\n",
    "            raise DataGenerationException('Mesh patch has issues and breaks the upsampling!')\n",
    "\n",
    "        dense_mesh = self._make_dense_mesh(mesh, extra_points_factor=40, point_split_factor=4)\n",
    "        dense_points = np.array(dense_mesh.vertices, order='C')\n",
    "        dense_normals = np.array(dense_mesh.vertex_normals, order='C')\n",
    "        dense_faces = np.array(dense_mesh.faces)\n",
    "\n",
    "        # Downsample v_dense to be from a blue noise distribution:\n",
    "        #\n",
    "        # `points` is a downsampled version of `dense_points` where points are separated by approximately\n",
    "        # `radius` distance, use_geodesic_distance indicates that the distance should be measured on the mesh.\n",
    "        #\n",
    "        # `normals` are the corresponding normals of `points`\n",
    "\n",
    "        # require a little bit extra points as PDS get you sometimes fewer than requested\n",
    "        required_points = int(1.1 * self.n_points)\n",
    "        points, normals = pcu.sample_mesh_poisson_disk(\n",
    "            dense_points, dense_faces, dense_normals,\n",
    "            required_points, radius=self.resolution_3d, use_geodesic_distance=True)\n",
    "\n",
    "        # ensure that we are returning exactly n_points\n",
    "        if self.make_n_points == 'crop_center':\n",
    "            centroid = np.mean(points, axis=1, keepdims=True) if centroid is None else centroid\n",
    "            return_idx = np.argsort(np.linalg.norm(points - centroid, axis=1))[:self.n_points]\n",
    "            \n",
    "        elif self.make_n_points == 'sample':\n",
    "            return_idx = np.random.choice(np.arange(len(points)), size=self.n_points, replace=False)\n",
    "            \n",
    "        else:\n",
    "            assert None is self.make_n_points\n",
    "            return_idx = np.arange(len(points))\n",
    "\n",
    "        points, normals = points[return_idx], normals[return_idx]\n",
    "        return points, normals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = PoissonDiskSampler.from_config({\n",
    "    'n_points': n_points,\n",
    "    'resolution_3d': 0.02,\n",
    "    'make_n_points': None\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_model_points, whole_model_normals = sampler.sample(mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniconda/envs/py36/lib/python3.6/site-packages/traittypes/traittypes.py:101: UserWarning: Given trait value dtype \"float64\" does not match required type \"float32\". A coerced copy has been created.\n",
      "  np.dtype(self.dtype).name))\n",
      "/home/user/miniconda/envs/py36/lib/python3.6/site-packages/traittypes/traittypes.py:101: UserWarning: Given trait value dtype \"int64\" does not match required type \"uint32\". A coerced copy has been created.\n",
      "  np.dtype(self.dtype).name))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12df05986fd14778ae7e884004b56234",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_sharpness(\n",
    "    mesh, plot_meshvert=False, meshvert_psize=sampler.resolution_3d,\n",
    "    samples=whole_model_points, samples_psize=1. * sampler.resolution_3d,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_n_points = config['sampling']['n_points']\n",
    "\n",
    "full_model_resolution_discount = 4.0\n",
    "nbhood_extractor.radius_base = np.sqrt(config_n_points) * 0.5 * sampler.resolution_3d / full_model_resolution_discount\n",
    "\n",
    "nbhood_extractor.index(mesh)\n",
    "\n",
    "full_model_resolution_discount = 1.0\n",
    "nbhood_extractor.radius_base = np.sqrt(config_n_points) * 0.5 * sampler.resolution_3d / full_model_resolution_discount\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nbhood_extractor.centroids_cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniconda/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:3: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "has_smell_mismatching_surface_annotation = any([\n",
    "    np.array(np.unique(mesh.faces[surface['face_indices']]) != np.sort(surface['vert_indices'])).all()\n",
    "    for surface in features['surfaces']\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "LARGEST_PROCESSABLE_MESH_VERTICES = 20000\n",
    "\n",
    "\n",
    "def compute_patches(\n",
    "        patch_idx,\n",
    "        whole_model_points,\n",
    "        mesh,\n",
    "        features,\n",
    "        nbhood_extractor,\n",
    "        sampler,\n",
    "        noiser,\n",
    "        annotator,\n",
    "        smell_coarse_surfaces_by_num_edges,\n",
    "        smell_coarse_surfaces_by_angles,\n",
    "        smell_deviating_resolution,\n",
    "        smell_bad_face_sampling,\n",
    "        smell_sharpness_discontinuities):\n",
    "\n",
    "\n",
    "    global LARGEST_PROCESSABLE_MESH_VERTICES\n",
    "\n",
    "    nbhood_extractor.current_patch_idx = patch_idx\n",
    "\n",
    "    # extract neighbourhood\n",
    "    try:\n",
    "        nbhood, mesh_vertex_indexes, mesh_face_indexes, scaler = nbhood_extractor.get_nbhood()\n",
    "        if len(nbhood.vertices) > LARGEST_PROCESSABLE_MESH_VERTICES:\n",
    "            raise DataGenerationException('Too large number of vertices in crop: {}'.format(len(nbhood.vertices)))\n",
    "    except DataGenerationException as e:\n",
    "        eprint_t(str(e))\n",
    "        return None\n",
    "    centroid = nbhood_extractor.centroid\n",
    "\n",
    "    has_smell_coarse_surfaces_by_num_edges = smell_coarse_surfaces_by_num_edges.run(mesh, mesh_face_indexes, features)\n",
    "    has_smell_coarse_surfaces_by_angles = smell_coarse_surfaces_by_angles.run(mesh, mesh_face_indexes, features)\n",
    "\n",
    "    # create annotations: condition the features onto the nbhood\n",
    "    nbhood_features = compute_features_nbhood(mesh, features, mesh_face_indexes,\n",
    "                                              mesh_vertex_indexes=mesh_vertex_indexes)\n",
    "\n",
    "    # remove vertices lying on the boundary (sharp edges found in 1 face only)\n",
    "    nbhood_features = remove_boundary_features(nbhood, nbhood_features, how='edges')\n",
    "\n",
    "    # sample the neighbourhood to form a point patch\n",
    "#     try:\n",
    "#         points, normals = sampler.sample(nbhood, centroid=nbhood_extractor.centroid)\n",
    "#     except DataGenerationException as e:\n",
    "#         eprint_t(str(e))\n",
    "#         return None\n",
    "\n",
    "    distance_sq, face_indexes, _ = igl.point_mesh_squared_distance(\n",
    "        whole_model_points,\n",
    "        nbhood.vertices,\n",
    "        nbhood.faces)\n",
    "    indexes = np.where(distance_sq < sampler.resolution_3d / 100)[0]\n",
    "    points, normals = whole_model_points[indexes], nbhood.face_normals[face_indexes[indexes]]\n",
    "\n",
    "    has_smell_deviating_resolution = smell_deviating_resolution.run(points)\n",
    "    has_smell_bad_face_sampling = smell_bad_face_sampling.run(nbhood, points)\n",
    "\n",
    "    # create a noisy sample\n",
    "    noisy_points = noiser.make_noise(points, normals)\n",
    "    \n",
    "    try:\n",
    "        distances, directions, has_sharp = annotator.annotate(nbhood, nbhood_features, noisy_points)\n",
    "    except DataGenerationException as e:\n",
    "        eprint_t(str(e))\n",
    "        return None \n",
    "\n",
    "    has_smell_sharpness_discontinuities = smell_sharpness_discontinuities.run(noisy_points, distances)\n",
    "\n",
    "    num_sharp_curves = len([curve for curve in nbhood_features['curves'] if curve['sharp']])\n",
    "    num_surfaces = len(nbhood_features['surfaces'])\n",
    "    patch = {\n",
    "        'points': np.array(noisy_points).astype(np.float64),\n",
    "        'normals': np.array(normals).astype(np.float64),\n",
    "        'distances': np.array(distances).astype(np.float64),\n",
    "        'directions': np.array(directions).astype(np.float64),\n",
    "        'orig_vert_indices': np.array(mesh_vertex_indexes).astype(np.int32),\n",
    "        'orig_face_indexes': np.array(mesh_face_indexes).astype(np.int32),\n",
    "        'has_sharp': has_sharp,\n",
    "        'num_sharp_curves': num_sharp_curves,\n",
    "        'num_surfaces': num_surfaces,\n",
    "        'has_smell_coarse_surfaces_by_num_faces': has_smell_coarse_surfaces_by_num_edges,\n",
    "        'has_smell_coarse_surfaces_by_angles': has_smell_coarse_surfaces_by_angles,\n",
    "        'has_smell_deviating_resolution': has_smell_deviating_resolution,\n",
    "        'has_smell_sharpness_discontinuities': has_smell_sharpness_discontinuities,\n",
    "        'has_smell_bad_face_sampling': has_smell_bad_face_sampling,\n",
    "#         'has_smell_mismatching_surface_annotation': has_smell_mismatching_surface_annotation,\n",
    "        'nbhood': nbhood,\n",
    "        'indexes': indexes\n",
    "    }\n",
    "    return patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch = compute_patches(\n",
    "    0,\n",
    "    whole_model_points,\n",
    "    mesh,\n",
    "    features,\n",
    "    nbhood_extractor,\n",
    "    sampler,\n",
    "    noiser,\n",
    "    annotator,\n",
    "    smell_coarse_surfaces_by_num_edges,\n",
    "    smell_coarse_surfaces_by_angles,\n",
    "    smell_deviating_resolution,\n",
    "    smell_bad_face_sampling,\n",
    "    smell_sharpness_discontinuities\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7269c508a5184fb29d5c48edc714e547",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_sharpness(\n",
    "    patch['nbhood'], plot_meshvert=False, meshvert_psize=sampler.resolution_3d,\n",
    "#     sharp_vert=nbhood.vertices, \n",
    "#     sharpvert_psize=10. * sampler.resolution_3d,\n",
    "#     sharp_vert=mesh.vertices[boundary_curves[1]['vert_indices']],\n",
    "    samples=patch['points'], samples_psize=1. * sampler.resolution_3d,\n",
    "    samples_distances=patch['distances']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend MultiprocessingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done   1 tasks      | elapsed:    1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniconda/envs/py36/lib/python3.6/site-packages/joblib/parallel.py:722: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/home/user/miniconda/envs/py36/lib/python3.6/site-packages/joblib/parallel.py:722: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/home/user/miniconda/envs/py36/lib/python3.6/site-packages/joblib/parallel.py:722: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/home/user/miniconda/envs/py36/lib/python3.6/site-packages/joblib/parallel.py:722: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/home/user/miniconda/envs/py36/lib/python3.6/site-packages/joblib/parallel.py:722: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Done   2 tasks      | elapsed:    3.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniconda/envs/py36/lib/python3.6/site-packages/joblib/parallel.py:722: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/home/user/miniconda/envs/py36/lib/python3.6/site-packages/joblib/parallel.py:722: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/home/user/miniconda/envs/py36/lib/python3.6/site-packages/joblib/parallel.py:722: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Done   3 tasks      | elapsed:    3.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniconda/envs/py36/lib/python3.6/site-packages/joblib/parallel.py:722: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/home/user/miniconda/envs/py36/lib/python3.6/site-packages/joblib/parallel.py:722: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/home/user/miniconda/envs/py36/lib/python3.6/site-packages/joblib/parallel.py:722: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/home/user/miniconda/envs/py36/lib/python3.6/site-packages/joblib/parallel.py:722: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/home/user/miniconda/envs/py36/lib/python3.6/site-packages/joblib/parallel.py:722: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/home/user/miniconda/envs/py36/lib/python3.6/site-packages/joblib/parallel.py:722: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/home/user/miniconda/envs/py36/lib/python3.6/site-packages/joblib/parallel.py:722: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/home/user/miniconda/envs/py36/lib/python3.6/site-packages/joblib/parallel.py:722: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Done   4 tasks      | elapsed:   13.4s\n",
      "[Parallel(n_jobs=16)]: Done   5 tasks      | elapsed:   14.2s\n",
      "[Parallel(n_jobs=16)]: Done   6 tasks      | elapsed:   14.3s\n",
      "[Parallel(n_jobs=16)]: Done   7 tasks      | elapsed:   14.4s\n",
      "[Parallel(n_jobs=16)]: Done   8 tasks      | elapsed:   14.5s\n",
      "[Parallel(n_jobs=16)]: Done   9 tasks      | elapsed:   16.0s\n",
      "[Parallel(n_jobs=16)]: Done  10 tasks      | elapsed:   16.8s\n",
      "[Parallel(n_jobs=16)]: Done  11 tasks      | elapsed:   18.5s\n",
      "[Parallel(n_jobs=16)]: Done  12 tasks      | elapsed:   19.1s\n",
      "[Parallel(n_jobs=16)]: Done  13 tasks      | elapsed:   19.1s\n",
      "[Parallel(n_jobs=16)]: Done  14 tasks      | elapsed:   19.3s\n",
      "[Parallel(n_jobs=16)]: Done  15 tasks      | elapsed:   20.1s\n",
      "[Parallel(n_jobs=16)]: Done  16 tasks      | elapsed:   20.2s\n",
      "[Parallel(n_jobs=16)]: Done  17 tasks      | elapsed:   20.5s\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:   21.1s\n",
      "[Parallel(n_jobs=16)]: Done  19 tasks      | elapsed:   21.5s\n",
      "[Parallel(n_jobs=16)]: Done  20 tasks      | elapsed:   21.6s\n",
      "[Parallel(n_jobs=16)]: Done  21 tasks      | elapsed:   23.4s\n",
      "[Parallel(n_jobs=16)]: Done  22 tasks      | elapsed:   25.3s\n",
      "[Parallel(n_jobs=16)]: Done  23 tasks      | elapsed:   26.0s\n",
      "[Parallel(n_jobs=16)]: Done  24 tasks      | elapsed:   27.4s\n",
      "[Parallel(n_jobs=16)]: Done  25 tasks      | elapsed:   27.5s\n",
      "[Parallel(n_jobs=16)]: Done  26 tasks      | elapsed:   28.5s\n",
      "[Parallel(n_jobs=16)]: Done  27 tasks      | elapsed:   28.7s\n",
      "[Parallel(n_jobs=16)]: Done  28 tasks      | elapsed:   29.0s\n",
      "[Parallel(n_jobs=16)]: Done  29 tasks      | elapsed:   30.8s\n",
      "[Parallel(n_jobs=16)]: Done  30 tasks      | elapsed:   31.2s\n",
      "[Parallel(n_jobs=16)]: Done  31 tasks      | elapsed:   31.6s\n",
      "[Parallel(n_jobs=16)]: Done  32 tasks      | elapsed:   33.4s\n",
      "[Parallel(n_jobs=16)]: Done  33 tasks      | elapsed:   33.6s\n",
      "[Parallel(n_jobs=16)]: Done  34 tasks      | elapsed:   33.7s\n",
      "[Parallel(n_jobs=16)]: Done  35 tasks      | elapsed:   35.3s\n",
      "[Parallel(n_jobs=16)]: Done  36 tasks      | elapsed:   36.4s\n",
      "[Parallel(n_jobs=16)]: Done  37 tasks      | elapsed:   36.5s\n",
      "[Parallel(n_jobs=16)]: Done  38 tasks      | elapsed:   37.6s\n",
      "[Parallel(n_jobs=16)]: Done  39 tasks      | elapsed:   39.0s\n",
      "[Parallel(n_jobs=16)]: Done  40 tasks      | elapsed:   40.0s\n",
      "[Parallel(n_jobs=16)]: Done  41 tasks      | elapsed:   41.5s\n",
      "[Parallel(n_jobs=16)]: Done  42 tasks      | elapsed:   42.8s\n",
      "[Parallel(n_jobs=16)]: Done  43 tasks      | elapsed:   44.1s\n",
      "[Parallel(n_jobs=16)]: Done  44 tasks      | elapsed:   45.6s\n",
      "[Parallel(n_jobs=16)]: Done  45 out of  75 | elapsed:   45.8s remaining:   30.5s\n",
      "[Parallel(n_jobs=16)]: Done  46 out of  75 | elapsed:   45.8s remaining:   28.9s\n",
      "[Parallel(n_jobs=16)]: Done  47 out of  75 | elapsed:   46.6s remaining:   27.8s\n",
      "[Parallel(n_jobs=16)]: Done  48 out of  75 | elapsed:   48.1s remaining:   27.1s\n",
      "[Parallel(n_jobs=16)]: Done  49 out of  75 | elapsed:   48.8s remaining:   25.9s\n",
      "[Parallel(n_jobs=16)]: Done  50 out of  75 | elapsed:   50.0s remaining:   25.0s\n",
      "[Parallel(n_jobs=16)]: Done  51 out of  75 | elapsed:   50.8s remaining:   23.9s\n",
      "[Parallel(n_jobs=16)]: Done  52 out of  75 | elapsed:   51.6s remaining:   22.8s\n",
      "[Parallel(n_jobs=16)]: Done  53 out of  75 | elapsed:   52.5s remaining:   21.8s\n",
      "[Parallel(n_jobs=16)]: Done  54 out of  75 | elapsed:   53.8s remaining:   20.9s\n",
      "[Parallel(n_jobs=16)]: Done  55 out of  75 | elapsed:   55.7s remaining:   20.3s\n",
      "[Parallel(n_jobs=16)]: Done  56 out of  75 | elapsed:   55.8s remaining:   18.9s\n",
      "[Parallel(n_jobs=16)]: Done  57 out of  75 | elapsed:   56.4s remaining:   17.8s\n",
      "[Parallel(n_jobs=16)]: Done  58 out of  75 | elapsed:   57.9s remaining:   17.0s\n",
      "[Parallel(n_jobs=16)]: Done  59 out of  75 | elapsed:   58.2s remaining:   15.8s\n",
      "[Parallel(n_jobs=16)]: Done  60 out of  75 | elapsed:   58.8s remaining:   14.7s\n",
      "[Parallel(n_jobs=16)]: Done  61 out of  75 | elapsed:  1.0min remaining:   13.8s\n",
      "[Parallel(n_jobs=16)]: Done  62 out of  75 | elapsed:  1.0min remaining:   12.7s\n",
      "[Parallel(n_jobs=16)]: Done  63 out of  75 | elapsed:  1.0min remaining:   11.6s\n",
      "[Parallel(n_jobs=16)]: Done  64 out of  75 | elapsed:  1.0min remaining:   10.5s\n",
      "[Parallel(n_jobs=16)]: Done  65 out of  75 | elapsed:  1.0min remaining:    9.5s\n",
      "[Parallel(n_jobs=16)]: Done  66 out of  75 | elapsed:  1.0min remaining:    8.4s\n",
      "[Parallel(n_jobs=16)]: Done  67 out of  75 | elapsed:  1.0min remaining:    7.4s\n",
      "[Parallel(n_jobs=16)]: Done  68 out of  75 | elapsed:  1.1min remaining:    6.7s\n",
      "[Parallel(n_jobs=16)]: Done  69 out of  75 | elapsed:  1.1min remaining:    5.8s\n",
      "[Parallel(n_jobs=16)]: Done  70 out of  75 | elapsed:  1.1min remaining:    4.9s\n",
      "[Parallel(n_jobs=16)]: Done  71 out of  75 | elapsed:  1.1min remaining:    3.8s\n",
      "[Parallel(n_jobs=16)]: Done  72 out of  75 | elapsed:  1.2min remaining:    2.9s\n",
      "[Parallel(n_jobs=16)]: Done  73 out of  75 | elapsed:  1.2min remaining:    1.9s\n",
      "[Parallel(n_jobs=16)]: Done  75 out of  75 | elapsed:  1.3min remaining:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done  75 out of  75 | elapsed:  1.3min finished\n"
     ]
    }
   ],
   "source": [
    "parallel = Parallel(n_jobs=16, backend='multiprocessing', verbose=100)\n",
    "delayed_iterable = (delayed(compute_patches)(\n",
    "    patch_idx,\n",
    "    whole_model_points,\n",
    "    mesh,\n",
    "    features,\n",
    "    nbhood_extractor,\n",
    "    sampler,\n",
    "    noiser,\n",
    "    annotator,\n",
    "    smell_coarse_surfaces_by_num_edges,\n",
    "    smell_coarse_surfaces_by_angles,\n",
    "    smell_deviating_resolution,\n",
    "    smell_bad_face_sampling,\n",
    "    smell_sharpness_discontinuities)\n",
    "for patch_idx in range(nbhood_extractor.n_patches_per_mesh))\n",
    "result = parallel(delayed_iterable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_model_distances = np.ones(len(whole_model_points)) * np.inf\n",
    "whole_model_directions = np.ones( (len(whole_model_points), 3) ) * np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [00:00<00:00, 3795.38it/s]\n"
     ]
    }
   ],
   "source": [
    "for patch in tqdm(result):\n",
    "    distances = patch['distances']\n",
    "    directions = patch['directions']\n",
    "    indexes = patch['indexes']\n",
    "\n",
    "    assign_mask = whole_model_distances[indexes] > distances\n",
    "    whole_model_distances[indexes[assign_mask]] = distances[assign_mask]\n",
    "    whole_model_directions[indexes[assign_mask]] = directions[assign_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e4313f1985a48d796678a137ea37574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_sharpness(None, plot_meshvert=False, meshvert_psize=0.01,\n",
    "                  sharp_vert=None, sharpvert_psize=2 * sampler.resolution_3d,\n",
    "                  samples=whole_model_points, samples_distances=whole_model_distances,\n",
    "                  samples_color=0x0000ff, samples_psize=sampler.resolution_3d,\n",
    "                  directions=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1101/1101 [00:00<00:00, 1549.59it/s]\n"
     ]
    }
   ],
   "source": [
    "whole_patches = []\n",
    "\n",
    "for patch in tqdm(result):\n",
    "    whole_patch = deepcopy(patch)\n",
    "    whole_patch['points'] = whole_patch['points'].ravel()\n",
    "    whole_patch['normals'] = whole_patch['normals'].ravel()\n",
    "    whole_patch['distances'] = whole_model_distances[patch['indexes']].ravel()\n",
    "    whole_patch['directions'] = whole_model_directions[patch['indexes'], :].ravel()\n",
    "    whole_patch['has_smell_mismatching_surface_annotation'] = has_smell_mismatching_surface_annotation\n",
    "    whole_patch['item_id'] = item.item_id\n",
    "    whole_patch.pop('nbhood')\n",
    "    whole_patch.pop('indexes')\n",
    "    whole_patch['indexes_in_whole'] = patch['indexes']\n",
    "    whole_patches.append(whole_patch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectors(colors=array([], dtype=uint32), head_color=255, id=140391723338664, line_width=0.0025, model_matrix=array([[1., 0., 0., 0.],\n",
      "       [0., 1., 0., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 0., 1.]], dtype=float32), origin_color=255, origins=array([[-0.91163605,  3.9049733 ,  1.3942498 ],\n",
      "       [-1.180367  ,  4.291388  ,  1.1762593 ],\n",
      "       [-1.0638735 ,  4.481517  ,  1.2829361 ],\n",
      "       ...,\n",
      "       [-0.9122167 ,  4.2156377 ,  1.3947088 ],\n",
      "       [-1.240742  ,  4.2024865 ,  1.1124586 ],\n",
      "       [-0.79642254,  3.95896   ,  1.4630924 ]], dtype=float32), type='Vectors', vectors=array([[ 7.7517296e-04,  9.9052566e-01, -1.1432274e-03],\n",
      "       [ 1.1846676e-03,  6.0411090e-01, -1.1222548e-03],\n",
      "       [ 1.5020202e-03,  4.1398209e-01, -1.7682882e-03],\n",
      "       ...,\n",
      "       [ 1.1712146e-03,  6.7986125e-01, -1.7274305e-03],\n",
      "       [ 1.1529304e-03,  6.9301242e-01, -1.0920764e-03],\n",
      "       [ 6.9720688e-04,  9.3653888e-01, -1.3150685e-03]], dtype=float32))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b95a5036e11425da0ca87a3b0323460",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = np.random.randint(len(result))\n",
    "\n",
    "patch = whole_patches[idx]\n",
    "\n",
    "display_sharpness(None, plot_meshvert=False, meshvert_psize=0.01,\n",
    "                  sharp_vert=None, sharpvert_psize=2 * sampler.resolution_3d,\n",
    "                  samples=patch['points'].reshape((-1, 3)), samples_distances=patch['distances'],\n",
    "                  samples_color=0x0000ff, samples_psize=sampler.resolution_3d,\n",
    "                  directions=patch['directions'].reshape((-1, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "WholePointCloudIO = io.HDF5IO({\n",
    "    'points': io.VarFloat64('points'),\n",
    "    'normals': io.VarFloat64('normals'),\n",
    "    'distances': io.VarFloat64('distances'),\n",
    "    'directions': io.VarFloat64('directions'),\n",
    "    'indexes_in_whole': io.VarInt32('indexes_in_whole'),\n",
    "    'item_id': io.AsciiString('item_id'),\n",
    "    'orig_vert_indices': io.VarInt32('orig_vert_indices'),\n",
    "    'orig_face_indexes': io.VarInt32('orig_face_indexes'),\n",
    "    'has_sharp': io.Bool('has_sharp'),\n",
    "    'num_sharp_curves': io.Int8('num_sharp_curves'),\n",
    "    'num_surfaces': io.Int8('num_surfaces'),\n",
    "    'has_smell_coarse_surfaces_by_num_faces': io.Bool('has_smell_coarse_surfaces_by_num_faces'),\n",
    "    'has_smell_coarse_surfaces_by_angles': io.Bool('has_smell_coarse_surfaces_by_angles'),\n",
    "    'has_smell_deviating_resolution': io.Bool('has_smell_deviating_resolution'),\n",
    "    'has_smell_sharpness_discontinuities': io.Bool('has_smell_sharpness_discontinuities'),\n",
    "    'has_smell_bad_face_sampling': io.Bool('has_smell_bad_face_sampling'),\n",
    "    'has_smell_mismatching_surface_annotation': io.Bool('has_smell_mismatching_surface_annotation'),\n",
    "},\n",
    "len_label='has_sharp',\n",
    "compression='lzf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial \n",
    "import h5py\n",
    "\n",
    "def save_whole_patches(patches, filename):\n",
    "    # turn a list of dicts into a dict of torch tensors:\n",
    "    # default_collate([{'a': 'str1', 'x': np.random.normal()}, {'a': 'str2', 'x': np.random.normal()}])\n",
    "    # Out[26]: {'a': ['str1', 'str2'], 'x': tensor([0.4252, 0.1414], dtype=torch.float64)}\n",
    "    collate_fn = partial(io.collate_mapping_with_io, io=WholePointCloudIO)\n",
    "    patches = collate_fn(patches)\n",
    "\n",
    "    with h5py.File(filename, 'w') as f:\n",
    "        for key in ['points', 'normals', 'distances', 'directions', 'indexes_in_whole']:\n",
    "            WholePointCloudIO.write(f, key, patches[key])\n",
    "        WholePointCloudIO.write(f, 'item_id', patches['item_id'])\n",
    "        WholePointCloudIO.write(f, 'orig_vert_indices', patches['orig_vert_indices'])\n",
    "        WholePointCloudIO.write(f, 'orig_face_indexes', patches['orig_face_indexes'])\n",
    "        WholePointCloudIO.write(f, 'has_sharp', patches['has_sharp'].numpy().astype(np.bool))\n",
    "        WholePointCloudIO.write(f, 'num_sharp_curves', patches['num_sharp_curves'].numpy())\n",
    "        WholePointCloudIO.write(f, 'num_surfaces', patches['num_surfaces'].numpy())\n",
    "        has_smell_keys = [key for key in WholePointCloudIO.datasets.keys()\n",
    "                          if key.startswith('has_smell')]\n",
    "        for key in has_smell_keys:\n",
    "            PointCloudIO.write(f, key, patches[key].numpy().astype(np.bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_whole_patches(whole_patches, '/logs/whole_{}.hdf5'.format(item.item_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sharpf.utils.abc_utils.hdf5.dataset import Hdf5File, PreloadTypes\n",
    "import sharpf.utils.abc_utils.hdf5.io_struct as io\n",
    "import sharpf.data.datasets.sharpf_io as io "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Hdf5File('/logs/abc_0022_00220090_ec51899db1f5298d674b3205_037.hdf5',\n",
    "                   io=io.WholePointCloudIO,\n",
    "                   preload=PreloadTypes.LAZY,\n",
    "                   labels='*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectors(colors=array([], dtype=uint32), head_color=255, id=140142132386504, line_width=0.0025, model_matrix=array([[1., 0., 0., 0.],\n",
      "       [0., 1., 0., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 0., 1.]], dtype=float32), origin_color=255, origins=array([[-0.29543132, -0.29372117, -0.28678182],\n",
      "       [-0.29102084, -0.29204527, -0.3032786 ],\n",
      "       [-0.28287807, -0.29605648, -0.28139922],\n",
      "       ...,\n",
      "       [-0.9756016 , -0.05885366,  0.05854423],\n",
      "       [-0.98914415, -0.05885366,  0.03921641],\n",
      "       [-0.9909573 , -0.05885366,  0.06072959]], dtype=float32), type='Vectors', vectors=array([[-4.1604769e-01,  2.3486714e-01, -4.1185358e-01],\n",
      "       [-3.9317936e-01,  2.3319122e-01, -4.2210862e-01],\n",
      "       [-4.2507905e-01,  2.3720245e-01, -4.2079392e-01],\n",
      "       ...,\n",
      "       [-1.9787207e-02,  0.0000000e+00,  1.4059661e-03],\n",
      "       [-7.2520049e-03,  0.0000000e+00,  2.2054254e-04],\n",
      "       [-4.3541389e-03,  6.9372619e-18,  3.0937864e-04]], dtype=float32))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b00423c86d014431a3ed2ec2d52de4c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = np.random.randint(len(dataset))\n",
    "\n",
    "patch = dataset[idx]\n",
    "\n",
    "display_sharpness(None, plot_meshvert=False, meshvert_psize=0.01,\n",
    "                  sharp_vert=None, sharpvert_psize=0.02,\n",
    "                  samples=patch['points'].reshape((-1, 3)), samples_distances=patch['distances'],\n",
    "                  samples_color=0x0000ff, samples_psize=0.02,\n",
    "                  directions=patch['directions'].reshape((-1, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_predictions(predictions, patches):\n",
    "    n_points = np.concatenate([\n",
    "        patch['indexes_in_whole']\n",
    "        for patch in patches]).max() + 1\n",
    "    \n",
    "    whole_model_points_pred = np.zeros((n_points, 3))\n",
    "    whole_model_distances_pred = np.ones(n_points) * np.inf\n",
    "    whole_model_directions_pred = np.ones( (n_points, 3) ) * np.inf\n",
    "    \n",
    "    for prediction, patch in zip(predictions, patches):\n",
    "        distances = prediction['distances']\n",
    "        directions = prediction['directions'].reshape((-1, 3))\n",
    "        indexes = patch['indexes_in_whole']\n",
    "        whole_model_points_pred[indexes] = patch['points'].reshape((-1, 3))\n",
    "\n",
    "        assign_mask = whole_model_distances_pred[indexes] > distances\n",
    "        whole_model_distances_pred[indexes[assign_mask]] = np.minimum(distances[assign_mask], 1.0)\n",
    "        whole_model_directions_pred[indexes[assign_mask]] = directions[assign_mask]\n",
    "        \n",
    "    return whole_model_points_pred, whole_model_distances_pred, whole_model_directions_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_model_points_pred, whole_model_distances_pred, whole_model_directions_pred = combine_predictions(\n",
    "    patches, patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "patches = [patch for patch in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_points = np.concatenate([\n",
    "    patch['indexes_in_whole']\n",
    "    for patch in dataset]).max() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_model_points_pred = np.zeros((n_points, 3))\n",
    "whole_model_distances_pred = np.ones(n_points) * np.inf\n",
    "whole_model_directions_pred = np.ones( (n_points, 3) ) * np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1101/1101 [00:00<00:00, 1462.67it/s]\n"
     ]
    }
   ],
   "source": [
    "for patch in tqdm(dataset):\n",
    "    distances = patch['distances'] + np.random.uniform(0.0, 0.1, size=len(patch['distances']))\n",
    "    directions = patch['directions'].reshape((-1, 3))\n",
    "    indexes = patch['indexes_in_whole']\n",
    "    whole_model_points_pred[indexes] = patch['points'].reshape((-1, 3))\n",
    "\n",
    "    assign_mask = whole_model_distances_pred[indexes] > distances\n",
    "    whole_model_distances_pred[indexes[assign_mask]] = np.minimum(distances[assign_mask], 1.0)\n",
    "    whole_model_directions_pred[indexes[assign_mask]] = directions[assign_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniconda/envs/py36/lib/python3.6/site-packages/traittypes/traittypes.py:101: UserWarning: Given trait value dtype \"float64\" does not match required type \"float32\". A coerced copy has been created.\n",
      "  np.dtype(self.dtype).name))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d78247f77cd4498696bc6db33810cf7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_sharpness(None, plot_meshvert=False, meshvert_psize=0.01,\n",
    "                  sharp_vert=None, sharpvert_psize=2 * sampler.resolution_3d,\n",
    "                  samples=whole_model_points_pred, samples_distances=whole_model_distances_pred,\n",
    "                  samples_color=0x0000ff, samples_psize=sampler.resolution_3d,\n",
    "                  directions=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_model_points_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_model_points = np.concatenate([\n",
    "    patch['points']\n",
    "    for patch in dataset\n",
    "])\n",
    "whole_model_points.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_model_directions = np.concatenate([\n",
    "    patch['directions']\n",
    "    for patch in dataset\n",
    "])\n",
    "whole_model_directions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_model_distances = np.concatenate([\n",
    "    patch['distances']\n",
    "    for patch in dataset\n",
    "])\n",
    "whole_model_distances.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_sharpness(None, plot_meshvert=False, meshvert_psize=0.01,\n",
    "                  sharp_vert=None, sharpvert_psize=0.02,\n",
    "                  samples=whole_model_points, samples_distances=whole_model_distances,\n",
    "                  samples_color=0x0000ff, samples_psize=0.02,\n",
    "                  directions=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
