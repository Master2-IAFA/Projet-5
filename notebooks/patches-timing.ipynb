{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import trimesh\n",
    "from scipy.spatial import KDTree\n",
    "\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('agg')\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from pathlib import Path\n",
    "import sys\n",
    "sys.setrecursionlimit(100000)\n",
    "\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "from notebooks.io import write_ply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "import yaml\n",
    "from yaml import Loader\n",
    "import k3d\n",
    "import randomcolor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/artonson/repos/sharp_features/')\n",
    "\n",
    "from sharpf.data.abc_data import ABCChunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trimesh_load(io: BytesIO):\n",
    "    \"\"\"Read the mesh: since trimesh messes the indices, this has to be done manually.\"\"\"\n",
    "\n",
    "    vertices, faces = [], []\n",
    "\n",
    "    for line in io.read().decode('utf-8').splitlines():\n",
    "        values = line.strip().split()\n",
    "        if not values: continue\n",
    "        if values[0] == 'v':\n",
    "            vertices.append(np.array(values[1:4], dtype='float'))\n",
    "        elif values[0] == 'f':\n",
    "            faces.append(np.array([values[1].split('//')[0], values[2].split('//')[0], values[3].split('//')[0]],\n",
    "                                  dtype='int'))\n",
    "\n",
    "    vertices = np.array(vertices)\n",
    "    faces = np.array(faces) - 1\n",
    "\n",
    "    mesh = trimesh.base.Trimesh(vertices=vertices, faces=faces, process=False)  # create a mesh from the vertices\n",
    "    return mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk = ABCChunk(['/home/artonson/tmp/abc/abc_0000_obj_v00.7z', '/home/artonson/tmp/abc/abc_0000_feat_v00.7z'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "item = chunk.get('00002992_79022290f16b4fd9a0a85b2d_000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh = trimesh_load(item.obj)\n",
    "labels = yaml.load(item.feat, Loader=Loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import yaml\n",
    "# import pywavefront\n",
    "# from yaml import CLoader as Loader, CDumper as Dumper\n",
    "\n",
    "# def get_config(path):\n",
    "#     with open(path, 'r') as stream:\n",
    "#         config = yaml.load(stream, Loader=Loader)\n",
    "#     return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes = {}\n",
    "\n",
    "shapes['00002992_79022290f16b4fd9a0a85b2d_000'] = {\n",
    "    'vertices': process_vertices(np.array(mesh.vertices)),\n",
    "    'faces': mesh.faces,\n",
    "    'labels': labels,\n",
    "    'edges': mesh.edges\n",
    "}\n",
    "shapes_ids = ['00002992_79022290f16b4fd9a0a85b2d_000']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/artonson/.pyenv/versions/3.6.6/lib/python3.6/site-packages/traittypes/traittypes.py:101: UserWarning: Given trait value dtype \"float64\" does not match required type \"float32\". A coerced copy has been created.\n",
      "  np.dtype(self.dtype).name))\n"
     ]
    }
   ],
   "source": [
    "plot = k3d.plot(height=768)\n",
    "\n",
    "k3d_points = k3d.points(mesh.vertices, point_size=0.5, color=0x0000ff)\n",
    "plot += k3d_points\n",
    "k3d_points.shader='3d'\n",
    "\n",
    "# sharp_points = mesh.vertices[np.array(list(shapes[shape_id]['sharp_vertices']))]\n",
    "# k3d_points = k3d.points(sharp_points, point_size=0.5, color=0xff0000)\n",
    "# plot += k3d_points\n",
    "# k3d_points.shader='3d'\n",
    "\n",
    "\n",
    "plot.grid_visible = False\n",
    "# plot.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_vertices(vertices):\n",
    "    '''Centering and scaling'''\n",
    "    centroid = vertices.mean(axis=0)\n",
    "#     print(centroid)\n",
    "    centered = vertices-centroid\n",
    "    max_dim = abs(centered.max(axis=0) - centered.min(axis=0))\n",
    "#     print(max_dim)\n",
    "    max_dim = max(max_dim)\n",
    "    centered/=max_dim\n",
    "    return centered\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shapes_ids = [ '00000005', '00000212']#,'00000416']#'00000005']# ]#'00000005', '00000212','00000416',\n",
    "\n",
    "# data_path = Path('/home/user/data/abc_new')\n",
    "# shapes = {}\n",
    "# for shape_id in tqdm(shapes_ids):\n",
    "\n",
    "#     mesh_file = glob.glob((data_path/shape_id/'*.obj').as_posix())[0]\n",
    "\n",
    "#     labels_file = glob.glob((data_path/shape_id/'*features*.yml').as_posix())[0]\n",
    "# #     print('labels_file', labels_file)\n",
    "#     labels = get_config(labels_file)\n",
    "\n",
    "#     scene = pywavefront.Wavefront(mesh_file, collect_faces=True)\n",
    "#     vertices = process_vertices(np.array(scene.vertices))\n",
    "#     faces = scene.mesh_list[0].faces\n",
    "#     edges = set()\n",
    "#     for face in faces:\n",
    "#         for edge in itertools.combinations(face, 2):\n",
    "#             edges.add(edge)\n",
    "\n",
    "# #     print('edges')\n",
    "# #     mesh = trimesh.base.Trimesh(vertices=vertices,\n",
    "# #                                 faces=faces,\n",
    "# #                                 process=False,\n",
    "# #                                 validate=False,)\n",
    "\n",
    "#     shapes[shape_id] = {'vertices': vertices, 'faces': faces, 'labels': labels, 'edges': edges }# , 'mesh': mesh}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vertices_from_face_indices(face_indices, faces):\n",
    "    face_vertices = set()\n",
    "    face_dict = defaultdict(list)\n",
    "    \n",
    "    for face_index in face_indices:\n",
    "        face_vertices.update(faces[face_index])\n",
    "        \n",
    "        for vert in faces[face_index]:\n",
    "            face_dict[vert].append(face_index)\n",
    "            \n",
    "    return list(face_vertices), face_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:23<00:00, 23.91s/it]\n"
     ]
    }
   ],
   "source": [
    "for shape_id in tqdm(shapes_ids):    \n",
    "\n",
    "    sharp_vertices = set()\n",
    "    sharp_edges = defaultdict(set)\n",
    "    all_sharp_edges = set()\n",
    "    shape_curves = defaultdict(set)\n",
    "    for i, curv in enumerate(shapes[shape_id]['labels'][\"curves\"]):\n",
    "        if curv[\"sharp\"]:\n",
    "            vert_ind = np.array(curv[\"vert_indices\"]) #+ 1\n",
    "\n",
    "            sharp_vertices.update(vert_ind)\n",
    "            shape_curves[i] = vert_ind\n",
    "            for ind1, ind2 in itertools.combinations(vert_ind, 2):\n",
    "                if (ind1, ind2) in shapes[shape_id]['edges'] or (ind2, ind1) in shapes[shape_id]['edges']:\n",
    "                    sharp_edges[i].add((ind1, ind2))\n",
    "                    all_sharp_edges.add((ind1, ind2))\n",
    "    \n",
    "   \n",
    "    shapes[shape_id]['sharp_vertices'] = sharp_vertices\n",
    "    shapes[shape_id]['sharp_edges'] = sharp_edges  # dict by curve\n",
    "    shapes[shape_id]['all_sharp_edges'] = all_sharp_edges # all\n",
    "    shapes[shape_id]['shape_curves'] = shape_curves\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/artonson/.pyenv/versions/3.6.6/lib/python3.6/site-packages/traittypes/traittypes.py:101: UserWarning: Given trait value dtype \"float64\" does not match required type \"float32\". A coerced copy has been created.\n",
      "  np.dtype(self.dtype).name))\n",
      "/home/artonson/.pyenv/versions/3.6.6/lib/python3.6/site-packages/traittypes/traittypes.py:101: UserWarning: Given trait value dtype \"int64\" does not match required type \"uint32\". A coerced copy has been created.\n",
      "  np.dtype(self.dtype).name))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccc1f27b1248424e8ab3c2218225b884",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot = k3d.plot(height=768)\n",
    "rand_color = randomcolor.RandomColor()\n",
    "\n",
    "k3d_mesh = k3d.mesh(mesh.vertices, mesh.faces, color=0xbbbbbb)\n",
    "plot += k3d_mesh\n",
    "\n",
    "# k3d_points = k3d.points(mesh.vertices, point_size=0.5, color=0x0000ff)\n",
    "# plot += k3d_points\n",
    "# k3d_points.shader='3d'\n",
    "\n",
    "# sharp_points = mesh.vertices[np.array(list(shapes[shape_id]['sharp_vertices']))]\n",
    "# k3d_points = k3d.points(sharp_points, point_size=0.5, color=0xff0000)\n",
    "# plot += k3d_points\n",
    "# k3d_points.shader='3d'\n",
    "\n",
    "for i, vert_ind in shape_curves.items():\n",
    "    sharp_points_curve = mesh.vertices[vert_ind]\n",
    "    color = rand_color.generate(hue='red')[0]\n",
    "    plt_line = k3d.line(sharp_points_curve, shader='mesh', width=0.5, color=int('0x' + color[1:], 16))\n",
    "    plot += plt_line\n",
    "\n",
    "plot.grid_visible = False\n",
    "plot.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping vertices to all faces it belongs to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for shape_id in shapes_ids: \n",
    "    face_dict = defaultdict(list)\n",
    "    for i, surface in enumerate(tqdm(shapes[shape_id]['labels'][\"surfaces\"])):\n",
    "        vertices, surface_face_dict = get_vertices_from_face_indices(surface['face_indices'], shapes[shape_id]['faces'])\n",
    "        for vertex in surface_face_dict:        \n",
    "            face_dict[vertex]+=surface_face_dict[vertex]\n",
    "    shapes[shape_id]['face_dict'] = face_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Almost) spherical patch sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_spherical_patch(shape, k, radius, root=None):\n",
    "    '''\n",
    "    samples mesh patch\n",
    "    k: pick k vertices within radius\n",
    "    radius: sphere radius\n",
    "    '''\n",
    "    # root vertex to sample around\n",
    "    if root is None:\n",
    "        root = np.random.choice(len(shape['vertices']))\n",
    "        \n",
    "    start = time.time()\n",
    "    # tree to sample from\n",
    "    tree = KDTree(shape['vertices'])\n",
    "    end = time.time()\n",
    "    print(\"{action}: {timing:3.3f}\".format(action=\"  building KD tree\", timing=end - start))\n",
    "    \n",
    "    start = time.time()\n",
    "    distances, vert_indices = tree.query(shape['vertices'][root], k=k, distance_upper_bound=radius)\n",
    "    end = time.time()\n",
    "    print(\"{action}: {timing:3.3f}\".format(action=\"  query in KD tree\", timing=end - start))\n",
    "\n",
    "    start = time.time()\n",
    "    vertices = set()\n",
    "    faces_indices = []\n",
    "    for vert_index in vert_indices:\n",
    "        vert_faces = shape['face_dict'][vert_index]\n",
    "        for face in vert_faces:\n",
    "            # if any vertex from a face is inside the sphere pick this face\n",
    "            if len(np.intersect1d(shape['faces'][face], list(vert_indices)))>0:\n",
    "                faces_indices.append(face)\n",
    "                vertices.update(shape['faces'][face])\n",
    "    vertices = list(vertices)   \n",
    "    end = time.time()\n",
    "    print(\"{action}: {timing:3.3f}\".format(action=\"  build vertices\", timing=end - start))\n",
    "\n",
    "#     print(vertices)\n",
    "    start = time.time()\n",
    "    reindex = dict(zip(vertices, range(len(vertices))))\n",
    "    faces = []\n",
    "    \n",
    "#     print(faces_indices)\n",
    "    for face in np.array(shape['faces'])[faces_indices]:\n",
    "        faces.append([reindex[vert] for vert in face])\n",
    "    end = time.time()\n",
    "    print(\"{action}: {timing:3.3f}\".format(action=\"  reindex\", timing=end - start))\n",
    "    \n",
    "    \n",
    "    start = time.time()\n",
    "    mesh = trimesh.base.Trimesh(vertices=shape['vertices'][vertices],\n",
    "                                faces=faces,\n",
    "                                process=False,\n",
    "                                validate=False,)\n",
    "    end = time.time()\n",
    "    print(\"{action}: {timing:3.3f}\".format(action=\"  create Trimesh\", timing=end - start))\n",
    "    \n",
    "    return mesh, vertices, faces_indices\n",
    "\n",
    "\n",
    "def resample(shape, vert_indices, face_indices, patch, target_dist=0.6, n_points=1000, distance_upper_bound=1.0, \\\n",
    "             noise_ampl=0.05):\n",
    "    '''\n",
    "    sample annotated point cloud from a mesh patch\n",
    "    target_dist: desired distance between points on the borders (should match point cloud density)\n",
    "    distance_upper_bound: maximum distance within which annotation is comuted\n",
    "    noise_ampl: noise amplitude to shutter the regular samples on the border (depends from target_dist)\n",
    "    \n",
    "    '''\n",
    "    sharp_samples = []\n",
    "    \n",
    "    # surface point samples\n",
    "    start = time.time()\n",
    "    point_samples, index = trimesh.sample.sample_surface(patch, n_points)\n",
    "    end = time.time()\n",
    "    print(\"{action}: {timing:3.3f}\".format(action=\"  sample_surface\", timing=end - start))\n",
    "\n",
    "    start = time.time()\n",
    "    pc_tree = KDTree(point_samples)\n",
    "    end = time.time()\n",
    "    print(\"{action}: {timing:3.3f}\".format(action=\"  build KDTree on sampled points\", timing=end - start))\n",
    "\n",
    "    start = time.time()\n",
    "    for vert1, vert2 in itertools.combinations(vert_indices, 2):\n",
    "#         vert1 in shape['sharp_vertices'] and vert2 in shape['sharp_vertices'] and \n",
    "        if ((vert1, vert2) in shape['all_sharp_edges'] or (vert2, vert1) in shape['all_sharp_edges']):\n",
    "            v1 = shape['vertices'][vert1]\n",
    "            v2 = shape['vertices'][vert2]\n",
    "            \n",
    "            # quite an ugly way to estimate the number of points to sample on edge\n",
    "            n_samples = 2+int(np.linalg.norm(v1-v2)/target_dist+0.5)\n",
    "\n",
    "            # border samples from sharp edges\n",
    "            sharp_samples.append(sample_even(v1, v2, n_samples))\n",
    "    end = time.time()\n",
    "    print(\"{action}: {timing:3.3f}\".format(action=\"  sample sharp edges\", timing=end - start))\n",
    "    \n",
    "    # patch without sharp features\n",
    "    if len(sharp_samples)==0:\n",
    "        return point_samples, np.ones_like(point_samples[:,0])*distance_upper_bound, np.zeros_like(point_samples)\n",
    "    sharp_samples = np.concatenate(sharp_samples)  \n",
    "    \n",
    "    ### !!! kostile\n",
    "    n_sharp = len(sharp_samples)\n",
    "    idx_to_keep = np.random.choice(np.arange(n_points), \n",
    "                                   size=n_points - n_sharp, replace=False)\n",
    "    point_samples = point_samples[idx_to_keep]\n",
    "    ### !!! end kostile\n",
    "    \n",
    "    # computing distances to the border samples\n",
    "    start = time.time()\n",
    "    tree = KDTree(sharp_samples)\n",
    "    end = time.time()\n",
    "    print(\"{action}: {timing:3.3f}\".format(action=\"  build KD tree on sharp samples\", timing=end - start))\n",
    "\n",
    "    start = time.time()\n",
    "    distances, vert_indices = tree.query(point_samples, distance_upper_bound=distance_upper_bound)\n",
    "    end = time.time()\n",
    "    print(\"{action}: {timing:3.3f}\".format(action=\"  query KD tree on sharp samples\", timing=end - start))\n",
    "\n",
    "#     print(distances[:40], vert_indices[:40])\n",
    "#     print(len(distances), len(vert_indices), vert_indices.max(), len(sharp_samples))\n",
    "    start = time.time()\n",
    "    mask_point = distances==np.inf\n",
    "    mask_sharp = vert_indices<len(sharp_samples)\n",
    "    vert_indices = vert_indices[mask_sharp]\n",
    "    \n",
    "    directions = np.zeros_like(point_samples)\n",
    "    directions[~mask_point] = sharp_samples[vert_indices] - point_samples[~mask_point]\n",
    "\n",
    "    distances[mask_point] = distance_upper_bound\n",
    "    end = time.time()\n",
    "    print(\"{action}: {timing:3.3f}\".format(action=\"  form distances\", timing=end - start))\n",
    "\n",
    "    \n",
    "    # adding noise to regular boundary samples\n",
    "    start = time.time()\n",
    "\n",
    "    noise = (np.random.rand(*sharp_samples.shape)-0.5)*2*noise_ampl\n",
    "    edge_samples = sharp_samples + noise\n",
    "    vert = np.concatenate([point_samples, sharp_samples])\n",
    "    distances = np.concatenate([distances, np.linalg.norm(noise, axis=1)])\n",
    "    directions = np.concatenate([directions, noise])\n",
    "    end = time.time()\n",
    "    print(\"{action}: {timing:3.3f}\".format(action=\"  add noise\", timing=end - start))\n",
    "\n",
    "    return vert, distances, directions\n",
    "\n",
    "def sample_even(v1, v2, count, noise_ampl=0.005):\n",
    "    unit = np.linspace(0, 1, count)[...,None] + noise_ampl*np.random.rand(count, 1)\n",
    "    unit = np.clip(unit, 0, 1)\n",
    "\n",
    "    vec = (v2-v1)[None, ...]\n",
    "    \n",
    "    return v1 + vec*unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = 'curves_test'\n",
    "os.makedirs(save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 1\n",
    "\n",
    "\n",
    "# patch mesh sampling\n",
    "n_vert = 400 # number of mesh vertices to pick\n",
    "max_dist = 1 # sphere radius\n",
    "\n",
    "# pc sampling\n",
    "distance_upper_bound = 0.01 # distance around borders \n",
    "target_dist=0.00001 # distance between regular edge samples\n",
    "n_points=4096 \n",
    "noise_ampl = 5e-4 # noise amplitude for regular edge samples\n",
    "\n",
    "\n",
    "patches = []\n",
    "for shape_id in shapes_ids:\n",
    "\n",
    "    for i in tqdm(range(num_samples)):\n",
    "        mesh, vert_indices, faces_indices = random_spherical_patch(shapes[shape_id], n_vert, max_dist)\n",
    "        \n",
    "        patches.append((mesh, vert_indices, faces_indices))\n",
    "#         target_dist = np.sqrt(mesh.area_faces.sum()/n_points)/10\n",
    "        noise_ampl = 0 #np.sqrt(target_dist)*1e-3\n",
    "#         print(target_dist)\n",
    "\n",
    "        point_samples, distances, directions = resample(\n",
    "            shapes[shape_id], vert_indices, faces_indices, mesh, n_points=n_points,\n",
    "            distance_upper_bound=distance_upper_bound, noise_ampl=noise_ampl)\n",
    "        write_ply(f'{save_dir}/{shape_id}_{i}.ply', point_samples, distances=distances/distance_upper_bound*255, directions=directions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from base64 import b64decode\n",
    "\n",
    "def display_sharpness(mesh=None, plot_meshvert=True,\n",
    "                      samples=None, samples_distances=None,\n",
    "                      sharp_vert=None, sharp_curves=None,\n",
    "                      samples_color=0x0000ff, samples_psize=0.002, \n",
    "                      mesh_color=0xbbbbbb, meshvert_color=0x666666, meshvert_psize=0.0025,\n",
    "                      sharpvert_color=0xff0000, sharpvert_psize=0.0025,\n",
    "                      sharpcurve_color=None, sharpcurve_width=0.0025,\n",
    "                      as_image=False, plot_height=768):\n",
    "    \n",
    "    plot = k3d.plot(height=plot_height)\n",
    "    \n",
    "    if None is not mesh:\n",
    "        k3d_mesh = k3d.mesh(mesh.vertices, mesh.faces, color=mesh_color)\n",
    "        plot += k3d_mesh\n",
    "\n",
    "        if plot_meshvert:\n",
    "            k3d_points = k3d.points(mesh.vertices, \n",
    "                                    point_size=meshvert_psize, color=meshvert_color)\n",
    "            plot += k3d_points\n",
    "            k3d_points.shader='3d'\n",
    "\n",
    "    if None is not samples:\n",
    "        if None is not samples_distances:\n",
    "            max_dist = np.max(distances)\n",
    "            colors = k3d.helpers.map_colors(\n",
    "                samples_distances, k3d.colormaps.basic_color_maps.WarmCool, [0, max_dist]\n",
    "            ).astype(np.uint32)\n",
    "            k3d_points = k3d.points(samples, point_size=samples_psize, colors=colors)\n",
    "        \n",
    "        else:\n",
    "            k3d_points = k3d.points(samples, point_size=samples_psize, color=samples_color)\n",
    "            \n",
    "        plot += k3d_points\n",
    "        k3d_points.shader='3d'\n",
    "\n",
    "    if None is not sharp_vert:\n",
    "        k3d_points = k3d.points(sharp_vert,\n",
    "                                point_size=sharpvert_psize, color=sharpvert_color)\n",
    "        plot += k3d_points\n",
    "        k3d_points.shader='3d'\n",
    "\n",
    "        rand_color = randomcolor.RandomColor()\n",
    "        for i, vert_ind in shape_curves.items():\n",
    "            sharp_points_curve = mesh.vertices[vert_ind]\n",
    "            if None is not sharpcurve_color:\n",
    "                color = sharpcurve_color\n",
    "            else:\n",
    "                color = rand_color.generate(hue='red')[0]\n",
    "                color = int('0x' + color[1:], 16)\n",
    "            plt_line = k3d.line(sharp_points_curve, \n",
    "                                shader='mesh', width=sharpcurve_width, color=color)\n",
    "            plot += plt_line\n",
    "\n",
    "    plot.grid_visible = False\n",
    "    plot.display()\n",
    "    \n",
    "    if as_image:\n",
    "        plot.fetch_screenshot()\n",
    "        return Image(data=b64decode(plot.screenshot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'point_samples' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-b3478a7fb505>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisplay_sharpness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmesh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmesh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpoint_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples_distances\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdistances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_image\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'point_samples' is not defined"
     ]
    }
   ],
   "source": [
    "im = display_sharpness(mesh=mesh, samples=point_samples, samples_distances=distances, as_image=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = k3d.plot(height=768)\n",
    "rand_color = randomcolor.RandomColor()\n",
    "\n",
    "k3d_mesh = k3d.mesh(mesh.vertices, mesh.faces, color=0xbbbbbb)\n",
    "plot += k3d_mesh\n",
    "\n",
    "k3d_points = k3d.points(mesh.vertices, point_size=0.0025, color=0x666666)\n",
    "plot += k3d_points\n",
    "k3d_points.shader='3d'\n",
    "\n",
    "\n",
    "colors = k3d.helpers.map_colors(\n",
    "    distances, k3d.colormaps.basic_color_maps.WarmCool,[0,0.01]).astype(np.uint32)\n",
    "\n",
    "k3d_points = k3d.points(point_samples, point_size=0.002, colors=colors)\n",
    "plot += k3d_points\n",
    "k3d_points.shader='3d'\n",
    "\n",
    "# sharp_points = mesh.vertices[np.array(list(shapes[shape_id]['sharp_vertices']))]\n",
    "# k3d_points = k3d.points(sharp_points, point_size=0.5, color=0xff0000)\n",
    "# plot += k3d_points\n",
    "# k3d_points.shader='3d'\n",
    "\n",
    "# for i, vert_ind in shape_curves.items():\n",
    "#     sharp_points_curve = mesh.vertices[vert_ind]\n",
    "#     color = rand_color.generate(hue='red')[0]\n",
    "#     plt_line = k3d.line(sharp_points_curve, shader='mesh', width=0.5, color=int('0x' + color[1:], 16))\n",
    "#     plot += plt_line\n",
    "\n",
    "plot.grid_visible = False\n",
    "# plot.camera_auto_fit = True\n",
    "plot.camera = [1.5, 1.5, 1.5, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]\n",
    "plot.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from base64 import b64decode\n",
    "i = Image(data=b64decode(plot.screenshot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.fetch_screenshot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(data=b64decode(plot.screenshot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = k3d.plot(height=768)\n",
    "rand_color = randomcolor.RandomColor()\n",
    "\n",
    "k3d_mesh = k3d.mesh(mesh.vertices, mesh.faces, color=0xbbbbbb)\n",
    "plot += k3d_mesh\n",
    "\n",
    "k3d_points = k3d.points(mesh.vertices, point_size=0.0025, color=0x0000ff)\n",
    "plot += k3d_points\n",
    "k3d_points.shader='3d'\n",
    "\n",
    "# sharp_points = mesh.vertices[np.array(list(shapes[shape_id]['sharp_vertices']))]\n",
    "# k3d_points = k3d.points(sharp_points, point_size=0.5, color=0xff0000)\n",
    "# plot += k3d_points\n",
    "# k3d_points.shader='3d'\n",
    "\n",
    "# for i, vert_ind in shape_curves.items():\n",
    "#     sharp_points_curve = mesh.vertices[vert_ind]\n",
    "#     color = rand_color.generate(hue='red')[0]\n",
    "#     plt_line = k3d.line(sharp_points_curve, shader='mesh', width=0.5, color=int('0x' + color[1:], 16))\n",
    "#     plot += plt_line\n",
    "\n",
    "plot.grid_visible = False\n",
    "plot.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def curves(shape):\n",
    "    sharp_samples = []\n",
    "    \n",
    "    for curve in shape['shape_curves']:\n",
    "#         print(shape['shape_curves'][curve])\n",
    "        sharp_samples+=list(shape['shape_curves'][curve])\n",
    "    \n",
    "    vert = shape['vertices'][sharp_samples]#np.concatenate(sharp_samples)  \n",
    "    distances = np.zeros_like(vert[:,0])# np.concatenate([distances, np.linalg.norm(noise, axis=1)])\n",
    "    \n",
    "    return vert, distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item.item_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the whole chunk and process it into patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "print(\"hello\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_parallel(meshes_filename, feats_filename, data_slice):\n",
    "    \n",
    "    num_samples_per_shape = 10\n",
    "\n",
    "    # patch mesh sampling\n",
    "    n_vert = 400 # number of mesh vertices to pick\n",
    "    max_dist = 1 # sphere radius\n",
    "\n",
    "    # pc sampling\n",
    "    distance_upper_bound = 0.01 # distance around borders \n",
    "    target_dist=0.00001 # distance between regular edge samples\n",
    "    n_points=4096 \n",
    "    noise_ampl = 5e-4 # noise amplitude for regular edge samples\n",
    "\n",
    "\n",
    "    slice_start, slice_end = data_slice\n",
    "    \n",
    "    start = time.time()\n",
    "    chunk = ABCChunk([meshes_filename, feats_filename])\n",
    "    end = time.time()\n",
    "    print(\"{action}: {timing:3.3f}\".format(action=\"Load chunk\", timing=end - start))\n",
    "\n",
    "\n",
    "    point_patches, point_distances, point_directions = [], [], []\n",
    "    \n",
    "    for item in chunk[slice_start:slice_end]:\n",
    "        start = time.time()\n",
    "        mesh = trimesh_load(item.obj)\n",
    "        labels = yaml.load(item.feat, Loader=Loader)\n",
    "        end = time.time()\n",
    "        print(\"{action}: {timing:3.3f}\".format(action=\"Load mesh from chunk\", timing=end - start))\n",
    "\n",
    "\n",
    "        \n",
    "        # form what's needed to sample\n",
    "        start = time.time()\n",
    "\n",
    "        shapes = {}\n",
    "        shapes_ids = [item.item_id]\n",
    "        shapes[item.item_id] = {\n",
    "            'vertices': process_vertices(np.array(mesh.vertices)),\n",
    "            'faces': mesh.faces,\n",
    "            'labels': labels,\n",
    "            'edges': mesh.edges\n",
    "        }\n",
    "        end = time.time()\n",
    "        print(\"{action}: {timing:3.3f}\".format(action=\"Form shape (process_vertices)\", timing=end - start))\n",
    "\n",
    "        \n",
    "        \n",
    "        start = time.time()\n",
    "        face_dict = defaultdict(list)\n",
    "        for i, surface in enumerate(shapes[item.item_id]['labels'][\"surfaces\"]):\n",
    "            vertices, surface_face_dict = get_vertices_from_face_indices(\n",
    "                surface['face_indices'], shapes[item.item_id]['faces'])\n",
    "            for vertex in surface_face_dict:        \n",
    "                face_dict[vertex] += surface_face_dict[vertex]\n",
    "        shapes[item.item_id]['face_dict'] = face_dict\n",
    "        end = time.time()\n",
    "        print(\"{action}: {timing:3.3f}\".format(action=\"Form shape (get_vertices_from_face_indices)\", timing=end - start))\n",
    "\n",
    "\n",
    "            \n",
    "        start = time.time()\n",
    "        sharp_vertices = set()\n",
    "        sharp_edges = defaultdict(set)\n",
    "        all_sharp_edges = set()\n",
    "        shape_curves = defaultdict(set)\n",
    "        for i, curv in enumerate(shapes[item.item_id]['labels'][\"curves\"]):\n",
    "            if curv[\"sharp\"]:\n",
    "                vert_ind = np.array(curv[\"vert_indices\"])\n",
    "\n",
    "                sharp_vertices.update(vert_ind)\n",
    "                shape_curves[i] = vert_ind\n",
    "                for ind1, ind2 in itertools.combinations(vert_ind, 2):\n",
    "                    if (ind1, ind2) in shapes[item.item_id]['edges'] or (ind2, ind1) in shapes[item.item_id]['edges']:\n",
    "                        sharp_edges[i].add((ind1, ind2))\n",
    "                        all_sharp_edges.add((ind1, ind2))\n",
    "\n",
    "            shapes[item.item_id]['sharp_vertices'] = sharp_vertices\n",
    "            shapes[item.item_id]['sharp_edges'] = sharp_edges  # dict by curve\n",
    "            shapes[item.item_id]['all_sharp_edges'] = all_sharp_edges # all\n",
    "            shapes[item.item_id]['shape_curves'] = shape_curves\n",
    "        end = time.time()\n",
    "        print(\"{action}: {timing:3.3f}\".format(action=\"Form shape (sharp_edges)\", timing=end - start))\n",
    "\n",
    "            \n",
    "            \n",
    "        # crop patches\n",
    "        patches = []\n",
    "\n",
    "\n",
    "        for i in range(num_samples_per_shape):\n",
    "            try:\n",
    "\n",
    "                start = time.time()\n",
    "                nbhood_mesh, vert_indices, faces_indices = random_spherical_patch(\n",
    "                    shapes[item.item_id], n_vert, max_dist)\n",
    "                end = time.time()\n",
    "                print(\"{action}: {timing:3.3f}\".format(action=\"random_spherical_patch\", timing=end - start))\n",
    "\n",
    "            except RecursionError:\n",
    "                print ('Recursion (KD tree) error on shape {}'.format(item.item_id))\n",
    "            else:\n",
    "\n",
    "                patches.append((mesh, vert_indices, faces_indices))\n",
    "        #         target_dist = np.sqrt(mesh.area_faces.sum()/n_points)/10\n",
    "                noise_ampl = 0 #np.sqrt(target_dist)*1e-3\n",
    "        #         print(target_dist)\n",
    "\n",
    "                start = time.time()\n",
    "                point_samples, distances, directions = resample(\n",
    "                    shapes[item.item_id], vert_indices, faces_indices, nbhood_mesh, n_points=n_points,\n",
    "                    distance_upper_bound=distance_upper_bound, noise_ampl=noise_ampl)\n",
    "                end = time.time()\n",
    "                print(\"{action}: {timing:3.3f}\".format(action=\"resample\", timing=end - start))\n",
    "\n",
    "\n",
    "                point_patches.append(point_samples)\n",
    "                point_distances.append(distances)\n",
    "                point_directions.append(directions)\n",
    "\n",
    "        \n",
    "                \n",
    "        \n",
    "#                 write_ply(f'{save_dir}/{shape_id}_{i}.ply', point_samples, distances=distances/distance_upper_bound*255, directions=directions)\n",
    "                \n",
    "\n",
    "    start = time.time()\n",
    "    point_patches = np.array(point_patches)  # num_samples_per_shape * num_shapes, 4096, 3\n",
    "    point_distances = np.array(point_distances)  # num_samples_per_shape * num_shapes, 4096, 1\n",
    "    point_directions = np.array(point_directions)  # 1num_samples_per_shape * num_shapes, 4096, 3\n",
    "    \n",
    "    sharp_dir_norms = np.linalg.norm(point_directions, axis=-1, keepdims=True)\n",
    "    nonzero = np.squeeze(sharp_dir_norms > 0, axis=-1)\n",
    "    point_directions[nonzero] /= sharp_dir_norms[nonzero]\n",
    "    end = time.time()\n",
    "    print(\"{action}: {timing:3.3f}\".format(action=\"Postprocessing\", timing=end - start))\n",
    "\n",
    "    \n",
    "    start = time.time()\n",
    "    with h5py.File(\"/home/artonson/tmp/abc/abc0000_{}_{}.hdf5\".format(slice_start, slice_end), \"w\") as f:\n",
    "        f.create_dataset(\"data\", data=point_patches, dtype=np.float64)\n",
    "        f.create_dataset(\"distances\", data=point_distances, dtype=np.float64)\n",
    "        f.create_dataset(\"directions\", data=point_directions, dtype=np.float64)\n",
    "    end = time.time()\n",
    "    print(\"{action}: {timing:3.3f}\".format(action=\"Saving to disk\", timing=end - start))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load chunk: 7.385\n",
      "Load mesh from chunk: 30.212\n",
      "Form shape (process_vertices): 0.005\n",
      "Form shape (get_vertices_from_face_indices): 0.609\n",
      "Form shape (sharp_edges): 176.276\n",
      "  building KD tree: 0.216\n",
      "  query in KD tree: 0.009\n",
      "  build vertices: 0.601\n",
      "  reindex: 0.010\n",
      "  create Trimesh: 0.003\n",
      "random_spherical_patch: 0.847\n",
      "  sample_surface: 0.005\n",
      "  build KDTree on sampled points: 0.038\n",
      "  sample sharp edges: 0.152\n",
      "  build KD tree on sharp samples: 0.030\n",
      "  query KD tree on sharp samples: 0.673\n",
      "  form distances: 0.000\n",
      "  add noise: 0.000\n",
      "resample: 0.906\n",
      "  building KD tree: 0.203\n",
      "  query in KD tree: 0.011\n",
      "  build vertices: 0.468\n",
      "  reindex: 0.010\n",
      "  create Trimesh: 0.003\n",
      "random_spherical_patch: 0.702\n",
      "  sample_surface: 0.004\n",
      "  build KDTree on sampled points: 0.042\n",
      "  sample sharp edges: 0.122\n",
      "  build KD tree on sharp samples: 0.002\n",
      "  query KD tree on sharp samples: 0.425\n",
      "  form distances: 0.001\n",
      "  add noise: 0.000\n",
      "resample: 0.600\n",
      "  building KD tree: 0.110\n",
      "  query in KD tree: 0.006\n",
      "  build vertices: 0.340\n",
      "  reindex: 0.011\n",
      "  create Trimesh: 0.003\n",
      "random_spherical_patch: 0.477\n",
      "  sample_surface: 0.005\n",
      "  build KDTree on sampled points: 0.043\n",
      "  sample sharp edges: 0.090\n",
      "  build KD tree on sharp samples: 0.005\n",
      "  query KD tree on sharp samples: 0.771\n",
      "  form distances: 0.000\n",
      "  add noise: 0.000\n",
      "resample: 0.919\n",
      "  building KD tree: 0.115\n",
      "  query in KD tree: 0.007\n",
      "  build vertices: 0.334\n",
      "  reindex: 0.006\n",
      "  create Trimesh: 0.002\n",
      "random_spherical_patch: 0.468\n",
      "  sample_surface: 0.004\n",
      "  build KDTree on sampled points: 0.064\n",
      "  sample sharp edges: 0.091\n",
      "  build KD tree on sharp samples: 0.019\n",
      "  query KD tree on sharp samples: 0.817\n",
      "  form distances: 0.000\n",
      "  add noise: 0.000\n",
      "resample: 1.000\n",
      "  building KD tree: 0.109\n",
      "  query in KD tree: 0.007\n",
      "  build vertices: 0.341\n",
      "  reindex: 0.007\n",
      "  create Trimesh: 0.002\n",
      "random_spherical_patch: 0.470\n",
      "  sample_surface: 0.004\n",
      "  build KDTree on sampled points: 0.024\n",
      "  sample sharp edges: 0.123\n",
      "  build KD tree on sharp samples: 0.021\n",
      "  query KD tree on sharp samples: 0.685\n",
      "  form distances: 0.001\n",
      "  add noise: 0.000\n",
      "resample: 0.861\n",
      "  building KD tree: 0.112\n",
      "  query in KD tree: 0.006\n",
      "  build vertices: 0.343\n",
      "  reindex: 0.006\n",
      "  create Trimesh: 0.002\n",
      "random_spherical_patch: 0.474\n",
      "  sample_surface: 0.003\n",
      "  build KDTree on sampled points: 0.024\n",
      "  sample sharp edges: 0.096\n",
      "  build KD tree on sharp samples: 0.017\n",
      "  query KD tree on sharp samples: 0.414\n",
      "  form distances: 0.000\n",
      "  add noise: 0.000\n",
      "resample: 0.561\n",
      "  building KD tree: 0.141\n",
      "  query in KD tree: 0.006\n",
      "  build vertices: 0.406\n",
      "  reindex: 0.010\n",
      "  create Trimesh: 0.003\n",
      "random_spherical_patch: 0.574\n",
      "  sample_surface: 0.004\n",
      "  build KDTree on sampled points: 0.043\n",
      "  sample sharp edges: 0.209\n",
      "  build KD tree on sharp samples: 0.100\n",
      "  query KD tree on sharp samples: 2.120\n",
      "  form distances: 0.004\n",
      "  add noise: 0.003\n",
      "resample: 2.530\n",
      "  building KD tree: 0.692\n",
      "  query in KD tree: 0.027\n",
      "  build vertices: 0.465\n",
      "  reindex: 0.012\n",
      "  create Trimesh: 0.003\n",
      "random_spherical_patch: 1.211\n",
      "  sample_surface: 0.004\n",
      "  build KDTree on sampled points: 0.045\n",
      "  sample sharp edges: 0.186\n",
      "  build KD tree on sharp samples: 0.044\n",
      "  query KD tree on sharp samples: 1.694\n",
      "  form distances: 0.001\n",
      "  add noise: 0.001\n",
      "resample: 1.981\n",
      "  building KD tree: 0.215\n",
      "  query in KD tree: 0.011\n",
      "  build vertices: 0.646\n",
      "  reindex: 0.011\n",
      "  create Trimesh: 0.003\n",
      "random_spherical_patch: 0.895\n",
      "  sample_surface: 0.005\n",
      "  build KDTree on sampled points: 0.048\n",
      "  sample sharp edges: 0.200\n",
      "  build KD tree on sharp samples: 0.042\n",
      "  query KD tree on sharp samples: 0.975\n",
      "  form distances: 0.000\n",
      "  add noise: 0.000\n",
      "resample: 1.277\n",
      "  building KD tree: 0.114\n",
      "  query in KD tree: 0.007\n",
      "  build vertices: 0.520\n",
      "  reindex: 0.011\n",
      "  create Trimesh: 0.003\n",
      "random_spherical_patch: 0.662\n",
      "  sample_surface: 0.006\n",
      "  build KDTree on sampled points: 0.049\n",
      "  sample sharp edges: 0.163\n",
      "  build KD tree on sharp samples: 0.015\n",
      "  query KD tree on sharp samples: 1.033\n",
      "  form distances: 0.001\n",
      "  add noise: 0.000\n",
      "resample: 1.274\n",
      "Postprocessing: 0.005\n",
      "Saving to disk: 0.007\n"
     ]
    }
   ],
   "source": [
    "process_parallel('/home/artonson/tmp/abc/abc_0000_obj_v00.7z',\n",
    "                 '/home/artonson/tmp/abc/abc_0000_feat_v00.7z',\n",
    "                 (0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 100\n",
    "\n",
    "obj_filename = '/home/artonson/tmp/abc/abc_0000_obj_v00.7z'\n",
    "feat_filename = '/home/artonson/tmp/abc/abc_0000_feat_v00.7z'\n",
    "    \n",
    "abc_data_slices = [(start, start + chunk_size)\n",
    "                   for start in range(0, 7200, chunk_size)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# run the filtering job in parallel\n",
    "delayed_iterable = (delayed(process_parallel)(obj_filename, feat_filename, data_slice)\n",
    "                    for data_slice in abc_data_slices)\n",
    "\n",
    "parallel = Parallel(n_jobs=36, backend=\"loky\")\n",
    "parallel(delayed_iterable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prometheus\r\n"
     ]
    }
   ],
   "source": [
    "!hostname"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
