{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abc_0051_00515110_43a0e83aaca82954cacdbe14_005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary config/cache directory at /tmp/matplotlib-y4ccgc13 because the default path (/home/user/.cache/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "import k3d\n",
    "import yaml\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import pymesh\n",
    "\n",
    "import torch\n",
    "\n",
    "import trimesh.transformations as tt\n",
    "import trimesh\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OMP_NUM_THREADS'] = '38'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_sharpness(mesh=None, plot_meshvert=True,\n",
    "                      samples=None, samples_distances=None,\n",
    "                      sharp_vert=None, sharp_curves=None,\n",
    "                      directions=None, directions_width=0.0025,\n",
    "                      samples_color=0x0000ff, samples_psize=0.002, \n",
    "                      mesh_color=0xbbbbbb, meshvert_color=0x666666, meshvert_psize=0.0025,\n",
    "                      sharpvert_color=0xff0000, sharpvert_psize=0.0025,\n",
    "                      sharpcurve_color=None, sharpcurve_width=0.0025,\n",
    "                      as_image=False, plot_height=768,\n",
    "                      cmap=k3d.colormaps.matplotlib_color_maps.coolwarm_r):\n",
    "    \n",
    "    plot = k3d.plot(height=plot_height)\n",
    "    \n",
    "    if None is not mesh:\n",
    "        k3d_mesh = k3d.mesh(mesh.vertices, mesh.faces, color=mesh_color, flat_shading=False)\n",
    "        plot += k3d_mesh\n",
    "\n",
    "        if plot_meshvert:\n",
    "            k3d_points = k3d.points(mesh.vertices, \n",
    "                                    point_size=meshvert_psize, color=meshvert_color)\n",
    "            plot += k3d_points\n",
    "            k3d_points.shader='flat'\n",
    "\n",
    "    if None is not samples:\n",
    "        colors = None\n",
    "        if None is not samples_distances:\n",
    "            max_dist = 1.0\n",
    "\n",
    "            colors = k3d.helpers.map_colors(\n",
    "                samples_distances, cmap, [0, max_dist]\n",
    "            ).astype(np.uint32)\n",
    "            k3d_points = k3d.points(samples, point_size=samples_psize, colors=colors)\n",
    "        else:\n",
    "            k3d_points = k3d.points(samples, point_size=samples_psize, color=samples_color)\n",
    "        plot += k3d_points\n",
    "        k3d_points.shader='flat'\n",
    "        \n",
    "        if None is not directions:\n",
    "            vectors = k3d.vectors(\n",
    "                samples,\n",
    "                directions * samples_distances[..., np.newaxis],\n",
    "                use_head=False, \n",
    "                line_width=directions_width)\n",
    "            print(vectors)\n",
    "            plot += vectors\n",
    "\n",
    "#             directions_to_plot = np.hstack((samples, samples + directions))\n",
    "            \n",
    "#             for i, dir_to_plot in enumerate(directions_to_plot):\n",
    "#                 dir_to_plot = dir_to_plot.reshape((2, 3))\n",
    "#                 if np.all(dir_to_plot[0] == dir_to_plot[1]):\n",
    "#                     continue\n",
    "#                 color = int(colors[i]) if None is not colors else samples_color\n",
    "#                 plt_line = k3d.line(dir_to_plot, \n",
    "#                                     shader='mesh', width=directions_width, color=color)\n",
    "#                 plot += plt_line\n",
    "\n",
    "    if None is not sharp_vert:\n",
    "        k3d_points = k3d.points(sharp_vert,\n",
    "                                point_size=sharpvert_psize, color=sharpvert_color)\n",
    "        plot += k3d_points\n",
    "        k3d_points.shader='flat'\n",
    "        \n",
    "        if None is not sharp_curves:            \n",
    "            if None is not sharpcurve_color:\n",
    "                color = sharpcurve_color\n",
    "            else:\n",
    "                import randomcolor\n",
    "                rand_color = randomcolor.RandomColor()\n",
    "            for i, vert_ind in enumerate(sharp_curves):\n",
    "                sharp_points_curve = mesh.vertices[vert_ind]\n",
    "                \n",
    "                if None is sharpcurve_color:\n",
    "                    color = rand_color.generate(hue='red')[0]\n",
    "                    color = int('0x' + color[1:], 16)\n",
    "                plt_line = k3d.line(sharp_points_curve, \n",
    "                                    shader='mesh', width=sharpcurve_width, color=color)\n",
    "                plot += plt_line\n",
    "        \n",
    "    plot.grid_visible = False\n",
    "    plot.display()\n",
    "    \n",
    "    if as_image:\n",
    "        plot.fetch_screenshot()\n",
    "        return Image(data=b64decode(plot.screenshot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mm/pixel\n",
    "HIGH_RES = 0.02\n",
    "MED_RES = 0.05\n",
    "LOW_RES = 0.125\n",
    "XLOW_RES = 0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Working with point patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sharpf.data import DataGenerationException\n",
    "from sharpf.utils.abc_utils.abc.abc_data import ABCModality, ABCChunk, ABC_7Z_FILEMASK\n",
    "from sharpf.data.annotation import ANNOTATOR_BY_TYPE\n",
    "from sharpf.data.camera_pose_manager import POSE_MANAGER_BY_TYPE\n",
    "from sharpf.data.datasets.sharpf_io import save_depth_maps\n",
    "from sharpf.data.imaging import IMAGING_BY_TYPE\n",
    "from sharpf.data.noisers import NOISE_BY_TYPE\n",
    "from sharpf.utils.abc_utils.abc import feature_utils\n",
    "from sharpf.utils.py_utils.console import eprint_t\n",
    "from sharpf.utils.py_utils.os import add_suffix\n",
    "from sharpf.utils.py_utils.config import load_func_from_config\n",
    "from sharpf.utils.abc_utils.mesh.io import trimesh_load\n",
    "from sharpf.utils.plotting import display_depth_sharpness, illustrate_camera\n",
    "from sharpf.utils.camera_utils.camera_pose import camera_to_display\n",
    "from sharpf.utils.abc_utils.mesh.indexing import reindex_zerobased, compute_relative_indexes\n",
    "import sharpf.data.data_smells as smells\n",
    "\n",
    "from sharpf.utils.camera_utils.spherical_spiral_sampling import spherical_spiral_sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3D_normals_dataset_generation.ipynb  realworld_sharpf_scans_raw\r\n",
      "_SKOLTECH.rar\t\t\t     scannet\r\n",
      "abc\t\t\t\t     sharp_features_data\r\n",
      "colmap_test\t\t\t     shm_stbasil\r\n",
      "mesh_denoising\t\t\t     toy\r\n",
      "realworld_sharpf_scans\r\n"
     ]
    }
   ],
   "source": [
    "!ls /data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'00510073_951e25d2ded40f22b598f84e_000'"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with ABCChunk(['/data/abc/abc_0051_obj_v00.7z', '/data/abc/abc_0051_feat_v00.7z']) as data_holder:\n",
    "    item = data_holder.get('00510073_951e25d2ded40f22b598f84e_000')\n",
    "item.item_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh, _, _ = trimesh_load(item.obj)\n",
    "features = yaml.load(item.feat, Loader=yaml.Loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 2), dtype=int32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pymesh.detect_self_intersection(mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "  \"shape_fabrication_extent\": 10.0,\n",
    "  \"short_curve_quantile\": 0.25,\n",
    "  \"base_n_points_per_short_curve\": 8,\n",
    "  \"base_resolution_3d\": 0.125,\n",
    "  \"camera_pose\": {\n",
    "    \"type\": \"sphere_spiral_to_origin\",\n",
    "    \"n_images\": 0,\n",
    "    \"layer_radius\": 0.1,\n",
    "    \"resolution\": 0.02,\n",
    "    \"n_initial_samples\": 1001,\n",
    "    \"min_arc_length\": 0\n",
    "#     \"type\": \"composite\",\n",
    "#     \"sequences\": [\n",
    "#         {\n",
    "#             \"type\": \"sphere_spiral_to_origin\",\n",
    "#             \"n_images\": 0,\n",
    "#             \"layer_radius\": 0.1,\n",
    "#             \"resolution\": 0.01,\n",
    "#             \"n_initial_samples\": 10001,\n",
    "#             \"min_arc_length\": 0.1\n",
    "#         }\n",
    "#       {\n",
    "#         \"type\": \"sphere_to_origin\",\n",
    "#         \"n_images\": 2\n",
    "#       },\n",
    "#       {\n",
    "#         \"type\": \"xy_translation\",\n",
    "#         \"n_images\": 8*8\n",
    "#       },\n",
    "#       {\n",
    "#         \"type\": \"z_rotation\",\n",
    "#         \"n_images\": 5\n",
    "#       }\n",
    "#     ]\n",
    "  },\n",
    "  \"imaging\": {\n",
    "    \"type\": \"raycasting\",\n",
    "    \"projection\": \"ortho\",\n",
    "    \"resolution_image\": 512,\n",
    "    \"resolution_3d\": 0.02,\n",
    "    \"fov\": [115, 85, 80],\n",
    "    \"validate_image\": True\n",
    "  },\n",
    "  \"noise\": {\n",
    "    \"type\": \"z_direction\",\n",
    "    \"scale\": 0.0\n",
    "  },\n",
    "  \"annotation\": {\n",
    "    \"type\": \"surface_based_aabb\",\n",
    "    \"distance_upper_bound\": 1.0,\n",
    "    \"distance_computation_method\": \"geom\",\n",
    "  },\n",
    "  \"smell_coarse_surfaces_by_num_edges\": {\n",
    "    \"num_edges_threshold\": 8\n",
    "  },\n",
    "  \"smell_coarse_surfaces_by_angles\": {\n",
    "    \"max_angle_threshold_degrees\": 10.0\n",
    "  },\n",
    "  \"smell_deviating_resolution\": {\n",
    "    \"resolution_3d\": 0.02,\n",
    "    \"resolution_deviation_tolerance\": 0.01\n",
    "  },\n",
    "  \"smell_sharpness_discontinuities\": { },\n",
    "  \"smell_bad_face_sampling\": {\n",
    "    \"min_points_per_face\": 0.02,\n",
    "    \"max_points_per_face\": 20.0\n",
    "  },\n",
    "  \"smell_raycasting_background\": { },\n",
    "  \"smell_mesh_self_intersections\": { },\n",
    "  \"smell_depth_discontinuity\": {\n",
    "    \"depth_discontinuity_threshold\": 0.5\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'composite': <class 'sharpf.data.camera_pose_manager.CompositePoseManager'>, 'sphere_to_origin': <class 'sharpf.data.camera_pose_manager.SphereOrientedToWorldOrigin'>, 'sphere_spiral_to_origin': <class 'sharpf.data.camera_pose_manager.SphericalSpiralOrientedToWorldOrigin'>, 'z_rotation': <class 'sharpf.data.camera_pose_manager.ZRotationInCameraFrame'>, 'xy_translation': <class 'sharpf.data.camera_pose_manager.XYTranslationInCameraFrame'>} {'type': 'sphere_spiral_to_origin', 'n_images': 0, 'layer_radius': 0.1, 'resolution': 0.02, 'n_initial_samples': 1001, 'min_arc_length': 0}\n",
      "{'raycasting': <class 'sharpf.data.imaging.RaycastingImaging'>} {'type': 'raycasting', 'projection': 'ortho', 'resolution_image': 512, 'resolution_3d': 0.02, 'fov': [115, 85, 80], 'validate_image': True}\n",
      "{'no_noise': <class 'sharpf.data.noisers.NoNoise'>, 'isotropic_gaussian': <class 'sharpf.data.noisers.IsotropicGaussianNoise'>, 'normals_gaussian': <class 'sharpf.data.noisers.NormalsGaussianNoise'>, 'z_direction': <class 'sharpf.data.noisers.ZDirectionGaussianNoise'>, 'many_noisers': <class 'sharpf.data.noisers.ManyNoise'>} {'type': 'z_direction', 'scale': 0.0}\n",
      "{'surface_based_aabb': <class 'sharpf.data.annotation.AABBSurfacePatchAnnotator'>} {'type': 'surface_based_aabb', 'distance_upper_bound': 1.0, 'distance_computation_method': 'geom'}\n"
     ]
    }
   ],
   "source": [
    "shape_fabrication_extent = config.get('shape_fabrication_extent', 10.0)\n",
    "base_n_points_per_short_curve = config.get('base_n_points_per_short_curve', 8)\n",
    "base_resolution_3d = config.get('base_resolution_3d', LOW_RES)\n",
    "\n",
    "short_curve_quantile = config.get('short_curve_quantile', 0.05)\n",
    "\n",
    "pose_manager = load_func_from_config(POSE_MANAGER_BY_TYPE, config['camera_pose'])\n",
    "imaging = load_func_from_config(IMAGING_BY_TYPE, config['imaging'])\n",
    "noiser = load_func_from_config(NOISE_BY_TYPE, config['noise'])\n",
    "annotator = load_func_from_config(ANNOTATOR_BY_TYPE, config['annotation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "smell_coarse_surfaces_by_num_edges = smells.SmellCoarseSurfacesByNumEdges.from_config(config['smell_coarse_surfaces_by_num_edges'])\n",
    "smell_coarse_surfaces_by_angles = smells.SmellCoarseSurfacesByAngles.from_config(config['smell_coarse_surfaces_by_angles'])\n",
    "smell_deviating_resolution = smells.SmellDeviatingResolution.from_config(config['smell_deviating_resolution'])\n",
    "smell_sharpness_discontinuities = smells.SmellSharpnessDiscontinuities.from_config(config['smell_sharpness_discontinuities'])\n",
    "smell_bad_face_sampling = smells.SmellBadFaceSampling.from_config(config['smell_bad_face_sampling'])\n",
    "smell_raycasting_background = smells.SmellRaycastingBackground.from_config(config['smell_raycasting_background'])\n",
    "smell_depth_discontinuity = smells.SmellDepthDiscontinuity.from_config(config['smell_depth_discontinuity'])\n",
    "smell_mesh_self_intersections = smells.SmellMeshSelfIntersections.from_config(config['smell_mesh_self_intersections'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_mesh(mesh, features, shape_fabrication_extent, resolution_3d,\n",
    "               short_curve_quantile=0.05, n_points_per_short_curve=4):\n",
    "    # compute standard size spatial extent\n",
    "    mesh_extent = np.max(mesh.bounding_box.extents)\n",
    "    mesh = mesh.apply_scale(shape_fabrication_extent / mesh_extent)\n",
    "\n",
    "    # compute lengths of curves\n",
    "    sharp_curves_lengths = feature_utils.get_curves_extents(mesh, features)\n",
    "\n",
    "    least_len = np.quantile(sharp_curves_lengths, short_curve_quantile)\n",
    "    least_len_mm = resolution_3d * n_points_per_short_curve\n",
    "\n",
    "    scale = least_len_mm / least_len\n",
    "    mesh = mesh.apply_scale(scale)\n",
    "\n",
    "    return mesh, scale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mesh, mesh_scale = scale_mesh(mesh, features, shape_fabrication_extent, base_resolution_3d,\n",
    "                              short_curve_quantile=short_curve_quantile,\n",
    "                              n_points_per_short_curve=base_n_points_per_short_curve)\n",
    "\n",
    "mesh = mesh.apply_translation(-mesh.vertices.mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh = mesh.apply_scale(shape_fabrication_extent / np.max(mesh.bounding_box.extents))\n",
    "mesh = mesh.apply_scale(mesh_scale)\n",
    "mesh = mesh.apply_translation(-mesh.vertices.mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.040656477057844"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(mesh.bounding_box.extents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = trimesh.exchange.export.export_mesh(\n",
    "    mesh,\n",
    "    '/logs/abc_0051_00510073_951e25d2ded40f22b598f84e_000.obj',\n",
    "    'obj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sharpf.data.imaging import RaycastingImaging\n",
    "import sharpf.data.datasets.sharpf_io as sharpf_io\n",
    "from sharpf.utils.abc_utils.hdf5.dataset import Hdf5File, PreloadTypes\n",
    "from typing import List, Mapping\n",
    "from functools import partial\n",
    "from sharpf.utils.camera_utils.camera_pose import CameraPose, camera_to_display\n",
    "\n",
    "\n",
    "resolution_3d = 0.02\n",
    "\n",
    "d = '/logs/paper_extra/spherical_sphiral/'\n",
    "gt_filename = os.path.join(d, 'abc_0051_64_65.hdf5')\n",
    "\n",
    "ground_truth_dataset = Hdf5File(\n",
    "    gt_filename,\n",
    "    io=sharpf_io.WholeDepthMapIO,\n",
    "    preload=PreloadTypes.LAZY,\n",
    "    labels='*')\n",
    "gt_dataset = [view for view in ground_truth_dataset]\n",
    "# depth images captured from a variety of views around the 3D shape\n",
    "gt_images = [view['image'] for view in gt_dataset]\n",
    "# ground-truth distances (multi-view consistent for the global 3D shape)\n",
    "gt_distances = [view.get('distances', np.ones_like(view['image'])) for view in gt_dataset]\n",
    "# extrinsic camera matrixes describing the 3D camera poses used to capture depth images\n",
    "gt_extrinsics = [view['camera_pose'] for view in gt_dataset]\n",
    "# intrinsic camera parameters describing how to compute image from points and vice versa\n",
    "gt_intrinsics = [dict(resolution_image=gt_images[0].shape[::-1], resolution_3d=resolution_3d, projection=None, validate_image=None) for view in\n",
    "                 gt_dataset]\n",
    "\n",
    "def get_view(\n",
    "        images: List[np.array],\n",
    "        distances: List[np.array],\n",
    "        extrinsics: List[np.array],\n",
    "        intrinsics_dict: List[Mapping],\n",
    "        i):\n",
    "    \"\"\"A helper function to conveniently prepare view information.\"\"\"\n",
    "    image_i = images[i]  # [h, w]\n",
    "    distances_image_i = distances[i]  # [h, w]\n",
    "    # Kill background for nicer visuals\n",
    "    distances_i = np.zeros_like(distances_image_i)\n",
    "    distances_i[np.nonzero(image_i)] = distances_image_i[np.nonzero(image_i)]\n",
    "\n",
    "    pose_i = CameraPose(extrinsics[i])\n",
    "    imaging_i = RaycastingImaging(**intrinsics_dict[i])\n",
    "    points_i = pose_i.camera_to_world(imaging_i.image_to_points(image_i))\n",
    "\n",
    "    return image_i, distances_i, points_i, pose_i, imaging_i\n",
    "\n",
    "\n",
    "get_view_local = partial(get_view, gt_images, gt_distances, gt_extrinsics, gt_intrinsics)\n",
    "\n",
    "\n",
    "# view_i = get_view_local(0)\n",
    "# view_j = get_view_local(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1023/1023 [28:35:38<00:00, 100.62s/it] \n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(gt_dataset))):\n",
    "    image, distances, points, pose, imaging = get_view_local(i)\n",
    "\n",
    "    distances, directions, has_sharp = annotator.annotate(\n",
    "        mesh, features, points)\n",
    "\n",
    "    ray_indexes = np.where(image.ravel() != 0)[0]\n",
    "    distances_image = imaging.points_to_image(distances.reshape(-1, 1), ray_indexes, assign_channels=[0])\n",
    "    directions_image = imaging.points_to_image(directions, ray_indexes, assign_channels=[0, 1, 2])\n",
    "    \n",
    "    gt_dataset[i]['distances'] = distances_image\n",
    "    gt_dataset[i]['directions'] = directions_image\n",
    "    \n",
    "    np.save(\n",
    "        os.path.join(d, 'npy', '{0:04d}__distances.npy'.format(i)),\n",
    "        distances_image)\n",
    "    np.save(\n",
    "        os.path.join(d, 'npy', '{0:04d}__directions.npy'.format(i)),\n",
    "        directions_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sharpf.data.datasets.sharpf_io import save_depth_maps\n",
    "gt_filename_out = os.path.join(d, 'abc_0051_64_65__whole_annotation.hdf5')\n",
    "save_depth_maps(gt_dataset, gt_filename_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, distances, points, pose, imaging = get_view_local(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 49941 is out of bounds for axis 0 with size 512",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-235-10da25177e0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msharp_vert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msharpvert_color\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0xF0C821\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msamples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples_psize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.02\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     samples_distances=distances[np.where(image.ravel() != 0)[0]])\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: index 49941 is out of bounds for axis 0 with size 512"
     ]
    }
   ],
   "source": [
    "display_sharpness(\n",
    "    mesh, plot_meshvert=False, mesh_color=0x0D0887,\n",
    "    sharp_vert=None, sharpvert_color=0xF0C821,\n",
    "    samples=points, samples_psize=0.02, \n",
    "    samples_distances=distances[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "\n",
    "class MplColorHelper:\n",
    "\n",
    "    def __init__(self, cmap_name, start_val, stop_val):\n",
    "        self.cmap_name = cmap_name\n",
    "        self.cmap = plt.get_cmap(cmap_name)\n",
    "        self.norm = mpl.colors.Normalize(vmin=start_val, vmax=stop_val)\n",
    "        self.scalarMap = cm.ScalarMappable(norm=self.norm, cmap=self.cmap)\n",
    "\n",
    "    def get_rgb(self, val):\n",
    "        return self.scalarMap.to_rgba(val)\n",
    "\n",
    "\n",
    "    \n",
    "def export_points_to_npy(\n",
    "    filename, \n",
    "    points, \n",
    "    distances=None, \n",
    "    pose=None, \n",
    "    radius=0.02,\n",
    "    max_distance=1.0):\n",
    "    \n",
    "    tol = 1e-3\n",
    "    if distances is None:\n",
    "        if pose is not None:\n",
    "            distances = np.linalg.norm(pose.frame_origin - points, axis=1)        \n",
    "            helper = MplColorHelper(\n",
    "                'viridis',\n",
    "                np.min(distances) - tol,\n",
    "                np.max(distances) + tol)\n",
    "        else:\n",
    "            raise ValueError()\n",
    "    else:\n",
    "        helper = MplColorHelper(\n",
    "            'plasma_r',\n",
    "            -tol,\n",
    "            max_distance + tol)\n",
    "\n",
    "    iterable = zip(points, distances)\n",
    "    colors_rgb = []\n",
    "    for point, distance in iterable:\n",
    "        rgba = helper.get_rgb(distance)\n",
    "        colors_rgb.append(rgba[:3])\n",
    "        \n",
    "    np.save(filename, np.hstack((points, colors_rgb)))\n",
    "    print('saved {}'.format(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /logs/abc_0051_00510073_951e25d2ded40f22b598f84e_000__points_202.npy\n",
      "saved /logs/abc_0051_00510073_951e25d2ded40f22b598f84e_000__points_204.npy\n"
     ]
    }
   ],
   "source": [
    "export_points_to_npy(\n",
    "    '/logs/abc_0051_00510073_951e25d2ded40f22b598f84e_000__points_202.npy',\n",
    "    view_i[2],\n",
    "    distances=view_i[1][view_i[1]!=0]\n",
    ")\n",
    "\n",
    "export_points_to_npy(\n",
    "    '/logs/abc_0051_00510073_951e25d2ded40f22b598f84e_000__points_204.npy',\n",
    "    view_j[2],\n",
    "    distances=view_j[1][view_j[1]!=0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_origins = spherical_spiral_sampling(\n",
    "    np.max(mesh.bounding_box.extents),\n",
    "    layer_radius=0.1,\n",
    "    resolution=0.01,\n",
    "    n_initial_samples=10001,\n",
    "    min_arc_length=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(camera_origins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bd54d62335b4c47981307d9c630daec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sharp_vert_indexes = np.concatenate(\n",
    "#     [c['vert_indices'] for c in features['curves'] if c['sharp']]\n",
    "# )\n",
    "# sharp_vert = mesh.vertices[sharp_vert_indexes]\n",
    "\n",
    "display_sharpness(\n",
    "    mesh, plot_meshvert=False, mesh_color=0x0D0887,\n",
    "    sharp_vert=camera_origins, sharpvert_color=0xF0C821,\n",
    "#     sharp_curves=[f['vert_indices'] for f in features['curves'] if f['sharp']], \n",
    "    sharpcurve_color=0xF0C821, sharpcurve_width=0.05,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_manager.prepare(mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot = k3d.plot(grid_visible=False, height=1024)\n",
    "# for idx, pose in tqdm(enumerate(pose_manager.camera_poses)):\n",
    "#     plot += illustrate_camera(pose, w=0.05, l=0.2)\n",
    "# # plot += k3d.mesh(mesh.vertices, mesh.faces, color=0xbbbbbb, flat_shading=False)\n",
    "# plot.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [04:18<00:00,  3.88it/s]\n"
     ]
    }
   ],
   "source": [
    "def get_image_from_pose(pose, mesh, features, imaging, annotator):\n",
    "    # extract neighbourhood\n",
    "    try:\n",
    "        image, points, normals, mesh_face_indexes = \\\n",
    "            imaging.get_image_from_pose(mesh, pose, return_hit_face_indexes=True)\n",
    "    except DataGenerationException as e:\n",
    "#         eprint_t(str(e))\n",
    "        return np.zeros(imaging.resolution_image), np.zeros(imaging.resolution_image), None, None\n",
    "\n",
    "#     nbhood, mesh_vertex_indexes, mesh_face_indexes = \\\n",
    "#                 feature_utils.submesh_from_hit_surfaces(mesh, features, mesh_face_indexes)\n",
    "\n",
    "#     # create annotations: condition the features onto the nbhood\n",
    "#     nbhood_features = feature_utils.compute_features_nbhood(\n",
    "#         mesh, features, mesh_face_indexes, mesh_vertex_indexes=mesh_vertex_indexes,\n",
    "#         deduce_verts_from_faces=False)\n",
    "\n",
    "#     # remove vertices lying on the boundary (sharp edges found in 1 face only)\n",
    "# #     nbhood_features = feature_utils.remove_boundary_features(nbhood, nbhood_features, how='edges')\n",
    "\n",
    "#     noisy_points = noiser.make_noise(\n",
    "#         pose.world_to_camera(points),\n",
    "#         normals,\n",
    "#         z_direction=np.array([0., 0., -1.]))\n",
    "\n",
    "#         # compute the TSharpDF\n",
    "#     try:\n",
    "#         distances, directions, has_sharp = annotator.annotate(\n",
    "#             nbhood, nbhood_features, pose.camera_to_world(noisy_points))\n",
    "#     except DataGenerationException as e:\n",
    "#         eprint_t(str(e))\n",
    "\n",
    "#     # convert everything to images\n",
    "#     ray_indexes = np.where(image.ravel() != 0)[0]\n",
    "#     noisy_image = imaging.points_to_image(noisy_points, ray_indexes)\n",
    "#     normals = imaging.points_to_image(normals, ray_indexes, assign_channels=[0, 1, 2])\n",
    "#     distances = imaging.points_to_image(distances.reshape(-1, 1), ray_indexes, assign_channels=[0])\n",
    "#     directions = imaging.points_to_image(directions, ray_indexes, assign_channels=[0, 1, 2])\n",
    "        \n",
    "    distances = None\n",
    "    nbhood = None\n",
    "    nbhood_features = None\n",
    "    return image, distances, nbhood, nbhood_features\n",
    "\n",
    "\n",
    "\n",
    "all_images, all_distances, all_patches, all_features, all_poses = [], [], [], [], []\n",
    "pose_manager.prepare(mesh)\n",
    "for pose in tqdm(pose_manager.camera_poses):\n",
    "    image, distances, patch, patch_features = get_image_from_pose(pose, mesh, features, imaging, annotator)\n",
    "    all_images.append(image)\n",
    "    all_distances.append(distances)\n",
    "    all_patches.append(patch)\n",
    "    all_features.append(patch_features)\n",
    "    all_poses.append(pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [01:49,  9.17it/s]\n"
     ]
    }
   ],
   "source": [
    "plt.ioff()\n",
    "\n",
    "for i, image in tqdm(enumerate(all_images)):\n",
    "    _ = display_depth_sharpness(\n",
    "        depth_images=[\n",
    "            camera_to_display(image)],\n",
    "    #     sharpness_images=[\n",
    "    #         camera_to_display(distances) \n",
    "    #         for distances in all_distances[pose_idx]],\n",
    "        ncols=1,\n",
    "        max_sharpness=1.05)\n",
    "    _ = plt.savefig('/logs/images_for_video/{0:04d}.png'.format(i + 1))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images, all_distances = np.array(all_images), np.array(all_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_directions = 2\n",
    "n_offsets_y, n_offsets_x = 8, 8\n",
    "n_offsets = n_offsets_y * n_offsets_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images = all_images.reshape((n_directions, n_offsets_y, n_offsets_x, 64, 64))\n",
    "all_images = np.rollaxis(all_images, 1, 3).reshape((2, n_offsets, 64, 64))\n",
    "\n",
    "all_distances = all_distances.reshape((n_directions, n_offsets_y, n_offsets_x, 64, 64))\n",
    "all_distances = np.rollaxis(all_distances, 1, 3).reshape((2, n_offsets, 64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pose_idx = 0\n",
    "\n",
    "display_depth_sharpness(\n",
    "    depth_images=[\n",
    "        camera_to_display(image) \n",
    "        for image in all_images[pose_idx]],\n",
    "#     sharpness_images=[\n",
    "#         camera_to_display(distances) \n",
    "#         for distances in all_distances[pose_idx]],\n",
    "    ncols=8,\n",
    "    axes_size=(4, 4),\n",
    "    layout_hpad=8,\n",
    "    max_sharpness=1.05,\n",
    "    frame_visible=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pose_idx = 0\n",
    "\n",
    "# row_idx, col_idx = 2, 3\n",
    "# row_idx, col_idx = 4, 3\n",
    "# row_idx, col_idx = 4, 6\n",
    "row_idx, col_idx = 3, 5\n",
    "item_idx = row_idx * n_offsets_x + col_idx\n",
    "print(item_idx, col_idx * n_offsets_x + row_idx)\n",
    "\n",
    "display_depth_sharpness(\n",
    "    depth_images=[\n",
    "        camera_to_display(image) \n",
    "        for image in all_images[pose_idx][[item_idx]]],\n",
    "    sharpness_images=[\n",
    "        camera_to_display(distances) \n",
    "        for distances in all_distances[pose_idx][[item_idx]]],\n",
    "    ncols=1,\n",
    "    axes_size=(4, 4),\n",
    "#     layout_pad=1,\n",
    "    max_sharpness=1.05,\n",
    "    frame_visible=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pose_manager.prepare(mesh)\n",
    "pose = all_poses[43]\n",
    "# plot = k3d.plot(grid_visible=False, height=1024)\n",
    "# for idx, pose in tqdm(enumerate(all_poses[:item_idx])):\n",
    "#     plot += illustrate_camera(pose, w=0.1, l=0.75)\n",
    "# plot += k3d.mesh(mesh.vertices, mesh.faces, color=0xbbbbbb, flat_shading=False)\n",
    "# plot.display()\n",
    "\n",
    "display_sharpness(\n",
    "    mesh, plot_meshvert=False, \n",
    "    samples=pose.camera_to_world(\n",
    "        imaging.image_to_points(\n",
    "            all_images[pose_idx][item_idx])),\n",
    "    samples_psize=0.1,\n",
    "#     sharp_vert=sharp_vert, sharpvert_color=0xF0C821,\n",
    "#     sharp_curves=[f['vert_indices'] for f in features['curves'] if f['sharp']], \n",
    "#     sharpcurve_color=0xF0C821, sharpcurve_width=0.05,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_points_to_npy(\n",
    "    filename, \n",
    "    points, \n",
    "    distances=None, \n",
    "    pose=None, \n",
    "    radius=0.02,\n",
    "    max_distance=1.0):\n",
    "    \n",
    "    tol = 1e-3\n",
    "    if distances is None:\n",
    "        if pose is not None:\n",
    "            distances = np.linalg.norm(pose.frame_origin - points, axis=1)        \n",
    "            helper = MplColorHelper(\n",
    "                'viridis',\n",
    "                np.min(distances) - tol,\n",
    "                np.max(distances) + tol)\n",
    "        else:\n",
    "            raise ValueError()\n",
    "    else:\n",
    "        helper = MplColorHelper(\n",
    "            'plasma_r',\n",
    "            -tol,\n",
    "            max_distance + tol)\n",
    "\n",
    "    iterable = zip(points, distances)\n",
    "    colors_rgb = []\n",
    "    for point, distance in iterable:\n",
    "        rgba = helper.get_rgb(distance)\n",
    "        colors_rgb.append(rgba[:3])\n",
    "        \n",
    "#         point_mesh = trimesh.creation.icosphere(\n",
    "#             subdivisions=1,\n",
    "#             radius=radius,\n",
    "#             color=rgba[:3])\n",
    "#         point_mesh.vertices += point\n",
    "#         full_mesh.append(point_mesh)\n",
    "#     full_mesh = trimesh.util.concatenate(full_mesh)\n",
    "#     _ = trimesh.exchange.export.export_mesh(\n",
    "#         full_meshes,\n",
    "#         'filename',\n",
    "#         'obj')\n",
    "\n",
    "    np.save(filename, np.hstack((points, colors_rgb)))\n",
    "    print('saved {}'.format(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_points_to_npy('/logs/data_generation__image_3.npy', pose.camera_to_world(\n",
    "        imaging.image_to_points(\n",
    "            all_images[pose_idx][item_idx])), pose=pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_sharpness(all_patches[52])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edges(mesh, features):\n",
    "    curve_segments = []\n",
    "    for curve_id, curve in enumerate(features['curves']):\n",
    "        if curve['sharp']:\n",
    "            # (n, 2) mask of boolean variables where each variable stores\n",
    "            # True if the corresponding vertex idx is in curve\n",
    "            is_edgevert_in_curve = np.isin(mesh.edges_unique, curve['vert_indices'])\n",
    "            is_edge_in_curve = np.all(is_edgevert_in_curve, axis=1)\n",
    "            edge_in_curve_indexes = np.where(is_edge_in_curve)[0]\n",
    "            curve_edges = mesh.edges_unique[edge_in_curve_indexes]  # n_curve, 2\n",
    "            curve_segment_xyz = mesh.vertices[curve_edges]  # n_curve, 2, 3\n",
    "            curve_segments.append((curve_id, curve['type'], np.ravel(curve_segment_xyz)))\n",
    "\n",
    "    return curve_segments\n",
    "\n",
    "\n",
    "def export_features_to_obj(output_filename, curve_segments):\n",
    "    with open(output_filename, 'w') as fobj:\n",
    "        vertices = ''\n",
    "        indices = ''\n",
    "        max_vi = 1\n",
    "        for curve_id, curve_type, xyz_xyz in curve_segments:\n",
    "            xyz_xyz = xyz_xyz.reshape((-1, 2, 3))\n",
    "            for v1, v2 in xyz_xyz:\n",
    "                vertices += 'v {v1}\\nv {v2}\\n'.format(\n",
    "                    v1=' '.join([str(coord) for coord in v1]),\n",
    "                    v2=' '.join([str(coord) for coord in v2])\n",
    "                )\n",
    "            for edge_idx, edge in enumerate(xyz_xyz):\n",
    "                indices += 'l {i1} {i2}\\n'.format(\n",
    "                    i1=str(max_vi + edge_idx * 2),\n",
    "                    i2=str(max_vi + edge_idx * 2 + 1),\n",
    "                )\n",
    "            max_vi += 2 * len(xyz_xyz)\n",
    "        fobj.write(vertices + '\\n' + indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, data_idx in enumerate([26, 28, 43, 52]):\n",
    "    curve_segments = get_edges(all_patches[data_idx], all_features[data_idx])\n",
    "    trimesh.exchange.export.export_mesh(\n",
    "        all_patches[data_idx], \n",
    "        '/logs/figures_for_paper/2-data-pipeline-images-{}-mesh.obj'.format(idx), \n",
    "        'obj')\n",
    "    export_features_to_obj(\n",
    "        '/logs/figures_for_paper/2-data-pipeline-images-{}-features.obj'.format(idx), \n",
    "        curve_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate camera poses\n",
    "pose_manager.prepare(mesh)\n",
    "\n",
    "pose_manager_iter = iter(pose_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# camera_pose = next(pose_manager_iter)\n",
    "\n",
    "# # extract neighbourhood\n",
    "# try:\n",
    "#     image, points, normals, mesh_face_indexes = \\\n",
    "#         imaging.get_image_from_pose(mesh, camera_pose, return_hit_face_indexes=True)\n",
    "# except DataGenerationException as e:\n",
    "#     eprint_t(str(e))\n",
    "\n",
    "\n",
    "plot = k3d.plot(grid_visible=False, height=1024)\n",
    "for idx, pose in tqdm(enumerate(pose_manager)):\n",
    "    if idx % 6 == 0:\n",
    "        plot += illustrate_camera(pose, w=0.1, l=0.75)\n",
    "    if idx == 63:\n",
    "        break\n",
    "plot += k3d.mesh(mesh.vertices, mesh.faces, color=0xbbbbbb, flat_shading=False)\n",
    "plot.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sharpf.data.annotation import ANNOTATOR_BY_TYPE\n",
    "from sharpf.data.mesh_nbhoods import NBHOOD_BY_TYPE\n",
    "from sharpf.data.noisers import NOISE_BY_TYPE\n",
    "from sharpf.data.point_samplers import SAMPLER_BY_TYPE\n",
    "\n",
    "config_points = {\n",
    "  \"shape_fabrication_extent\": 10.0,\n",
    "  \"short_curve_quantile\": 0.25,\n",
    "  \"base_n_points_per_short_curve\": 8,\n",
    "  \"base_resolution_3d\": 0.125,\n",
    "  \"neighbourhood\": {\n",
    "    \"type\": \"random_euclidean_sphere\",\n",
    "    \"max_patches_per_mesh\": 128,\n",
    "    \"n_vertices\": None,\n",
    "    \"centroid\": None,\n",
    "    \"centroid_mode\": \"poisson_disk\",\n",
    "    \"radius_base\": 10.0,\n",
    "    \"radius_delta\": 0.0,\n",
    "    \"geodesic_patches\": True,\n",
    "    \"radius_scale_mode\": \"no_scale\"\n",
    "  },\n",
    "  \"sampling\": {\n",
    "    \"type\": \"poisson_disk\",\n",
    "    \"n_points\": 4096,\n",
    "    \"resolution_3d\": 0.05,\n",
    "    \"make_n_points\": \"crop_center\"\n",
    "  },\n",
    "  \"noise\": {\n",
    "    \"type\": \"many_noisers\",\n",
    "    \"subtype\": \"isotropic_gaussian\",\n",
    "    \"scale\": [0.0]\n",
    "  },\n",
    "  \"annotation\": {\n",
    "    \"type\": \"surface_based_aabb\",\n",
    "    \"distance_upper_bound\": 1.0\n",
    "  },\n",
    "  \"smell_coarse_surfaces_by_num_edges\": {\n",
    "    \"num_edges_threshold\": 8\n",
    "  },\n",
    "  \"smell_coarse_surfaces_by_angles\": {\n",
    "    \"max_angle_threshold_degrees\": 10.0\n",
    "  },\n",
    "  \"smell_deviating_resolution\": {\n",
    "    \"resolution_3d\": 0.125,\n",
    "    \"resolution_deviation_tolerance\": 0.0625\n",
    "  },\n",
    "  \"smell_sharpness_discontinuities\": {\n",
    "  },\n",
    "  \"smell_bad_face_sampling\": {\n",
    "    \"min_points_per_face\": 0.02,\n",
    "    \"max_points_per_face\": 20.0\n",
    "  }\n",
    "}\n",
    "\n",
    "shape_fabrication_extent = config.get('shape_fabrication_extent', 10.0)\n",
    "base_n_points_per_short_curve = config.get('base_n_points_per_short_curve', 8)\n",
    "base_resolution_3d = config.get('base_resolution_3d', LOW_RES)\n",
    "\n",
    "short_curve_quantile = config.get('short_curve_quantile', 0.05)\n",
    "\n",
    "nbhood_extractor = load_func_from_config(NBHOOD_BY_TYPE, config_points['neighbourhood'])\n",
    "sampler = load_func_from_config(SAMPLER_BY_TYPE, config_points['sampling'])\n",
    "annotator = load_func_from_config(ANNOTATOR_BY_TYPE, config_points['annotation'])\n",
    "\n",
    "# Specific to this script only: override radius of neighbourhood extractor\n",
    "# to reflect actual point cloud resolution:\n",
    "# we extract spheres of radius r, such that area of a (plane) disk with radius r\n",
    "# is equal to the total area of 3d points (as if we scanned a plane wall)\n",
    "nbhood_extractor.radius_base = np.sqrt(sampler.n_points) * 0.5 * sampler.resolution_3d / 1.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "\n",
    "class MplColorHelper:\n",
    "\n",
    "    def __init__(self, cmap_name, start_val, stop_val):\n",
    "        self.cmap_name = cmap_name\n",
    "        self.cmap = plt.get_cmap(cmap_name)\n",
    "        self.norm = mpl.colors.Normalize(vmin=start_val, vmax=stop_val)\n",
    "        self.scalarMap = cm.ScalarMappable(norm=self.norm, cmap=self.cmap)\n",
    "\n",
    "    def get_rgb(self, val):\n",
    "        return self.scalarMap.to_rgba(val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "np.random.seed(5371)\n",
    "nbhood_extractor.index(mesh)\n",
    "\n",
    "LARGEST_PROCESSABLE_MESH_VERTICES = 20000\n",
    "\n",
    "all_points, all_distances_points, all_patches_points, all_features_points = [], [], [], []\n",
    "for current_patch_idx in tqdm(range(len(nbhood_extractor.centroids_cache))):\n",
    "\n",
    "    # extract neighbourhood\n",
    "    try:\n",
    "        nbhood, mesh_vertex_indexes, mesh_face_indexes, scaler = nbhood_extractor.get_nbhood()\n",
    "        if len(nbhood.vertices) > LARGEST_PROCESSABLE_MESH_VERTICES:\n",
    "            raise DataGenerationException('Too large number of vertices in crop: {}'.format(len(nbhood.vertices)))\n",
    "    except DataGenerationException as e:\n",
    "        eprint_t(str(e))\n",
    "    centroid = nbhood_extractor.centroid\n",
    "\n",
    "    # sample the neighbourhood to form a point patch\n",
    "    try:\n",
    "        points, normals = sampler.sample(nbhood, centroid=None)\n",
    "    except Exception as e:\n",
    "        eprint(str(e))\n",
    "\n",
    "\n",
    "    # create annotations: condition the features onto the nbhood\n",
    "    nbhood_features = feature_utils.compute_features_nbhood(mesh, features, mesh_face_indexes, mesh_vertex_indexes=mesh_vertex_indexes)\n",
    "\n",
    "    # remove vertices lying on the boundary (sharp edges found in 1 face only)\n",
    "    nbhood_features = feature_utils.remove_boundary_features(nbhood, nbhood_features, how='edges')\n",
    "\n",
    "    try:\n",
    "        distances, directions, has_sharp = annotator.annotate(nbhood, nbhood_features, points)\n",
    "    except DataGenerationException as e:\n",
    "        eprint_t(str(e))\n",
    "\n",
    "    \n",
    "    all_points.append(points)\n",
    "    all_distances_points.append(distances)\n",
    "    all_patches_points.append(nbhood)\n",
    "    all_features_points.append(nbhood_features)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_meshes = []\n",
    "\n",
    "for points, distances in zip(all_points[4:5], all_distances_points[4:5]):\n",
    "\n",
    "    distances_to_camera = np.linalg.norm(pose.frame_origin - points, axis=1)\n",
    "    tol = 1e-3\n",
    "#     helper = MplColorHelper(\n",
    "#         'viridis',\n",
    "#         np.min(distances_to_camera) - tol,\n",
    "#         np.max(distances_to_camera) + tol)\n",
    "    helper = MplColorHelper(\n",
    "        'plasma_r',\n",
    "        - tol,\n",
    "        1. + tol)\n",
    "\n",
    "    iterable = zip(points, distances)\n",
    "    full_mesh = []\n",
    "    for point, distance in iterable:\n",
    "        rgba = helper.get_rgb(distance)\n",
    "        point_mesh = trimesh.creation.icosphere(\n",
    "            subdivisions=1,\n",
    "            radius=0.02,\n",
    "            color=rgba[:3])\n",
    "        point_mesh.vertices += point\n",
    "        full_mesh.append(point_mesh)\n",
    "\n",
    "    full_mesh = trimesh.util.concatenate(full_mesh)\n",
    "\n",
    "    full_meshes.append(full_mesh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_meshes = trimesh.util.concatenate(full_meshes)\n",
    "\n",
    "_ = trimesh.exchange.export.export_mesh(\n",
    "    full_meshes,\n",
    "    '/logs/figures_for_paper/2-data-pipeline-points-3-distances.obj',\n",
    "    'obj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, data_idx in enumerate([8, 15, 4]):\n",
    "    curve_segments = get_edges(all_patches_points[data_idx], all_features_points[data_idx])\n",
    "    trimesh.exchange.export.export_mesh(\n",
    "        all_patches_points[data_idx], \n",
    "        '/logs/figures_for_paper/2-data-pipeline-points-{}-mesh.obj'.format(idx + 1), \n",
    "        'obj')\n",
    "    export_features_to_obj(\n",
    "        '/logs/figures_for_paper/2-data-pipeline-points-{}-features.obj'.format(idx + 1), \n",
    "        curve_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = k3d.plot(grid_visible=False, height=1024)\n",
    "\n",
    "idx = 15\n",
    "points, distances = all_points[idx], all_distances_points[idx]\n",
    "\n",
    "d = np.linalg.norm(pose.frame_origin - points, axis=1)\n",
    "colors = k3d.helpers.map_colors(\n",
    "    d, \n",
    "    k3d.colormaps.matplotlib_color_maps.viridis, [np.min(d), np.max(d)]\n",
    ").astype(np.uint32)\n",
    "\n",
    "plot += k3d.points(\n",
    "    points, \n",
    "    colors=colors,\n",
    "    shader='flat',\n",
    "    point_size=0.02,)\n",
    "\n",
    "plot.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = k3d.plot(grid_visible=False, height=1024)\n",
    "for full_mesh in full_meshes:\n",
    "    plot += k3d.mesh(full_mesh.vertices, full_mesh.faces, color=0xbbbbbb, flat_shading=False)\n",
    "plot.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbhood, mesh_vertex_indexes, mesh_face_indexes = \\\n",
    "            feature_utils.submesh_from_hit_surfaces(mesh, features, mesh_face_indexes)\n",
    "\n",
    "# create annotations: condition the features onto the nbhood\n",
    "nbhood_features = feature_utils.compute_features_nbhood(\n",
    "    mesh, features, mesh_face_indexes, mesh_vertex_indexes=mesh_vertex_indexes,\n",
    "    deduce_verts_from_faces=False)\n",
    "\n",
    "# remove vertices lying on the boundary (sharp edges found in 1 face only)\n",
    "nbhood_features = feature_utils.remove_boundary_features(nbhood, nbhood_features, how='edges')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbhood_sharp_vert_indexes = np.concatenate(\n",
    "    [c['vert_indices'] for c in nbhood_features['curves'] if c['sharp']]\n",
    ")\n",
    "nbhood_sharp_vert = nbhood.vertices[nbhood_sharp_vert_indexes]\n",
    "\n",
    "\n",
    "display_sharpness(\n",
    "    nbhood, plot_meshvert=True, meshvert_psize=imaging.resolution_3d / 2,\n",
    "#     sharp_vert=camera_pose.camera_to_world(imaging.rays_origins), sharpvert_psize=0.5,\n",
    "    sharp_vert=nbhood_sharp_vert, sharpvert_psize=0.2,\n",
    "    samples=camera_pose.camera_to_world(imaging.image_to_points(image)), samples_psize=0.1,\n",
    "    directions=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_points = noiser.make_noise(\n",
    "    camera_pose.world_to_camera(points),\n",
    "    normals,\n",
    "    z_direction=np.array([0., 0., -1.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import igl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, point_face_indexes, _ = \\\n",
    "            igl.point_mesh_squared_distance(noisy_points, nbhood.vertices, nbhood.faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sharpf.utils.abc_utils.abc.feature_utils import get_adjacent_features_by_bfs_with_depth1, build_surface_patch_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacent_sharp_features, adjacent_surfaces = build_surface_patch_graph(nbhood, nbhood_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacent_sharp_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacent_surfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def get_adjacent_features_by_bfs_with_depth1(\n",
    "        surface_idx,\n",
    "        adjacent_sharp_features,\n",
    "        adjacent_surfaces,\n",
    "        always_check_adjacent_surfaces=False\n",
    "):\n",
    "    \"\"\"If adjacent sharp curves exist, return one of them.\n",
    "    If not, return ones adjacent to adjacent surfaces. \"\"\"\n",
    "\n",
    "    adjacent_sharp_indexes = deepcopy(adjacent_sharp_features[surface_idx])\n",
    "    if always_check_adjacent_surfaces or len(adjacent_sharp_indexes) == 0:\n",
    "\n",
    "        for adjacent_surface_idx in adjacent_surfaces[surface_idx]:\n",
    "            adjacent_surface_adjacent_sharp_features = \\\n",
    "                {adjacent_surface_idx: adjacent_sharp_features[adjacent_surface_idx]}\n",
    "\n",
    "            adjacent_surface_adjacent_sharp_indexes = \\\n",
    "                get_adjacent_features_by_bfs_with_depth1(\n",
    "                    adjacent_surface_idx, adjacent_surface_adjacent_sharp_features,\n",
    "                    defaultdict(list))\n",
    "\n",
    "            adjacent_sharp_indexes.extend(adjacent_surface_adjacent_sharp_indexes)\n",
    "\n",
    "    return adjacent_sharp_indexes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surface_idx = 2\n",
    "\n",
    "surface = nbhood_features['surfaces'][surface_idx]\n",
    "\n",
    "# constrain distance computation to certain sharp features only\n",
    "adjacent_sharp_indexes = get_adjacent_features_by_bfs_with_depth1(\n",
    "    surface_idx, adjacent_sharp_features, adjacent_surfaces, always_check_adjacent_surfaces=True)\n",
    "\n",
    "nbhood_sharp_vert_indexes = np.concatenate(\n",
    "    [nbhood_features['curves'][curve_idx]['vert_indices'] \n",
    "     for curve_idx in adjacent_sharp_indexes\n",
    "     if nbhood_features['curves'][curve_idx]['sharp']]\n",
    ")\n",
    "nbhood_sharp_vert = nbhood.vertices[nbhood_sharp_vert_indexes]\n",
    "\n",
    "\n",
    "nbhood_surface_verts = nbhood.vertices[surface['vert_indices']]\n",
    "\n",
    "\n",
    "\n",
    "display_sharpness(\n",
    "    nbhood, plot_meshvert=True, meshvert_psize=imaging.resolution_3d / 2,\n",
    "#     sharp_vert=camera_pose.camera_to_world(imaging.rays_origins), sharpvert_psize=0.5,\n",
    "    sharp_vert=nbhood_sharp_vert, sharpvert_psize=0.1,\n",
    "    samples=nbhood_surface_verts, samples_psize=0.1,\n",
    "    directions=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projections, distances, _ = self.flat_annotation(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the TSharpDF\n",
    "try:\n",
    "    distances, directions, has_sharp = annotator.annotate(\n",
    "        nbhood, nbhood_features, camera_pose.camera_to_world(noisy_points))\n",
    "except DataGenerationException as e:\n",
    "    eprint_t(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_sharpness(\n",
    "    nbhood, plot_meshvert=True, meshvert_psize=imaging.resolution_3d / 2,\n",
    "#     sharp_vert=camera_pose.camera_to_world(imaging.rays_origins), sharpvert_psize=0.5,\n",
    "    sharp_vert=nbhood_sharp_vert, sharpvert_psize=0.5,\n",
    "    samples=camera_pose.camera_to_world(noisy_points), samples_psize=0.1,\n",
    "    samples_distances=distances,\n",
    "    directions=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert everything to images\n",
    "ray_indexes = np.where(image.ravel() != 0)[0]\n",
    "noisy_image = imaging.points_to_image(noisy_points, ray_indexes)\n",
    "normals = imaging.points_to_image(normals, ray_indexes, assign_channels=[0, 1, 2])\n",
    "distances = imaging.points_to_image(distances.reshape(-1, 1), ray_indexes, assign_channels=[0])\n",
    "directions = imaging.points_to_image(directions, ray_indexes, assign_channels=[0, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_depth_sharpness(\n",
    "    depth_images=[camera_to_display(image)],\n",
    "    sharpness_images=[camera_to_display(distances)],\n",
    "    axes_size=(16, 16), \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smell_raycasting_background.run(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smell_depth_discontinuity._depth_discontinuity_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smell_depth_discontinuity.run(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smell_mesh_self_intersections.run(mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute statistics\n",
    "num_sharp_curves = len([curve for curve in nbhood_features['curves'] if curve['sharp']])\n",
    "num_surfaces = len(nbhood_features['surfaces'])\n",
    "\n",
    "patch_info = {\n",
    "    'image': noisy_image,\n",
    "    'normals': normals,\n",
    "    'distances': distances,\n",
    "    'directions': directions,\n",
    "    'item_id': item.item_id,\n",
    "    'orig_vert_indices': mesh_vertex_indexes,\n",
    "    'orig_face_indexes': mesh_face_indexes,\n",
    "    'has_sharp': has_sharp,\n",
    "    'num_sharp_curves': num_sharp_curves,\n",
    "    'num_surfaces': num_surfaces,\n",
    "    'camera_pose': camera_pose.camera_to_world_4x4,\n",
    "    'mesh_scale': mesh_scale\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_patches.append(patch_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_depth_maps(point_patches, '/logs/abc_0056_test.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls -lah /logs/abc_0056_test.hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
