{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "import k3d\n",
    "import yaml\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "import warnings\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OPENBLAS_NUM_THREADS'] = '10'\n",
    "os.environ['OMP_NUM_THREADS'] = '10'\n",
    "os.environ['MKL_NUM_THREADS'] = '10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_sharpness(mesh=None, plot_meshvert=True,\n",
    "                      samples=None, samples_distances=None,\n",
    "                      sharp_vert=None, sharp_curves=None,\n",
    "                      directions=None, directions_width=0.0025,\n",
    "                      samples_color=0x0000ff, samples_psize=0.002, \n",
    "                      mesh_color=0xbbbbbb, meshvert_color=0x666666, meshvert_psize=0.0025,\n",
    "                      sharpvert_color=0xff0000, sharpvert_psize=0.0025,\n",
    "                      sharpcurve_color=None, sharpcurve_width=0.0025,\n",
    "                      as_image=False, plot_height=768):\n",
    "    \n",
    "    plot = k3d.plot(height=plot_height)\n",
    "    \n",
    "    if None is not mesh:\n",
    "        k3d_mesh = k3d.mesh(mesh.vertices, mesh.faces, color=mesh_color)\n",
    "        plot += k3d_mesh\n",
    "\n",
    "        if plot_meshvert:\n",
    "            k3d_points = k3d.points(mesh.vertices, \n",
    "                                    point_size=meshvert_psize, color=meshvert_color)\n",
    "            plot += k3d_points\n",
    "            k3d_points.shader='flat'\n",
    "\n",
    "    if None is not samples:\n",
    "        colors = None\n",
    "        if None is not samples_distances:\n",
    "            max_dist = 0.5\n",
    "\n",
    "            colors = k3d.helpers.map_colors(\n",
    "                samples_distances, k3d.colormaps.matplotlib_color_maps.coolwarm_r, [0, max_dist]\n",
    "            ).astype(np.uint32)\n",
    "            k3d_points = k3d.points(samples, point_size=samples_psize, colors=colors)\n",
    "        else:\n",
    "            k3d_points = k3d.points(samples, point_size=samples_psize, color=samples_color)\n",
    "        plot += k3d_points\n",
    "        k3d_points.shader='flat'\n",
    "        \n",
    "        if None is not directions:\n",
    "            vectors = k3d.vectors(\n",
    "                samples,\n",
    "                directions * samples_distances[..., np.newaxis],\n",
    "                use_head=False, \n",
    "                line_width=directions_width)\n",
    "            print(vectors)\n",
    "            plot += vectors\n",
    "\n",
    "#             directions_to_plot = np.hstack((samples, samples + directions))\n",
    "            \n",
    "#             for i, dir_to_plot in enumerate(directions_to_plot):\n",
    "#                 dir_to_plot = dir_to_plot.reshape((2, 3))\n",
    "#                 if np.all(dir_to_plot[0] == dir_to_plot[1]):\n",
    "#                     continue\n",
    "#                 color = int(colors[i]) if None is not colors else samples_color\n",
    "#                 plt_line = k3d.line(dir_to_plot, \n",
    "#                                     shader='mesh', width=directions_width, color=color)\n",
    "#                 plot += plt_line\n",
    "\n",
    "    if None is not sharp_vert:\n",
    "        k3d_points = k3d.points(sharp_vert,\n",
    "                                point_size=sharpvert_psize, color=sharpvert_color)\n",
    "        plot += k3d_points\n",
    "        k3d_points.shader='flat'\n",
    "        \n",
    "        if None is not sharp_curves:            \n",
    "            if None is not sharpcurve_color:\n",
    "                color = sharpcurve_color\n",
    "            else:\n",
    "                import randomcolor\n",
    "                rand_color = randomcolor.RandomColor()\n",
    "            for i, vert_ind in enumerate(sharp_curves):\n",
    "                sharp_points_curve = mesh.vertices[vert_ind]\n",
    "                \n",
    "                if None is sharpcurve_color:\n",
    "                    color = rand_color.generate(hue='red')[0]\n",
    "                    color = int('0x' + color[1:], 16)\n",
    "                plt_line = k3d.line(sharp_points_curve, \n",
    "                                    shader='mesh', width=sharpcurve_width, color=color)\n",
    "                plot += plt_line\n",
    "        \n",
    "    plot.grid_visible = False\n",
    "    plot.display()\n",
    "    \n",
    "    if as_image:\n",
    "        plot.fetch_screenshot()\n",
    "        return Image(data=b64decode(plot.screenshot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mm/pixel\n",
    "HIGH_RES = 0.02\n",
    "MED_RES = 0.05\n",
    "LOW_RES = 0.125\n",
    "XLOW_RES = 0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Working with point patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sharpf.data import DataGenerationException\n",
    "from sharpf.utils.abc_utils.abc.abc_data import ABCModality, ABCChunk, ABC_7Z_FILEMASK\n",
    "from sharpf.data.annotation import ANNOTATOR_BY_TYPE\n",
    "from sharpf.data.datasets.sharpf_io import save_point_patches\n",
    "from sharpf.data.mesh_nbhoods import NBHOOD_BY_TYPE\n",
    "from sharpf.data.noisers import NOISE_BY_TYPE\n",
    "from sharpf.data.point_samplers import SAMPLER_BY_TYPE\n",
    "from sharpf.utils.abc_utils.abc.feature_utils import compute_features_nbhood, remove_boundary_features, get_curves_extents\n",
    "from sharpf.utils.py_utils.console import eprint_t\n",
    "from sharpf.utils.py_utils.os import add_suffix\n",
    "from sharpf.utils.py_utils.config import load_func_from_config\n",
    "from sharpf.utils.abc_utils.mesh.io import trimesh_load\n",
    "from sharpf.utils.geometry import mean_mmd\n",
    "import sharpf.data.data_smells as smells\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ABCChunk(['/data/abc/abc_0050_obj_v00.7z', '/data/abc/abc_0050_feat_v00.7z']) as data_holder:\n",
    "    item = data_holder.get('00502539_6e851dae74079e807f2dbcf4_012')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'00502539_6e851dae74079e807f2dbcf4_012'"
      ]
     },
     "execution_count": 575,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item.item_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mesh, vertex_normals, vertex_normal_indices = trimesh_load(item.obj)\n",
    "mesh, _, _ = trimesh_load(item.obj)\n",
    "\n",
    "features = yaml.load(item.feat, Loader=yaml.Loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh2 = mesh.copy()\n",
    "mesh2._validate = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<trimesh.Trimesh(vertices.shape=(21382, 3), faces.shape=(42764, 3))>"
      ]
     },
     "execution_count": 578,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mesh2.process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<trimesh.Trimesh(vertices.shape=(21382, 3), faces.shape=(42764, 3))>"
      ]
     },
     "execution_count": 579,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 580,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mesh.is_watertight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 True\n",
      "1 False\n",
      "2 True\n",
      "3 True\n",
      "4 True\n",
      "5 True\n",
      "6 True\n",
      "7 True\n",
      "8 True\n",
      "9 True\n",
      "10 True\n",
      "11 True\n",
      "12 True\n",
      "13 True\n",
      "14 True\n",
      "15 True\n",
      "16 True\n",
      "17 True\n",
      "18 True\n",
      "19 True\n",
      "20 True\n",
      "21 True\n",
      "22 True\n",
      "23 True\n",
      "24 True\n",
      "25 True\n",
      "26 True\n",
      "27 True\n",
      "28 True\n",
      "29 True\n",
      "30 True\n",
      "31 True\n",
      "32 False\n",
      "33 False\n",
      "34 False\n",
      "35 False\n",
      "36 False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniconda/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:3: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(features['surfaces'])):\n",
    "    print(i, np.array(np.unique(mesh.faces[features['surfaces'][i]['face_indices']]) == \n",
    "                      np.sort(features['surfaces'][i]['vert_indices'])).all()\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'shape_fabrication_extent': 10.0,\n",
       " 'short_curve_quantile': 0.25,\n",
       " 'base_n_points_per_short_curve': 8,\n",
       " 'base_resolution_3d': 0.125,\n",
       " 'neighbourhood': {'type': 'random_euclidean_sphere',\n",
       "  'max_patches_per_mesh': 10000,\n",
       "  'n_vertices': None,\n",
       "  'centroid': None,\n",
       "  'centroid_mode': 'poisson_disk',\n",
       "  'radius_base': 10.0,\n",
       "  'radius_delta': 0.0,\n",
       "  'geodesic_patches': True,\n",
       "  'radius_scale_mode': 'no_scale'},\n",
       " 'sampling': {'type': 'poisson_disk',\n",
       "  'n_points': 4096,\n",
       "  'resolution_3d': 0.02,\n",
       "  'make_n_points': 'crop_center'},\n",
       " 'noise': {'type': 'many_noisers',\n",
       "  'subtype': 'isotropic_gaussian',\n",
       "  'scale': [0.0]},\n",
       " 'annotation': {'type': 'surface_based_aabb', 'distance_upper_bound': 1.0},\n",
       " 'smell_coarse_surfaces_by_num_edges': {'num_edges_threshold': 8},\n",
       " 'smell_coarse_surfaces_by_angles': {'max_angle_threshold_degrees': 10.0},\n",
       " 'smell_deviating_resolution': {'resolution_3d': 0.02,\n",
       "  'resolution_deviation_tolerance': 0.01},\n",
       " 'smell_sharpness_discontinuities': {},\n",
       " 'smell_bad_face_sampling': {'min_points_per_face': 0.02,\n",
       "  'max_points_per_face': 20.0}}"
      ]
     },
     "execution_count": 582,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('/code/scripts/data_scripts/configs/pointcloud_datasets/dataset_config_high_res_clean.json') as config_file:\n",
    "    config = json.load(config_file)\n",
    "\n",
    "config['neighbourhood']['max_patches_per_mesh'] = 10000\n",
    "# config['sampling']['resolution_3d'] = 0.05\n",
    "# config['smell_deviating_resolution'] = {\n",
    "#     'resolution_3d': 0.05,\n",
    "#     'resolution_deviation_tolerance': 0.05 / 2\n",
    "# }\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape_fabrication_extent = config.get('shape_fabrication_extent', 10.0)\n",
    "# base_n_points_per_short_curve = config.get('base_n_points_per_short_curve', 8)\n",
    "# base_resolution_3d = config.get('base_resolution_3d', LOW_RES)\n",
    "# short_curve_quantile = config.get('short_curve_quantile', 0.05)\n",
    "shape_fabrication_extent = config.get('shape_fabrication_extent', 10.0)\n",
    "base_n_points_per_short_curve = 8\n",
    "base_resolution_3d = 0.15\n",
    "short_curve_quantile = 0.25\n",
    "\n",
    "nbhood_extractor = load_func_from_config(NBHOOD_BY_TYPE, config['neighbourhood'])\n",
    "sampler = load_func_from_config(SAMPLER_BY_TYPE, config['sampling'])\n",
    "noiser = load_func_from_config(NOISE_BY_TYPE, config['noise'])\n",
    "annotator = load_func_from_config(ANNOTATOR_BY_TYPE, config['annotation'])\n",
    "\n",
    "\n",
    "smell_coarse_surfaces_by_num_edges = smells.SmellCoarseSurfacesByNumEdges.from_config(config['smell_coarse_surfaces_by_num_edges'])\n",
    "smell_coarse_surfaces_by_angles = smells.SmellCoarseSurfacesByAngles.from_config(config['smell_coarse_surfaces_by_angles'])\n",
    "smell_deviating_resolution = smells.SmellDeviatingResolution.from_config(config['smell_deviating_resolution'])\n",
    "smell_sharpness_discontinuities = smells.SmellSharpnessDiscontinuities.from_config(config['smell_sharpness_discontinuities'])\n",
    "smell_bad_face_sampling = smells.SmellBadFaceSampling.from_config(config['smell_bad_face_sampling'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def scale_mesh(mesh, features, shape_fabrication_extent, resolution_3d,\n",
    "               short_curve_quantile=0.05, n_points_per_short_curve=4):\n",
    "    # compute standard size spatial extent\n",
    "    mesh_extent = np.max(mesh.bounding_box.extents)\n",
    "    mesh = mesh.apply_scale(shape_fabrication_extent / mesh_extent)\n",
    "\n",
    "    # compute lengths of curves\n",
    "    sharp_curves_lengths = get_curves_extents(mesh, features)\n",
    "\n",
    "    least_len = np.quantile(sharp_curves_lengths, short_curve_quantile)\n",
    "    least_len_mm = resolution_3d * n_points_per_short_curve\n",
    "\n",
    "    mesh = mesh.apply_scale(least_len_mm / least_len)\n",
    "\n",
    "    return mesh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mesh = scale_mesh(mesh, features, shape_fabrication_extent, base_resolution_3d,\n",
    "                      short_curve_quantile=short_curve_quantile,\n",
    "                      n_points_per_short_curve=base_n_points_per_short_curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.79999976480001"
      ]
     },
     "execution_count": 586,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(mesh.bounding_box.extents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_range = np.array([1000, 600, 300])\n",
    "resolutions_3d = np.array([0.25, 0.15, 0.06])\n",
    "std_3d = np.array([0.12, 0.06, 0.04])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_wr_r3d = 0.5 * (working_range[1] - working_range[0]) / (resolutions_3d[1] - resolutions_3d[0]) + \\\n",
    "0.5 * (working_range[2] - working_range[1]) / (resolutions_3d[2] - resolutions_3d[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_wr_e3d = 0.5 * (working_range[1] - working_range[0]) / (std_3d[1] - std_3d[0]) + \\\n",
    "    0.5 * (working_range[2] - working_range[1]) / (std_3d[2] - std_3d[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_resolution_3d = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh = scale_mesh(mesh, features, shape_fabrication_extent, target_resolution_3d,\n",
    "                      short_curve_quantile=short_curve_quantile,\n",
    "                      n_points_per_short_curve=base_n_points_per_short_curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111.99999843200006"
      ]
     },
     "execution_count": 592,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(mesh.bounding_box.extents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trimesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [],
   "source": [
    "stl_mesh = trimesh.exchange.export.export_stl(mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '{item_id}__{size:3.1f}mm.stl'.format(\n",
    "    item_id=item.item_id,\n",
    "    size=np.max(mesh.bounding_box.extents))\n",
    "with open(filename, 'wb') as f:\n",
    "    f.write(stl_mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smells.SmellMeshSelfIntersections().run(mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d9b21161189454ab7ffc41ee57dd2ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# surf_vert_indices = np.array(features['surfaces'][0]['vert_indices'])\n",
    "# surf_verts = mesh.vertices[surf_vert_indices]\n",
    "# surf_vert_indices2 = np.array(features['surfaces'][0]['vert_indices'])\n",
    "# surf_verts2 = mesh.vertices[surf_vert_indices]\n",
    "\n",
    "\n",
    "\n",
    "display_sharpness(\n",
    "    mesh, plot_meshvert=True, meshvert_psize=sampler.resolution_3d,\n",
    "    sharp_vert=None, \n",
    "    sharpvert_psize=1. * sampler.resolution_3d,\n",
    "#     sharp_vert=mesh.vertices[boundary_curves[1]['vert_indices']],\n",
    "    samples=None, samples_psize=1. * sampler.resolution_3d,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having surface area $S$, sampling resolution $r$ (= mean distance between points), and considering each point as occupying a surface $\\pi r^2 / 4$, we have the number of points as:\n",
    "$$\n",
    "n = S / \\frac {\\pi r^2} {4}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.062002725243821, 6564)"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_points = np.ceil(mesh.area / (np.pi * 0.02 ** 2 / 4)).astype(int)\n",
    "mesh.area, n_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import igl\n",
    "import trimesh\n",
    "\n",
    "def _make_dense_mesh(mesh, n_desired_points, extra_points_factor=10, point_split_factor=4):\n",
    "    # Intuition: take 10x the number of needed n_points,\n",
    "    # keep in mind that each call to `igl.upsample` generates 4x the points,\n",
    "    # then compute the upsampling factor K from the relation:\n",
    "    # 4^K n = 10 n_points\n",
    "    upsampling_factor = np.ceil(\n",
    "        np.log(n_desired_points * extra_points_factor / len(mesh.vertices)) /\n",
    "        np.log(point_split_factor)\n",
    "    ).astype(int)\n",
    "\n",
    "    # Generate very dense subdivision samples on the mesh (v, f, n)\n",
    "    # for _ in range(upsampling_factor):\n",
    "    #     mesh = mesh.subdivide()\n",
    "    dense_points, dense_faces = igl.upsample(mesh.vertices, mesh.faces, upsampling_factor)\n",
    "\n",
    "    # compute vertex normals by pushing to trimesh\n",
    "    dense_mesh = trimesh.base.Trimesh(vertices=dense_points, faces=dense_faces, process=False, validate=False)\n",
    "    return dense_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import point_cloud_utils as pcu\n",
    "\n",
    "dense_mesh = _make_dense_mesh(\n",
    "    mesh,\n",
    "    n_desired_points=n_points,\n",
    "    extra_points_factor=10,\n",
    "    point_split_factor=4\n",
    ")\n",
    "\n",
    "dense_points = np.array(dense_mesh.vertices, order='C')\n",
    "dense_normals = np.array(dense_mesh.vertex_normals, order='C')\n",
    "dense_faces = np.array(dense_mesh.faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample v_dense to be from a blue noise distribution:\n",
    "#\n",
    "# `points` is a downsampled version of `dense_points` where points are separated by approximately\n",
    "# `radius` distance, use_geodesic_distance indicates that the distance should be measured on the mesh.\n",
    "#\n",
    "# `normals` are the corresponding normals of `points`\n",
    "\n",
    "# require a little bit extra points as PDS get you sometimes fewer than requested\n",
    "required_points = int(1.1 * n_points)\n",
    "points, normals = pcu.sample_mesh_poisson_disk(\n",
    "    dense_points, dense_faces, dense_normals,\n",
    "    required_points, radius=sampler.resolution_3d, use_geodesic_distance=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_sharpness(\n",
    "    mesh, plot_meshvert=False, meshvert_psize=sampler.resolution_3d,\n",
    "    sharp_vert=None, \n",
    "    sharpvert_psize=1. * sampler.resolution_3d,\n",
    "#     sharp_vert=mesh.vertices[boundary_curves[1]['vert_indices']],\n",
    "    samples=points, samples_psize=1. * sampler.resolution_3d,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model_resolution_discount = 4.0\n",
    "nbhood_extractor.radius_base = np.sqrt(sampler.n_points) * 0.5 * sampler.resolution_3d / full_model_resolution_discount\n",
    "\n",
    "nbhood_extractor.index(mesh)\n",
    "\n",
    "full_model_resolution_discount = 1.0\n",
    "nbhood_extractor.radius_base = np.sqrt(sampler.n_points) * 0.5 * sampler.resolution_3d / full_model_resolution_discount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "347"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nbhood_extractor.centroids_cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniconda/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:3: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "has_smell_mismatching_surface_annotation = any([\n",
    "    np.array(np.unique(mesh.faces[surface['face_indices']]) != np.sort(surface['vert_indices'])).all()\n",
    "    for surface in features['surfaces']\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "LARGEST_PROCESSABLE_MESH_VERTICES = 20000\n",
    "\n",
    "nbhood_extractor.current_patch_idx = 0\n",
    "\n",
    "# extract neighbourhood\n",
    "try:\n",
    "    nbhood, mesh_vertex_indexes, mesh_face_indexes, scaler = nbhood_extractor.get_nbhood()\n",
    "    if len(nbhood.vertices) > LARGEST_PROCESSABLE_MESH_VERTICES:\n",
    "        raise DataGenerationException('Too large number of vertices in crop: {}'.format(len(nbhood.vertices)))\n",
    "except DataGenerationException as e:\n",
    "    eprint_t(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3996a945e39a467a98c515cdb4c958e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_sharpness(\n",
    "    nbhood, plot_meshvert=False, meshvert_psize=sampler.resolution_3d,\n",
    "    sharp_vert=None, \n",
    "    sharpvert_psize=1. * sampler.resolution_3d,\n",
    "#     sharp_vert=mesh.vertices[boundary_curves[1]['vert_indices']],\n",
    "#     samples=points, samples_psize=1. * sampler.resolution_3d,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroid = nbhood_extractor.centroid\n",
    "\n",
    "has_smell_coarse_surfaces_by_num_edges = smell_coarse_surfaces_by_num_edges.run(mesh, mesh_face_indexes, features)\n",
    "has_smell_coarse_surfaces_by_angles = smell_coarse_surfaces_by_angles.run(mesh, mesh_face_indexes, features)\n",
    "\n",
    "# create annotations: condition the features onto the nbhood\n",
    "nbhood_features = compute_features_nbhood(mesh, features, mesh_face_indexes,\n",
    "                                          mesh_vertex_indexes=mesh_vertex_indexes)\n",
    "\n",
    "# remove vertices lying on the boundary (sharp edges found in 1 face only)\n",
    "nbhood_features = remove_boundary_features(nbhood, nbhood_features, how='edges')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import cKDTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = cKDTree(points, leafsize=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, indexes = tree.query(centroid, k=4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_points, patch_normals = points[indexes], normals[indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniconda/envs/py36/lib/python3.6/site-packages/traittypes/traittypes.py:101: UserWarning: Given trait value dtype \"float64\" does not match required type \"float32\". A coerced copy has been created.\n",
      "  np.dtype(self.dtype).name))\n",
      "/home/user/miniconda/envs/py36/lib/python3.6/site-packages/traittypes/traittypes.py:101: UserWarning: Given trait value dtype \"int64\" does not match required type \"uint32\". A coerced copy has been created.\n",
      "  np.dtype(self.dtype).name))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f357bde928db4efabbc5c977aca65eeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_sharpness(\n",
    "    nbhood, plot_meshvert=False, meshvert_psize=sampler.resolution_3d,\n",
    "    sharp_vert=None, \n",
    "    sharpvert_psize=1. * sampler.resolution_3d,\n",
    "#     sharp_vert=mesh.vertices[boundary_curves[1]['vert_indices']],\n",
    "    samples=patch_points, samples_psize=1. * sampler.resolution_3d,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LARGEST_PROCESSABLE_MESH_VERTICES = 20000\n",
    "\n",
    "\n",
    "def compute_patches(patch_idx, mesh, features,\n",
    "                    nbhood_extractor, sampler, noiser,\n",
    "                    smell_coarse_surfaces_by_num_edges,\n",
    "                    smell_coarse_surfaces_by_angles,\n",
    "                    smell_deviating_resolution,\n",
    "                    smell_bad_face_sampling):\n",
    "    \n",
    "    global LARGEST_PROCESSABLE_MESH_VERTICES\n",
    "\n",
    "    patches_by_config = defaultdict(list)\n",
    "\n",
    "    nbhood_extractor.current_patch_idx = patch_idx\n",
    "\n",
    "    # extract neighbourhood\n",
    "    try:\n",
    "        nbhood, mesh_vertex_indexes, mesh_face_indexes, scaler = nbhood_extractor.get_nbhood()\n",
    "        if len(nbhood.vertices) > LARGEST_PROCESSABLE_MESH_VERTICES:\n",
    "            raise DataGenerationException('Too large number of vertices in crop: {}'.format(len(nbhood.vertices)))\n",
    "    except DataGenerationException as e:\n",
    "        eprint_t(str(e))\n",
    "        return None\n",
    "    centroid = nbhood_extractor.centroid\n",
    "\n",
    "    has_smell_coarse_surfaces_by_num_edges = smell_coarse_surfaces_by_num_edges.run(mesh, mesh_face_indexes, features)\n",
    "    has_smell_coarse_surfaces_by_angles = smell_coarse_surfaces_by_angles.run(mesh, mesh_face_indexes, features)\n",
    "\n",
    "    # create annotations: condition the features onto the nbhood\n",
    "    nbhood_features = compute_features_nbhood(mesh, features, mesh_face_indexes,\n",
    "                                              mesh_vertex_indexes=mesh_vertex_indexes)\n",
    "\n",
    "    # remove vertices lying on the boundary (sharp edges found in 1 face only)\n",
    "    nbhood_features = remove_boundary_features(nbhood, nbhood_features, how='edges')\n",
    "\n",
    "    # sample the neighbourhood to form a point patch\n",
    "    try:\n",
    "        points, normals = sampler.sample(nbhood, centroid=nbhood_extractor.centroid)\n",
    "    except DataGenerationException as e:\n",
    "        eprint_t(str(e))\n",
    "        return None\n",
    "\n",
    "    has_smell_deviating_resolution = smell_deviating_resolution.run(points)\n",
    "    has_smell_bad_face_sampling = smell_bad_face_sampling.run(nbhood, points)\n",
    "\n",
    "    # create a noisy sample\n",
    "    for configuration, noisy_points in noiser.make_noise(points, normals):\n",
    "        num_sharp_curves = len([curve for curve in nbhood_features['curves'] if curve['sharp']])\n",
    "        num_surfaces = len(nbhood_features['surfaces'])\n",
    "        patch_info = {\n",
    "            'points': np.array(noisy_points).astype(np.float64),\n",
    "            'normals': np.array(normals).astype(np.float64),\n",
    "            # 'distances': np.array(distances).astype(np.float64),\n",
    "            # 'directions': np.array(directions).astype(np.float64),\n",
    "#             'item_id': item_id,\n",
    "            'orig_vert_indices': np.array(mesh_vertex_indexes).astype(np.int32),\n",
    "            'orig_face_indexes': np.array(mesh_face_indexes).astype(np.int32),\n",
    "            # 'has_sharp': has_sharp,\n",
    "            'num_sharp_curves': num_sharp_curves,\n",
    "            'num_surfaces': num_surfaces,\n",
    "            'has_smell_coarse_surfaces_by_num_faces': has_smell_coarse_surfaces_by_num_edges,\n",
    "            'has_smell_coarse_surfaces_by_angles': has_smell_coarse_surfaces_by_angles,\n",
    "            'has_smell_deviating_resolution': has_smell_deviating_resolution,\n",
    "            # 'has_smell_sharpness_discontinuities': has_smell_sharpness_discontinuities,\n",
    "            'has_smell_bad_face_sampling': has_smell_bad_face_sampling,\n",
    "            # 'has_smell_mismatching_surface_annotation': has_smell_mismatching_surface_annotation,\n",
    "            'nbhood': nbhood,\n",
    "            'nbhood_features': nbhood_features,\n",
    "            'centroid': centroid,\n",
    "            'nbhood_radius': nbhood_extractor.radius_base,\n",
    "        }\n",
    "        config_name = configuration.get('name')\n",
    "        patches_by_config[config_name].append(patch_info)\n",
    "\n",
    "    return patches_by_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "parallel = Parallel(n_jobs=36, backend='multiprocessing', verbose=100)\n",
    "delayed_iterable = (delayed(compute_patches)(\n",
    "        patch_idx, mesh, features,\n",
    "        nbhood_extractor, sampler, noiser,\n",
    "        smell_coarse_surfaces_by_num_edges,\n",
    "        smell_coarse_surfaces_by_angles,\n",
    "        smell_deviating_resolution,\n",
    "        smell_bad_face_sampling)\n",
    "        for patch_idx in range(nbhood_extractor.n_patches_per_mesh))\n",
    "result = parallel(delayed_iterable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patches_by_config = defaultdict(list)\n",
    "\n",
    "for r in result:\n",
    "    for config_name, patch_infos in r.items():\n",
    "        for info in patch_infos:\n",
    "            info.update({\n",
    "                'item_id': item.item_id,\n",
    "                'has_smell_mismatching_surface_annotation': has_smell_mismatching_surface_annotation,\n",
    "            })\n",
    "        patches_by_config[config_name].extend(patch_infos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patches = patches_by_config[0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_model_points = np.concatenate([\n",
    "    patch['points']\n",
    "    for patch in patches\n",
    "])\n",
    "whole_model_points.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_model_points_norm_sq = np.linalg.norm(whole_model_points, axis=1) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 14\n",
    "centroid = patches[idx]['centroid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time distance_to_centroid = np.sqrt(np.square(whole_model_points - centroid).sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "distance_to_centroid2 = np.sqrt(\n",
    "    (whole_model_points_norm_sq \n",
    "     - 2 * np.dot(whole_model_points, centroid) \n",
    "     + np.linalg.norm(centroid) ** 2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time indexes = np.where(distance_to_centroid < nbhood_extractor.radius_base)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in tqdm(range(len(patches))):\n",
    "    centroid = patches[idx]['centroid']\n",
    "    distance_to_centroid = np.sqrt(\n",
    "        whole_model_points_norm_sq \n",
    "         - 2 * np.dot(whole_model_points, centroid) \n",
    "         + np.linalg.norm(centroid) ** 2\n",
    "    )\n",
    "    indexes = np.where(distance_to_centroid < nbhood_extractor.radius_base)[0]\n",
    "    noisy_points = whole_model_points[indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_annotation_nonlocal(patch, whole_model_points, config):\n",
    "    annotator = load_func_from_config(ANNOTATOR_BY_TYPE, config['annotation'])\n",
    "    smell_sharpness_discontinuities = smells.SmellSharpnessDiscontinuities.from_config(\n",
    "        config['smell_sharpness_discontinuities'])\n",
    "\n",
    "    whole_model_points_norm_sq = np.linalg.norm(whole_model_points, axis=1) ** 2\n",
    "    centroid = patch['centroid']\n",
    "    distance_to_centroid = np.sqrt(\n",
    "        whole_model_points_norm_sq \n",
    "         - 2 * np.dot(whole_model_points, centroid) \n",
    "         + np.linalg.norm(centroid) ** 2\n",
    "    )\n",
    "    indexes = np.where(distance_to_centroid < nbhood_extractor.radius_base)[0]\n",
    "    noisy_points = whole_model_points[indexes]    \n",
    "    \n",
    "    nbhood = patch['nbhood']\n",
    "    nbhood_features = patch['nbhood_features']\n",
    "    \n",
    "    try:\n",
    "        distances, directions, has_sharp = annotator.annotate(nbhood, nbhood_features, noisy_points)\n",
    "    except DataGenerationException as e:\n",
    "        eprint_t(str(e))\n",
    "        return [None] * 5\n",
    "    has_smell_sharpness_discontinuities = smell_sharpness_discontinuities.run(noisy_points, distances)\n",
    "\n",
    "    return distances, directions, has_sharp, indexes, has_smell_sharpness_discontinuities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "parallel = Parallel(n_jobs=20, backend='multiprocessing', verbose=100)\n",
    "delayed_iterable = (delayed(compute_annotation_nonlocal)(patch, whole_model_points, config) for patch in patches)\n",
    "result = parallel(delayed_iterable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_model_distances = np.ones(len(whole_model_points)) * np.inf\n",
    "whole_model_directions = np.ones( (len(whole_model_points), 3) ) * np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (distances, directions, has_sharp, indexes, has_smell_sharpness_discontinuities) in tqdm(enumerate(result)):\n",
    "    assign_mask = whole_model_distances[indexes] > distances\n",
    "    whole_model_distances[indexes[assign_mask]] = distances[assign_mask]\n",
    "    whole_model_directions[indexes[assign_mask]] = directions[assign_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_sharpness(None, plot_meshvert=False, meshvert_psize=0.01,\n",
    "                  sharp_vert=None, sharpvert_psize=2 * sampler.resolution_3d,\n",
    "                  samples=whole_model_points, samples_distances=whole_model_distances,\n",
    "                  samples_color=0x0000ff, samples_psize=sampler.resolution_3d,\n",
    "                  directions=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_idx = whole_model_distances.argmin(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_patches = []\n",
    "\n",
    "for i, (patch, relabeled) in tqdm(enumerate(zip(patches, result))):\n",
    "    distances, directions, has_sharp, indexes, has_smell_sharpness_discontinuities = relabeled\n",
    "    \n",
    "    whole_patch = deepcopy(patch)\n",
    "    i1, i2 = i * sampler.n_points, (i + 1) * sampler.n_points\n",
    "    whole_patch['distances'] = whole_model_distances[i1:i2]\n",
    "    whole_patch['directions'] = whole_model_directions[i1:i2, :]\n",
    "    nbhood_features = patch['nbhood_features']\n",
    "    whole_patch['has_sharp'] = any(curve['sharp'] for curve in nbhood_features['curves'])\n",
    "    whole_patch['num_sharp_curves'] = len([curve for curve in nbhood_features['curves'] if curve['sharp']])\n",
    "    whole_patch['num_surfaces'] = len(nbhood_features['surfaces'])\n",
    "    whole_patch['has_smell_mismatching_surface_annotation'] = False\n",
    "    whole_patch['has_smell_sharpness_discontinuities'] = has_smell_sharpness_discontinuities\n",
    "    whole_patches.append(whole_patch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.randint(len(patches))\n",
    "\n",
    "patch = whole_patches[idx]\n",
    "\n",
    "display_sharpness(None, plot_meshvert=False, meshvert_psize=0.01,\n",
    "                  sharp_vert=None, sharpvert_psize=2 * sampler.resolution_3d,\n",
    "                  samples=patch['points'], samples_distances=patch['distances'],\n",
    "                  samples_color=0x0000ff, samples_psize=sampler.resolution_3d,\n",
    "                  directions=patch['directions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sharpf.data.datasets.sharpf_io import save_point_patches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_point_patches(whole_patches, '/logs/whole_{}.hdf5'.format(item.item_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sharpf.utils.abc_utils.hdf5.dataset import Hdf5File, PreloadTypes\n",
    "import sharpf.utils.abc_utils.hdf5.io_struct as io\n",
    "from sharpf.data.datasets.sharpf_io import PointCloudIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "PointCloudIO = io.HDF5IO({\n",
    "    'points': io.Float64('points'),\n",
    "    'normals': io.Float64('normals'),\n",
    "    'distances': io.Float64('distances'),\n",
    "    'directions': io.Float64('directions'),\n",
    "    'item_id': io.AsciiString('item_id'),\n",
    "    'orig_vert_indices': io.VarInt32('orig_vert_indices'),\n",
    "    'orig_face_indexes': io.VarInt32('orig_face_indexes'),\n",
    "    'has_sharp': io.Bool('has_sharp'),\n",
    "    'num_sharp_curves': io.Int8('num_sharp_curves'),\n",
    "    'num_surfaces': io.Int8('num_surfaces'),\n",
    "    'has_smell_coarse_surfaces_by_num_faces': io.Bool('has_smell_coarse_surfaces_by_num_faces'),\n",
    "    'has_smell_coarse_surfaces_by_angles': io.Bool('has_smell_coarse_surfaces_by_angles'),\n",
    "    'has_smell_deviating_resolution': io.Bool('has_smell_deviating_resolution'),\n",
    "    'has_smell_sharpness_discontinuities': io.Bool('has_smell_sharpness_discontinuities'),\n",
    "    'has_smell_bad_face_sampling': io.Bool('has_smell_bad_face_sampling'),\n",
    "    'has_smell_mismatching_surface_annotation': io.Bool('has_smell_mismatching_surface_annotation'),\n",
    "# 'voronoi': io.Float64('voronoi'),\n",
    "# 'normals_estimation_10': io.Float64('normals_estimation_10'),\n",
    "# 'normals_estimation_100': io.Float64('normals_estimation_100'),\n",
    "\n",
    "},\n",
    "len_label='has_sharp',\n",
    "compression='lzf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Hdf5File('/logs/abc_0000_00007710_5e85263979fb44d18725b575_008.hdf5',\n",
    "                   io=PointCloudIO,\n",
    "                   preload=PreloadTypes.LAZY,\n",
    "                   labels='*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3067904, 3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whole_model_points = np.concatenate([\n",
    "    patch['points']\n",
    "    for patch in dataset\n",
    "])\n",
    "whole_model_points.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3067904, 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whole_model_directions = np.concatenate([\n",
    "    patch['directions']\n",
    "    for patch in dataset\n",
    "])\n",
    "whole_model_directions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3067904,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whole_model_distances = np.concatenate([\n",
    "    patch['distances']\n",
    "    for patch in dataset\n",
    "])\n",
    "whole_model_distances.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45e16f8962044570bde661390b4f4188",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_sharpness(None, plot_meshvert=False, meshvert_psize=0.01,\n",
    "                  sharp_vert=None, sharpvert_psize=0.02,\n",
    "                  samples=whole_model_points, samples_distances=whole_model_distances,\n",
    "                  samples_color=0x0000ff, samples_psize=0.02,\n",
    "                  directions=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
