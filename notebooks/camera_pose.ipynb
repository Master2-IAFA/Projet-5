{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trimesh.transformations as tt\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_to_world_origin(camera_origin):\n",
    "    # construct a 3x3 rotation matrix to a coordinate frame where:\n",
    "    # Z axis points to world origin aka center of a mesh\n",
    "    # Y axis points down\n",
    "    # X axis is computed as Y cross Z\n",
    "    \n",
    "    camera_origin = np.asanyarray(camera_origin)\n",
    "\n",
    "    e_z = -camera_origin / np.linalg.norm(camera_origin)  # Z axis points to world origin aka center of a mesh\n",
    "    e_y = np.array([0, 0, -1])  # proxy to Y axis pointing directly down\n",
    "                                # note that real e_y must be \n",
    "                                # 1) orthogonal to e_z;\n",
    "                                # 2) lie in the plane spanned by e_y and e_z;\n",
    "                                # 3) point downwards so <e_y, [0, 0, -1]> >= <e_y, [0, 0, +1]>\n",
    "                                # 4) unit norm\n",
    "    gamma = np.dot(e_y, e_z)\n",
    "    e_y = -gamma / (1 + gamma**2) * e_z + 1. / (1 + gamma**2) * e_y\n",
    "    if np.dot(e_y, [0, 0, -1]) < np.dot(e_y, [0, 0, 1]):\n",
    "        e_y *= -1\n",
    "    e_y /= np.linalg.norm(e_y)\n",
    "    e_x = np.cross(e_y, e_z)  # X axis \n",
    "    R = np.array([e_x, e_y, e_z])\n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CameraPose:\n",
    "    def __init__(self, transform):\n",
    "        self._camera_to_world_4x4 = transform\n",
    "        # always store transform from world to camera frame\n",
    "        self._world_to_camera_4x4 = np.linalg.inv(self._camera_to_world_4x4)  \n",
    "\n",
    "    @classmethod\n",
    "    def from_camera_to_world(cls, rotation=None, translation=None):\n",
    "        \"\"\"Create camera pose from camera to world transform.\n",
    "        \n",
    "        :param rotation: 3x3 rotation matrix of camera frame axes in world frame\n",
    "        :param translation: 3d location of camera frame origin in world frame\n",
    "        \"\"\"\n",
    "        rotation = np.identity(3) if None is rotation else np.asanyarray(rotation)\n",
    "        translation = np.zeros(3) if None is translation else np.asanyarray(translation)\n",
    "\n",
    "        transform = np.identity(4)\n",
    "        transform[:3, :3] = rotation\n",
    "        transform[:3, 3] = translation\n",
    "\n",
    "        return cls(transform)\n",
    "    \n",
    "    @classmethod\n",
    "    def from_camera_axes(cls, R=None, t=None):\n",
    "        \"\"\"Compute 4x4 camera pose from camera axes given in world frame.\n",
    "        \n",
    "        :param R: a list of 3D basis vectors (cx, cy, cz) defined in world frame\n",
    "        :param translation: 3D vector defining location of camera origin in world frame\n",
    "        \"\"\"\n",
    "        if None is R:\n",
    "            R = np.identity(3)\n",
    "        \n",
    "        return cls.from_camera_to_world(rotation=R.T, translation=t)\n",
    "    \n",
    "    def world_to_camera(self, points):\n",
    "        \"\"\"Transform points from world to camera coordinates.\n",
    "        Useful for understanding where the objects are, as seen by the camera.\n",
    "        \n",
    "        :param points: either n * 3 array, or a single 3-vector\n",
    "        \"\"\"\n",
    "        points = np.atleast_2d(points)\n",
    "        return tt.transform_points(points, self._world_to_camera_4x4)\n",
    "    \n",
    "    def camera_to_world(self, points, translate=True):\n",
    "        \"\"\"Transform points from camera to world coordinates.\n",
    "        Useful for understanding where objects bound to camera \n",
    "        (e.g., image pixels) are in the world.\n",
    "        \n",
    "        :param points: either n * 3 array, or a single 3-vector\n",
    "        \"\"\"\n",
    "        points = np.atleast_2d(points)\n",
    "        return tt.transform_points(points, self._camera_to_world_4x4, translate=translate)\n",
    "    \n",
    "    @property\n",
    "    def world_to_camera_4x4(self):\n",
    "        return self._world_to_camera_4x4\n",
    "\n",
    "    @property\n",
    "    def camera_to_world_4x4(self):\n",
    "        return self._camera_to_world_4x4\n",
    "    \n",
    "    @property\n",
    "    def frame_origin(self):\n",
    "        \"\"\"Return camera frame origin in world coordinates.\"\"\"\n",
    "        return pose.camera_to_world_4x4[:3, 3]\n",
    "    \n",
    "    @property\n",
    "    def frame_axes(self):\n",
    "        \"\"\"Return camera axes: a list of 3D basis \n",
    "        vectors (cx, cy, cz) defined in world frame\"\"\"\n",
    "        return pose.camera_to_world_4x4[:3, :3].T\n",
    "\n",
    "    def compose_world_to_camera(self, other_pose):\n",
    "        \"\"\"Compose camera poses C_1, C_2, ... (defined relative to each other), \n",
    "        computing transforms from world frame to an innermost camera frame.\n",
    "        \n",
    "        Equivalent to: \n",
    "        x_world = <some point>\n",
    "        other_pose.world_to_camera(\n",
    "            pose.world_to_camera(\n",
    "                x_world\n",
    "            )\n",
    "        )\n",
    "        \"\"\"\n",
    "        composed_world_to_camera_4x4 = np.dot(other_pose.world_to_camera_4x4, self._world_to_camera_4x4)\n",
    "        composed_camera_to_world_4x4 = np.linalg.inv(composed_world_to_camera_4x4)\n",
    "        return CameraPose(composed_camera_to_world_4x4)\n",
    "    \n",
    "    def compose_camera_to_world(self, other_pose):\n",
    "        \"\"\"Compose camera poses C_1, C_2, ... (defined relative to each other), \n",
    "        computing transforms from innermost camera frame to the world frame.\n",
    "        \n",
    "        Equivalent to: \n",
    "        x_local = <some point>\n",
    "        pose.camera_to_world(\n",
    "            pose_local.camera_to_world(\n",
    "                x_local\n",
    "            )\n",
    "        )\n",
    "        \"\"\"\n",
    "        composed_camera_to_world_4x4 = np.dot(self._camera_to_world_4x4, other_pose.camera_to_world_4x4, )\n",
    "        return CameraPose(composed_camera_to_world_4x4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.array([1, 1, 0])\n",
    "R = rotate_to_world_origin(t)\n",
    "# R = np.identity(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "pose = CameraPose.from_camera_axes(R=R, t=t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_local = CameraPose.from_camera_axes(R=np.identity(3), t=np.array([1, 1, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1.,  0.,  0., -1.],\n",
       "        [ 0.,  1.,  0., -1.],\n",
       "        [ 0.,  0.,  1.,  0.],\n",
       "        [ 0.,  0.,  0.,  1.]]),\n",
       " array([[-0.70710678,  0.70710678, -0.        , -0.        ],\n",
       "        [-0.        , -0.        , -1.        , -0.        ],\n",
       "        [-0.70710678, -0.70710678, -0.        ,  1.41421356],\n",
       "        [ 0.        ,  0.        ,  0.        ,  1.        ]]))"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pose_local.world_to_camera_4x4, pose.world_to_camera_4x4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "composed = pose.compose_right(pose_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.70710678,  0.70710678, -0.        , -1.        ],\n",
       "       [-0.        , -0.        , -1.        , -1.        ],\n",
       "       [-0.70710678, -0.70710678, -0.        ,  1.41421356],\n",
       "       [ 0.        ,  0.        ,  0.        ,  1.        ]])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "composed.world_to_camera_4x4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.70710678,  0.70710678,  0.        , -1.        ],\n",
       "        [ 0.        ,  0.        , -1.        , -1.        ],\n",
       "        [-0.70710678, -0.70710678,  0.        ,  1.41421356],\n",
       "        [ 0.        ,  0.        ,  0.        ,  1.        ]]),)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(pose_local.world_to_camera_4x4, pose.world_to_camera_4x4),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1., -2.,  0.,  1.])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(\n",
    "    np.dot(pose_local.world_to_camera_4x4, pose.world_to_camera_4x4),\n",
    "    np.array([1., 1., 1., 1.]).T\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.70710678,  0.        , -0.70710678,  1.        ],\n",
       "       [ 0.70710678,  0.        , -0.70710678,  1.        ],\n",
       "       [ 0.        , -1.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  1.        ]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pose.camera_to_world_4x4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_world = np.array([1., 1., 1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0., -1.,  0.]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pose.world_to_camera(x_world)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1., -2.,  0.]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pose_local.world_to_camera(\n",
    "    pose.world_to_camera(x_world)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_local = np.array([0., 0., 0.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 0.]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pose_local.camera_to_world(\n",
    "    x_local\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.29289322,  1.70710678, -1.        ]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pose.camera_to_world(\n",
    "    pose_local.camera_to_world(\n",
    "        x_local\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.70710678,  0.        , -0.70710678,  0.29289322],\n",
       "       [ 0.70710678,  0.        , -0.70710678,  1.70710678],\n",
       "       [ 0.        , -1.        ,  0.        , -1.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  1.        ]])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(pose.camera_to_world_4x4, pose_local.camera_to_world_4x4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.70710678,  0.        , -0.70710678,  0.29289322],\n",
       "       [ 0.70710678,  0.        , -0.70710678,  1.70710678],\n",
       "       [ 0.        , -1.        ,  0.        , -1.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  1.        ]])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pose.compose_camera_to_world(pose_local).camera_to_world_4x4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.70710678,  0.70710678, -0.        , -1.        ],\n",
       "       [-0.        , -0.        , -1.        , -1.        ],\n",
       "       [-0.70710678, -0.70710678, -0.        ,  1.41421356],\n",
       "       [ 0.        ,  0.        ,  0.        ,  1.        ]])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pose.compose_camera_to_world(pose_local).world_to_camera_4x4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.70710678,  0.70710678,  0.        , -1.        ],\n",
       "        [ 0.        ,  0.        , -1.        , -1.        ],\n",
       "        [-0.70710678, -0.70710678,  0.        ,  1.41421356],\n",
       "        [ 0.        ,  0.        ,  0.        ,  1.        ]]),)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(pose_local.world_to_camera_4x4, pose.world_to_camera_4x4),"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
